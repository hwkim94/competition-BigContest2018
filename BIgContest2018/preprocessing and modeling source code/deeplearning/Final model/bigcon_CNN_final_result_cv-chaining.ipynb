{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_csv(\"final_result/valid_250_epoch.csv\").rename(columns = {\"Unnamed: 0\" : \"acc_id\"}).fillna(0)\n",
    "test = pd.read_csv(\"final_result/test_250_epoch.csv\").rename(columns = {\"Unnamed: 0\" : \"acc_id\"}).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  ['week-tree', 'total_week', 'retained-week-tree',\n",
    "             'month-tree', \"total_month\", 'retained-month-tree', 'retained-2month-week_month-tree', 'week-month-tree',\n",
    "             '2month-tree', \"total_2month\", 'retained-2month-tree', 'retained-week-month_2month-tree', 'retained-month-week_2month-tree', 'week-2month-tree', 'week-retained-month_2month-tree', \n",
    "             'retained-tree', \"total_retained\",'week-retained-tree', 'week-month-2month_retained-tree', 'week-2month-month_retained-tree']\n",
    "\n",
    "target = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "valid F1 score : 0.835019533206\n",
    "valid F1 score : 0.511169513798\n",
    "valid F1 score : 0.624146637987\n",
    "valid F1 score : 0.759031198686\n",
    "valid F1 score : 0.857057237039\n",
    "valid F1 score : 0.559139784946\n",
    "valid F1 score : 0.721834139352\n",
    "valid F1 score : 0.882810071495\n",
    "valid F1 score : 0.74330571304\n",
    "valid F1 score : 0.930932160033\n",
    "valid F1 score : 0.604991177212\n",
    "valid F1 score : 0.628211250119\n",
    "valid F1 score : 0.776022020593\n",
    "valid F1 score : 0.747978788142\n",
    "valid F1 score : 0.829327654396\n",
    "valid F1 score : 0.873835053613\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1_score(solution, submission):\n",
    "    a=pd.DataFrame(submission,columns=['Y_hat'])\n",
    "    b=pd.DataFrame(solution.tolist(),columns=['Y'])\n",
    "    c=pd.concat([a,b],axis=1)\n",
    "    \n",
    "    tot_table=c.groupby(['Y','Y_hat']).Y_hat.count().unstack()\n",
    "    accuracy=np.sum(np.diag(np.array(tot_table)))/len(c)\n",
    "     \n",
    "    f1_score=1/(np.mean(np.concatenate([1/np.diag(tot_table/tot_table.sum(axis=0)),1/np.diag(tot_table/tot_table.sum(axis=1))])))\n",
    "    print('final accuracy:%s'%(accuracy))    \n",
    "    print('final_f1_score:%s'%(f1_score))   \n",
    "    print()\n",
    "    \n",
    "    return f1_score \n",
    "\n",
    "my_scorer = make_scorer(my_f1_score, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1_score2(solution, submission):\n",
    "    a=pd.DataFrame(submission,columns=['Y_hat'])\n",
    "    b=pd.DataFrame(solution,columns=['Y'])\n",
    "    c=pd.concat([a,b],axis=1)\n",
    "    \n",
    "    tot_table=c.groupby(['Y','Y_hat']).Y_hat.count().unstack()\n",
    "    accuracy=np.sum(np.diag(np.array(tot_table)))/len(c)\n",
    "     \n",
    "    f1_score=1/(np.mean(np.concatenate([1/np.diag(tot_table/tot_table.sum(axis=0)),1/np.diag(tot_table/tot_table.sum(axis=1))])))\n",
    "    return f1_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weight() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        \n",
    "    def convolution(self, input_X, kernel_size, width, num_filter, activation=True) :\n",
    "        conv = tf.layers.conv2d(input_X, filters=num_filter, kernel_size=[kernel_size, width], strides=1)\n",
    "        \n",
    "        if activation :\n",
    "            norm = tf.contrib.layers.layer_norm(conv)\n",
    "            relu = tf.nn.relu(norm)\n",
    "        \n",
    "            return relu\n",
    "        return conv\n",
    "        \n",
    "    def build(self, batch_size, input_dim, is_fc, fc_num_unit, output_dim) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            ## Setting ##\n",
    "            self.batch_size = batch_size\n",
    "            self.input_dim = input_dim\n",
    "            self.output_dim = output_dim\n",
    "            self.is_fc = is_fc\n",
    "            self.fc_num_unit = fc_num_unit\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, self.input_dim])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, self.output_dim])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            #############\n",
    "\n",
    "            \n",
    "            ## Weight ##\n",
    "            if self.is_fc : \n",
    "                self.fc_weight1 = tf.Variable(tf.random_normal([self.input_dim, self.fc_num_unit]))\n",
    "                self.fc_weight2 = tf.Variable(tf.random_normal([self.fc_num_unit, self.output_dim]))\n",
    "                \n",
    "                self.fc_weighted1 = tf.matmul(self.X, self.fc_weight1)\n",
    "                norm = tf.contrib.layers.layer_norm(self.fc_weighted1)\n",
    "                relu = tf.nn.relu(norm)\n",
    "                self.fc_weighted2 = tf.matmul(relu, self.fc_weight2)\n",
    "                \n",
    "                self.weighted =  self.fc_weighted2\n",
    "                \n",
    "            else :\n",
    "                self.weight = tf.Variable(tf.random_normal([self.input_dim, self.output_dim]))\n",
    "                self.weighted = tf.matmul(self.X, self.weight)\n",
    "            \n",
    "            self.logit = self.weighted\n",
    "            self.softmax = tf.nn.softmax(self.logit)\n",
    "            ################\n",
    "            \n",
    "            \n",
    "            ## Learning ##\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logit, labels=self.Y))\n",
    "\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.RMSPropOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "            \n",
    "            self.prediction = tf.equal(tf.argmax(self.logit, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.prediction, tf.float32))    \n",
    "            ##############\n",
    "        \n",
    "        \n",
    "    def train(self, X_input, Y_input, learning_rate, training=True):\n",
    "        feed_dict = {self.X: X_input, self.Y: Y_input, self.learning_rate: learning_rate, self.training: training}\n",
    "        _, cost = self.sess.run([self.optimizer, self.cost], feed_dict=feed_dict)\n",
    "        \n",
    "        return _, cost\n",
    "    \n",
    "    def predict(self, X_input, training=False):\n",
    "        feed_dict = {self.X: X_input, self.training: training}\n",
    "        result = self.sess.run([self.logit], feed_dict=feed_dict)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input):\n",
    "        size = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for idx in range(0, size, self.batch_size):\n",
    "            X_batch = X_input[idx:idx + batch_size]\n",
    "            Y_batch = Y_input[idx:idx + batch_size]\n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= size\n",
    "        total_acc /= size\n",
    "            \n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_weight = []\n",
    "best_f1 = 0\n",
    "\n",
    "for idx0 in range(0, 31)  :\n",
    "    print()\n",
    "    print(\"-------\",idx0,\"-------\")\n",
    "    \n",
    "    for idx1 in range(0, 31)  :\n",
    "        for idx2 in range(0, 31)  :\n",
    "            for idx3 in range(0, 31)  :\n",
    "                pred_df[\"week\"] = (idx0*pred_df[\"model0_week\"] + (30-idx0)*pred_df[\"model1_week\"]) / 30\n",
    "                pred_df[\"month\"] = (idx1*pred_df[\"model0_month\"] + (30-idx1)*pred_df[\"model1_month\"]) / 30\n",
    "                pred_df[\"2month\"] = (idx2*pred_df[\"model0_2month\"] + (30-idx2)*pred_df[\"model1_2month\"]) / 30\n",
    "                pred_df[\"retained\"] = (idx3*pred_df[\"model0_retained\"] + (30-idx3)*pred_df[\"model1_retained\"]) / 30\n",
    "                \n",
    "                f1 = my_f1_score2(np.argmax(pred_df[[\"week\", \"month\", \"2month\", \"retained\"]].values, axis=1), np.argmax(valid_label, axis=1))\n",
    "                if f1 > best_f1 :\n",
    "                    best_f1 = f1\n",
    "                    best_weight = [idx0, idx1, idx2, idx3]\n",
    "                    print(best_f1, best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
