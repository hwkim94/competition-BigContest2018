{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 8\n",
    "input_size = 36\n",
    "input_class = 4\n",
    "hidden_layer1 = 64\n",
    "hidden_layer2 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "  \n",
    "    def build(self) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, input_length, input_size])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, input_class])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            \n",
    "            cell1 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer1)\n",
    "            dropout1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "            cell2 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer1)\n",
    "            multi_cell = tf.nn.rnn_cell.MultiRNNCell([dropout1, cell2])\n",
    "            \n",
    "            output, state = tf.nn.dynamic_rnn(multi_cell, self.X, dtype=tf.float32)\n",
    "            output = tf.transpose(output,[1,0,2])[-1]\n",
    "            \n",
    "            dense = tf.layers.dense(inputs=output, units=input_class)\n",
    "            self.logits = dense\n",
    "\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            \n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, X_input, training=False):\n",
    "        return self.sess.run(self.logits,feed_dict={self.X: X_input, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, X_input, Y_input, training=False):\n",
    "        return self.sess.run(self.accuracy,feed_dict={self.X: X_input,self.Y: Y_input, self.training: training})\n",
    "\n",
    "    def train(self, X_input, Y_input, learning_rate,training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.X: X_input, self.Y: Y_input, self.learning_rate:learning_rate,self.training: training})\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input, batch_size):\n",
    "        N = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for i in range(0, N, batch_size):\n",
    "            X_batch = X_input[i:i + batch_size]\n",
    "            Y_batch = Y_input[i:i + batch_size]\n",
    "                \n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= N\n",
    "        total_acc /= N\n",
    "            \n",
    "        return total_loss, total_acc\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "  \n",
    "    def build(self) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, input_length, input_size])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, input_class])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            \n",
    "            cell1 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer2)\n",
    "            dropout1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "            cell2 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer2)\n",
    "            multi_cell = tf.nn.rnn_cell.MultiRNNCell([dropout1, cell2])\n",
    "            \n",
    "            output, state = tf.nn.dynamic_rnn(multi_cell, self.X, dtype=tf.float32)\n",
    "            output = tf.transpose(output,[1,0,2])[-1]\n",
    "            \n",
    "            dense = tf.layers.dense(inputs=output, units=input_class)\n",
    "            self.logits = dense\n",
    "\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            \n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, X_input, training=False):\n",
    "        return self.sess.run(self.logits,feed_dict={self.X: X_input, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, X_input, Y_input, training=False):\n",
    "        return self.sess.run(self.accuracy,feed_dict={self.X: X_input,self.Y: Y_input, self.training: training})\n",
    "\n",
    "    def train(self, X_input, Y_input, learning_rate,training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.X: X_input, self.Y: Y_input, self.learning_rate:learning_rate,self.training: training})\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input, batch_size):\n",
    "        N = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for i in range(0, N, batch_size):\n",
    "            X_batch = X_input[i:i + batch_size]\n",
    "            Y_batch = Y_input[i:i + batch_size]\n",
    "                \n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= N\n",
    "        total_acc /= N\n",
    "            \n",
    "        return total_loss, total_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
