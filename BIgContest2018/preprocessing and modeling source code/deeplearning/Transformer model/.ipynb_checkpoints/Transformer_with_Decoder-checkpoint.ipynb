{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "- Transformer with denseNet\n",
    "    - Encoding된 vector를 stack하는 방식\n",
    "    - 마지막에 1x1 CNN\n",
    "    \n",
    "    \n",
    "- need to customize\n",
    "    - QK_T_dk -> QK_T\n",
    "    - sinusoid PE -> other PE\n",
    "    - pooling\n",
    "    - one-hot을 한 후 cost 계산\n",
    "    \n",
    "    \n",
    "- https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/4f4a192f0fd272102c8852b00b1007dffd292b90/transformer/Models.py#L11\n",
    "- https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_attention.py\n",
    "- http://nlp.seas.harvard.edu/2018/04/03/attention.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Classifer() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        \n",
    "    def enc_embedding(self, X_input, emb_dim, emb_activation) :\n",
    "        if emb_dim == X_input.get_shape().as_list()[2] :\n",
    "            emb_vector = X_input\n",
    "            \n",
    "        else :\n",
    "            batch, position, dim = X_input.get_shape().as_list()\n",
    "            W_emb = tf.Variable(tf.random_normal([batch, dim, emb_dim]), name=\"W_emb_enc\")\n",
    "            emb_vector = tf.matmul(X_input, W_emb)\n",
    "            \n",
    "        return emb_vector\n",
    "    \n",
    "    def dec_embedding(self, X_input, emb_dim, emb_activation) :\n",
    "        batch, position, dim = X_input.get_shape().as_list()\n",
    "        dimension = position*dim\n",
    "        \n",
    "        flat = tf.reshape(X_input, [batch, 1, dimension])\n",
    "        W_emb = tf.Variable(tf.random_normal([batch, dimension, emb_dim]), name=\"W_emb_dec\")\n",
    "        \n",
    "        emb_vector = tf.matmul(flat, W_emb)\n",
    "        return emb_vector\n",
    "    \n",
    "    def positional_encoding(self, X_input) :\n",
    "        batch, position, dim = X_input.get_shape().as_list()\n",
    "        position_enc = np.array([list([[pos / np.power(10000, 2*i/dim) for i in range(dim)] \n",
    "                                if pos != 0 else np.zeros(dim) for pos in range(position)])]*batch)\n",
    "\n",
    "        position_enc[:, 1:, 0::2] = np.sin(position_enc[:, 1:, 0::2])\n",
    "        position_enc[:, 1:, 1::2] = np.cos(position_enc[:, 1:, 1::2])\n",
    "\n",
    "        pos_enc_vector = tf.constant(position_enc, dtype=tf.float32, shape=[batch, position, dim])\n",
    "        return pos_enc_vector\n",
    "    \n",
    "    def scaled_dot_product_attention(self, Q, K, V, dk) :\n",
    "        QKT_dk = tf.matmul(Q,K, transpose_b=True) / dk\n",
    "        attention = tf.nn.softmax(QKT_dk)\n",
    "        attended_vector = tf.matmul(attention,V)\n",
    "        \n",
    "        return attended_vector\n",
    "        \n",
    "    def multihead_attention(self, Q, K, V, h) :\n",
    "        batch, position, dim_q = Q.get_shape().as_list()\n",
    "        batch, position, dim_k = K.get_shape().as_list()\n",
    "        batch, position, dim_v = V.get_shape().as_list()\n",
    "        dq = dim_q//h\n",
    "        dk = dim_k//h\n",
    "        dv = dim_v//h\n",
    "        \n",
    "        W_Q = tf.Variable(tf.random_normal([h, batch, dim_q, dq]), name=\"W_Q\")\n",
    "        W_K = tf.Variable(tf.random_normal([h, batch, dim_k, dk]), name=\"W_K\")\n",
    "        W_V = tf.Variable(tf.random_normal([h, batch, dim_v, dv]), name=\"W_V\")\n",
    "        W_O = tf.Variable(tf.random_normal([batch, dk*h, dim_k]), name=\"W_O\")\n",
    "    \n",
    "        head_lst = []\n",
    "        for idx in range(h) :\n",
    "            head_lst.append(self.scaled_dot_product_attention(tf.matmul(Q, W_Q[idx]), \n",
    "                                                              tf.matmul(K, W_K[idx]), \n",
    "                                                              tf.matmul(V, W_V[idx]), \n",
    "                                                              tf.constant(dk, tf.float32)))\n",
    "        \n",
    "        multihead_attention = tf.concat(head_lst, axis=2)\n",
    "        linear_projection= tf.matmul(multihead_attention, W_O)\n",
    "        \n",
    "        return linear_projection\n",
    "        \n",
    "    def normarlization(self, X_input) :\n",
    "        return tf.contrib.layers.layer_norm(X_input)\n",
    "    \n",
    "    def feedforward_network(self, X_input, ffn_dim) :\n",
    "        batch, position, dim =  X_input.get_shape().as_list()\n",
    "\n",
    "        ff_vector1 = tf.layers.dense(X_input, ffn_dim, activation=tf.nn.relu)\n",
    "        dropout = tf.layers.dropout(ff_vector1, training=self.training)\n",
    "        ff_vector2 = tf.layers.dense(dropout, dim)\n",
    "        \n",
    "        return ff_vector2\n",
    "    \n",
    "    def resnet(self, X_input1, X_input2) :\n",
    "        return X_input1 + X_input2\n",
    "        \n",
    "    def encoder_layer(self, X_input, h, ffn_dim) :\n",
    "        attended_vector = self.multihead_attention(X_input, X_input, X_input, h)\n",
    "        sublayer1 = self.resnet(X_input, attended_vector)\n",
    "        norm1 = self.normarlization(sublayer1)\n",
    "        \n",
    "        ffn_vector = self.feedforward_network(norm1, ffn_dim)\n",
    "        sublayer2 = self.resnet(norm1, ffn_vector)\n",
    "        norm2 = self.normarlization(sublayer2)\n",
    "        \n",
    "        return norm2\n",
    "    \n",
    "    def decoder_layer(self, X_input, Y_input, h, ffn_dim) :\n",
    "        attended_vector = self.multihead_attention(Y_input, X_input, X_input, h)\n",
    "        sublayer1 = self.resnet(X_input, attended_vector)\n",
    "        norm1 = self.normarlization(sublayer1)\n",
    "        \n",
    "        ffn_vector = self.feedforward_network(norm1, ffn_dim)\n",
    "        sublayer2 = self.resnet(norm1, ffn_vector)\n",
    "        norm2 = self.normarlization(sublayer2)\n",
    "        \n",
    "        return norm2\n",
    "    \n",
    "    def Encode(self) :\n",
    "        enc_embedded_vector = self.enc_embedding(self.X, self.emb_dim, self.emb_activation)\n",
    "        enc_pos_encoded_vector = enc_embedded_vector + self.positional_encoding(enc_embedded_vector)\n",
    "        encoder_input = enc_pos_encoded_vector\n",
    "        \n",
    "        for idx in range(self.N) :\n",
    "            encoder_input = self.encoder_layer(encoder_input, self.h, self.ffn_dim)\n",
    "        encoder_output = encoder_input\n",
    "    \n",
    "        return encoder_output\n",
    "    \n",
    "    def Decode(self, encoder_output) :\n",
    "        dec_embedded_vector = self.dec_embedding(self.X, self.emb_dim, self.emb_activation)\n",
    "        decoder_input = dec_embedded_vector\n",
    "        \n",
    "        W_D = tf.Variable(tf.random_normal([self.output_length-1, self.batch_size, self.emb_dim, self.emb_dim]), name=\"W_D\")\n",
    "        decode_lst = []\n",
    "\n",
    "        for idx in range(self.output_length) :\n",
    "            if idx != 0 :\n",
    "                decoder_input = tf.matmul(decoder_input, W_D[idx-1])\n",
    "                \n",
    "            for idx2 in range(self.N) :\n",
    "                decoder_input = self.decoder_layer(encoder_output, decoder_input, self.h, self.ffn_dim)\n",
    "                \n",
    "            decoder_output = decoder_input\n",
    "            decode_lst.append(decoder_output)\n",
    "\n",
    "        return decode_lst\n",
    "    \n",
    "    def Classify(self, decoder_output) : \n",
    "        classifier_input = tf.stack(decoder_output, axis=1)\n",
    "        batch, length, position, dim = classifier_input.get_shape().as_list()\n",
    "\n",
    "        dimension = position*dim\n",
    "        flat = tf.reshape(classifier_input, [batch, length, dimension])\n",
    "        layer = tf.layers.dense(inputs=flat, units=1)\n",
    "\n",
    "        return tf.reshape(layer, [batch, length])\n",
    "    \n",
    "    def build(self, batch_size, input_length, output_length, input_dim, N, emb_dim, emb_activation, h, ffn_dim, fc_activation) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            ## Setting ##\n",
    "            # input  : ? x input_length x input_dim\n",
    "            self.X = tf.placeholder(tf.float32, [batch_size, input_length, input_dim])\n",
    "            self.Y = tf.placeholder(tf.float32, [batch_size, output_length])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            \n",
    "            self.batch_size = batch_size\n",
    "            self.input_length = input_length\n",
    "            self.output_length = output_length\n",
    "            self.input_dim = input_dim\n",
    "            self.N = N\n",
    "            self.emb_dim = emb_dim\n",
    "            self.emb_activation = emb_activation\n",
    "            self.h = h \n",
    "            self.ffn_dim = ffn_dim\n",
    "            self.fc_activation = fc_activation\n",
    "            #############\n",
    "            \n",
    "            \n",
    "            ## Encoder and Decoder ##\n",
    "            self.Encoder = self.Encode()\n",
    "            self.Decoder = self.Decode(self.Encoder)\n",
    "            #########################\n",
    "            \n",
    "            \n",
    "            ## Classifier ##\n",
    "            self.logit = self.Classify(self.Decoder)\n",
    "            self.softmax = tf.nn.softmax(self.logit)\n",
    "            self.softmax_logit = tf.nn.softmax_cross_entropy_with_logits(logits=self.logit, labels=self.Y)\n",
    "            ################\n",
    "            \n",
    "            \n",
    "            ## Learning ##\n",
    "            self.cost =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logit, labels=self.Y))\n",
    "\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "            \n",
    "            self.prediction = tf.equal(tf.argmax(self.logit, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.prediction, tf.float32))    \n",
    "            ##############\n",
    "        \n",
    "        \n",
    "    def train(self, X_input, Y_input, learning_rate, training=True):\n",
    "        feed_dict = {self.X: X_input, self.Y: Y_input, self.learning_rate: learning_rate, self.training: training}\n",
    "        _, cost = self.sess.run([self.optimizer, self.cost], feed_dict=feed_dict)\n",
    "        \n",
    "        return _, cost\n",
    "    \n",
    "    def predict(self, X_input, training=False):\n",
    "        size = X_input.shape[0]\n",
    "        result_lst = []\n",
    "        \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for idx in range(0, size, self.batch_size):\n",
    "            X_batch = X_input[idx:idx + batch_size]\n",
    "            feed_dict = {self.X: X_batch, self.training: False}\n",
    "                \n",
    "            result = self.sess.run([self.logit], feed_dict=feed_dict)\n",
    "            result_lst.append(result)\n",
    "            \n",
    "        return np.concatenate([x[0][:] for x in result_lst], axis=0)\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input):\n",
    "        size = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for idx in range(0, size, self.batch_size):\n",
    "            X_batch = X_input[idx:idx + batch_size]\n",
    "            Y_batch = Y_input[idx:idx + batch_size]\n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= size\n",
    "        total_acc /= size\n",
    "            \n",
    "        return total_loss, total_acc\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
