{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(lst, num_class=4) :\n",
    "    return np.eye(num_class)[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_cv(csv, fold=5) :\n",
    "    activity= pd.read_csv(csv).drop(\"Unnamed: 0\", axis=1)\n",
    "    activity = activity[activity[\"label\"] != \"empty\"]\n",
    "    \n",
    "    activity = activity.sort_values([\"acc_id\",\"wk\"])[['acc_id', 'wk', 'cnt_clear_bam', 'cnt_clear_inzone_light','cnt_clear_inzone_normal', \n",
    "                                                      'cnt_clear_inzone_skilled', 'cnt_clear_inzone_solo', 'cnt_clear_raid', 'cnt_clear_raid_light',\n",
    "                                                      'cnt_dt', 'cnt_enter_bam', 'cnt_enter_inzone_light', 'cnt_enter_inzone_normal', \n",
    "                                                      'cnt_enter_inzone_skilled', 'cnt_enter_inzone_solo', 'cnt_enter_raid', 'cnt_enter_raid_light',\n",
    "                                                      'cnt_use_buffitem', 'district_chat', 'duel_cnt', 'duel_win', 'faction_chat', 'game_combat_time', \n",
    "                                                      'gathering_cnt', 'get_money','guild_chat', 'item_hongmun', 'making_cnt', 'normal_chat', \n",
    "                                                      'npc_exp', 'npc_hongmun', 'party_chat', 'partybattle_cnt', 'partybattle_win', 'play_time', \n",
    "                                                      'quest_exp', 'quest_hongmun', 'whisper_chat','first_week', 'payment_amount', 'label']]\n",
    "    \n",
    "    activity_lst = []\n",
    "    length = len(activity)//fold\n",
    "    idx = 0\n",
    "    for _ in range(fold) :\n",
    "        activity_lst.append(activity[idx:idx+length])\n",
    "        idx += length\n",
    "        \n",
    "    return activity_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_data_only_one_of_four(cv, only, fold=5) :\n",
    "    \n",
    "    total_value_lst = []\n",
    "    total_label_lst = []\n",
    "    total_acc_id_lst = []\n",
    "    length = len(cv)//fold\n",
    "    \n",
    "    for fold_num in range(fold) :\n",
    "        df = cv[fold_num]\n",
    "        \n",
    "        label = df[[\"acc_id\", \"label\"]]\n",
    "        label = sorted(list(set([tuple(x) for x in label.values])))\n",
    "        label = pd.DataFrame(label, columns = [\"acc_id\", \"label\"])\n",
    "\n",
    "        activity = df.drop(\"label\", axis=1)\n",
    "        acc_id = label[[\"acc_id\"]]\n",
    "    \n",
    "        activity1 = activity[activity[\"wk\"]==1].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity2 = activity[activity[\"wk\"]==2].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity3 = activity[activity[\"wk\"]==3].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity4 = activity[activity[\"wk\"]==4].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity5 = activity[activity[\"wk\"]==5].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity6 = activity[activity[\"wk\"]==6].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity7 = activity[activity[\"wk\"]==7].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity8 = activity[activity[\"wk\"]==8].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "\n",
    "        num_values = len(activity1.values[0])\n",
    "        activity = np.concatenate([activity1.values.reshape([-1, 1, num_values]), activity2.values.reshape([-1, 1, num_values]), \n",
    "                                   activity3.values.reshape([-1, 1, num_values]), activity4.values.reshape([-1, 1, num_values]),\n",
    "                                   activity5.values.reshape([-1, 1, num_values]), activity6.values.reshape([-1, 1, num_values]),\n",
    "                                   activity7.values.reshape([-1, 1, num_values]), activity8.values.reshape([-1, 1, num_values])], axis=1)\n",
    "\n",
    "        label[\"label\"] = label[\"label\"].map(lambda x : 1 if x==only else 0)\n",
    "        label_dic = label.label.tolist()\n",
    "\n",
    "        total_value = activity\n",
    "        total_label = one_hot(label_dic, num_class=2)\n",
    "        total_acc_id = acc_id\n",
    "        \n",
    "        total_value_lst.append(total_value)\n",
    "        total_label_lst.append(total_label)\n",
    "        total_acc_id_lst.append(total_acc_id)\n",
    "        \n",
    "    return total_value_lst, total_label_lst, total_acc_id_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_data_only_one_of_three(cv, only, drop, fold=5) :\n",
    "    \n",
    "    total_value_lst = []\n",
    "    total_label_lst = []\n",
    "    total_acc_id_lst = []\n",
    "    length = len(cv)//fold\n",
    "    \n",
    "    for fold_num in range(fold) :\n",
    "        df = cv[fold_num]\n",
    "        df = df[df[\"label\"]!=drop]\n",
    "        \n",
    "        label = df[[\"acc_id\", \"label\"]]\n",
    "        label = sorted(list(set([tuple(x) for x in label.values])))\n",
    "        label = pd.DataFrame(label, columns = [\"acc_id\", \"label\"])\n",
    "\n",
    "        activity = df.drop(\"label\", axis=1)\n",
    "        acc_id = label[[\"acc_id\"]]\n",
    "    \n",
    "        activity1 = activity[activity[\"wk\"]==1].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity2 = activity[activity[\"wk\"]==2].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity3 = activity[activity[\"wk\"]==3].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity4 = activity[activity[\"wk\"]==4].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity5 = activity[activity[\"wk\"]==5].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity6 = activity[activity[\"wk\"]==6].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity7 = activity[activity[\"wk\"]==7].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity8 = activity[activity[\"wk\"]==8].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "\n",
    "        num_values = len(activity1.values[0])\n",
    "        activity = np.concatenate([activity1.values.reshape([-1, 1, num_values]), activity2.values.reshape([-1, 1, num_values]), \n",
    "                                   activity3.values.reshape([-1, 1, num_values]), activity4.values.reshape([-1, 1, num_values]),\n",
    "                                   activity5.values.reshape([-1, 1, num_values]), activity6.values.reshape([-1, 1, num_values]),\n",
    "                                   activity7.values.reshape([-1, 1, num_values]), activity8.values.reshape([-1, 1, num_values])], axis=1)\n",
    "\n",
    "        label[\"label\"] = label[\"label\"].map(lambda x : 1 if x==only else 0)\n",
    "        label_dic = label.label.tolist()\n",
    "\n",
    "        total_value = activity\n",
    "        total_label = one_hot(label_dic, num_class=2)\n",
    "        total_acc_id = acc_id\n",
    "        \n",
    "        total_value_lst.append(total_value)\n",
    "        total_label_lst.append(total_label)\n",
    "        total_acc_id_lst.append(total_acc_id)\n",
    "        \n",
    "    return total_value_lst, total_label_lst, total_acc_id_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_data_only_one_of_two(cv, only, drop, fold=5) :\n",
    "    \n",
    "    total_value_lst = []\n",
    "    total_label_lst = []\n",
    "    total_acc_id_lst = []\n",
    "    length = len(cv)//fold\n",
    "    \n",
    "    for fold_num in range(fold) :\n",
    "        df = cv[fold_num]\n",
    "        df = df[df[\"label\"]!=drop[0]]\n",
    "        df = df[df[\"label\"]!=drop[1]]\n",
    "        \n",
    "        label = df[[\"acc_id\", \"label\"]]\n",
    "        label = sorted(list(set([tuple(x) for x in label.values])))\n",
    "        label = pd.DataFrame(label, columns = [\"acc_id\", \"label\"])\n",
    "\n",
    "        activity = df.drop(\"label\", axis=1)\n",
    "        acc_id = label[[\"acc_id\"]]\n",
    "    \n",
    "        activity1 = activity[activity[\"wk\"]==1].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity2 = activity[activity[\"wk\"]==2].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity3 = activity[activity[\"wk\"]==3].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity4 = activity[activity[\"wk\"]==4].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity5 = activity[activity[\"wk\"]==5].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity6 = activity[activity[\"wk\"]==6].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity7 = activity[activity[\"wk\"]==7].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity8 = activity[activity[\"wk\"]==8].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "\n",
    "        num_values = len(activity1.values[0])\n",
    "        activity = np.concatenate([activity1.values.reshape([-1, 1, num_values]), activity2.values.reshape([-1, 1, num_values]), \n",
    "                                   activity3.values.reshape([-1, 1, num_values]), activity4.values.reshape([-1, 1, num_values]),\n",
    "                                   activity5.values.reshape([-1, 1, num_values]), activity6.values.reshape([-1, 1, num_values]),\n",
    "                                   activity7.values.reshape([-1, 1, num_values]), activity8.values.reshape([-1, 1, num_values])], axis=1)\n",
    "\n",
    "        label[\"label\"] = label[\"label\"].map(lambda x : 1 if x==only else 0)\n",
    "        label_dic = label.label.tolist()\n",
    "\n",
    "        total_value = activity\n",
    "        total_label = one_hot(label_dic, num_class=2)\n",
    "        total_acc_id = acc_id\n",
    "        \n",
    "        total_value_lst.append(total_value)\n",
    "        total_label_lst.append(total_label)\n",
    "        total_acc_id_lst.append(total_acc_id)\n",
    "        \n",
    "    return total_value_lst, total_label_lst, total_acc_id_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_data_four_label(cv, fold=5) :\n",
    "    total_value_lst = []\n",
    "    total_label_lst = []\n",
    "    total_acc_id_lst = []\n",
    "    length = len(cv)//fold\n",
    "    \n",
    "    for fold_num in range(fold) :\n",
    "        df = cv[fold_num]\n",
    "        \n",
    "        label = df[[\"acc_id\", \"label\"]]\n",
    "        label = sorted(list(set([tuple(x) for x in label.values])))\n",
    "        label = pd.DataFrame(label, columns = [\"acc_id\", \"label\"])\n",
    "\n",
    "        activity = df.drop(\"label\", axis=1)\n",
    "        acc_id = label[[\"acc_id\"]]\n",
    "    \n",
    "        activity1 = activity[activity[\"wk\"]==1].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity2 = activity[activity[\"wk\"]==2].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity3 = activity[activity[\"wk\"]==3].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity4 = activity[activity[\"wk\"]==4].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity5 = activity[activity[\"wk\"]==5].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity6 = activity[activity[\"wk\"]==6].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity7 = activity[activity[\"wk\"]==7].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "        activity8 = activity[activity[\"wk\"]==8].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "\n",
    "        num_values = len(activity1.values[0])\n",
    "        activity = np.concatenate([activity1.values.reshape([-1, 1, num_values]), activity2.values.reshape([-1, 1, num_values]), \n",
    "                                   activity3.values.reshape([-1, 1, num_values]), activity4.values.reshape([-1, 1, num_values]),\n",
    "                                   activity5.values.reshape([-1, 1, num_values]), activity6.values.reshape([-1, 1, num_values]),\n",
    "                                   activity7.values.reshape([-1, 1, num_values]), activity8.values.reshape([-1, 1, num_values])], axis=1)\n",
    "\n",
    "        dic = {\"week\" : 0, \"month\":1, \"2month\":2, \"retained\":3}\n",
    "        label[\"label\"] = label[\"label\"].map(lambda x : dic[x])\n",
    "        label_dic = label.label.tolist()\n",
    "\n",
    "        total_value = activity\n",
    "        total_label = one_hot(label_dic, num_class=4)\n",
    "        total_acc_id = acc_id\n",
    "        \n",
    "        total_value_lst.append(total_value)\n",
    "        total_label_lst.append(total_label)\n",
    "        total_acc_id_lst.append(total_acc_id)\n",
    "        \n",
    "    return total_value_lst, total_label_lst, total_acc_id_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check = pd.read_csv(\"OnlyExpanded.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "check.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = get_data_cv(\"OnlyExpanded.csv\")\n",
    "\n",
    "total_lst0, total_label0, total_acc_id0 = making_data_only_one_of_four(cv_data, \"week\")\n",
    "total_lst1, total_label1, total_acc_id1 = making_data_only_one_of_four(cv_data, \"month\")\n",
    "total_lst2, total_label2, total_acc_id2 = making_data_only_one_of_four(cv_data, \"2month\")\n",
    "total_lst3, total_label3, total_acc_id3 = making_data_only_one_of_four(cv_data, \"retained\")\n",
    "\n",
    "total_lst4, total_label4, total_acc_id4 = making_data_only_one_of_three(cv_data, \"week\", \"retained\")\n",
    "total_lst5, total_label5, total_acc_id5 = making_data_only_one_of_three(cv_data, \"month\", \"retained\")\n",
    "total_lst6, total_label6, total_acc_id6 = making_data_only_one_of_three(cv_data, \"2month\", \"retained\")\n",
    "\n",
    "total_lst7, total_label7, total_acc_id7 = making_data_only_one_of_two(cv_data, \"month\", [\"retained\", \"2month\"])\n",
    "total_lst8, total_label8, total_acc_id8 = making_data_only_one_of_two(cv_data, \"2month\", [\"retained\", \"week\"])\n",
    "total_lst9, total_label9, total_acc_id9 = making_data_only_one_of_two(cv_data, \"2month\", [\"retained\", \"month\"])\n",
    "\n",
    "total_lst10, total_label10, total_acc_id10 = making_data_only_one_of_three(cv_data, \"month\", \"week\")\n",
    "total_lst11, total_label11, total_acc_id11 = making_data_only_one_of_three(cv_data, \"2month\", \"week\")\n",
    "total_lst12, total_label12, total_acc_id12 = making_data_only_one_of_three(cv_data, \"retained\", \"week\")\n",
    "\n",
    "total_lst13, total_label13, total_acc_id13 = making_data_only_one_of_two(cv_data, \"2month\", [\"week\", \"retained\"])\n",
    "total_lst14, total_label14, total_acc_id14 = making_data_only_one_of_two(cv_data, \"retained\", [\"week\", \"month\"])\n",
    "total_lst15, total_label15, total_acc_id15 = making_data_only_one_of_two(cv_data, \"retained\", [\"week\", \"2month\"])\n",
    "\n",
    "total_lst16, total_label16, total_acc_id16 = making_data_four_label(cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(17) :\n",
    "    print(np.array(eval(\"total_lst{}\".format(idx))).shape, np.array(eval(\"total_label{}\".format(idx))).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        \n",
    "    def convolution(self, input_X, kernel_size, width, num_filter, activation=True) :\n",
    "        conv = tf.layers.conv2d(input_X, filters=num_filter, kernel_size=[kernel_size, width], strides=1)\n",
    "        \n",
    "        if activation :\n",
    "            norm = tf.contrib.layers.layer_norm(conv)\n",
    "            relu = tf.nn.relu(norm)\n",
    "        \n",
    "            return relu\n",
    "        return conv\n",
    "        \n",
    "    def build(self, batch_size, height, width, depth, is_embedding, emb_width, num_filter, is_fc, fc_num_unit, fc_activation, cost_function, output_dim) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            ## Setting ##\n",
    "            self.batch_size = batch_size\n",
    "            self.height = height\n",
    "            self.width = width\n",
    "            self.depth = depth\n",
    "            self.is_embedding = is_embedding\n",
    "            self.emb_width = emb_width\n",
    "            self.num_filter = num_filter\n",
    "            self.is_fc = is_fc\n",
    "            self.fc_num_unit = fc_num_unit\n",
    "            self.fc_activation = fc_activation\n",
    "            self.output_dim = output_dim\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, self.height, self.width])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, self.output_dim])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            #############\n",
    "            \n",
    "            \n",
    "            ## Embedding ##\n",
    "            if self.is_embedding :\n",
    "                emb_dense = tf.layers.dense(self.X, self.emb_width*2)\n",
    "                emb_norm = tf.contrib.layers.layer_norm(emb_dense)\n",
    "                emb_relu = tf.nn.relu(emb_norm)\n",
    "                emb_concat = tf.concat([self.X, tf.layers.dense(emb_relu, self.emb_width)], axis=2)\n",
    "                reshaped_X = tf.reshape(emb_concat, [-1, self.height, self.emb_width+self.width, self.depth])\n",
    "                self.width = self.emb_width+self.width\n",
    "            else :\n",
    "                reshaped_X = tf.reshape(self.X, [-1, self.height, self.width, self.depth])\n",
    "            ###############\n",
    "            \n",
    "            \n",
    "            ## Convolution ##\n",
    "            conv1 = self.convolution(reshaped_X, 1, self.width, self.num_filter)\n",
    "            conv1 = self.convolution(conv1, 4, 1, self.num_filter*2)\n",
    "            conv1 = self.convolution(conv1, 1, 1, self.num_filter//4, activation=False)\n",
    "            batch, height, width, depth = conv1.get_shape().as_list()\n",
    "            conv1 = tf.reshape(conv1, [-1, height*width*depth])\n",
    "            \n",
    "            conv2 = self.convolution(reshaped_X, 2, self.width, self.num_filter)\n",
    "            conv2 = self.convolution(conv2, 4, 1, self.num_filter*2)\n",
    "            conv2 = self.convolution(conv2, 1, 1, self.num_filter//4, activation=False)\n",
    "            batch, height, width, depth = conv2.get_shape().as_list()\n",
    "            conv2 = tf.reshape(conv2, [-1, height*width*depth])\n",
    "            \n",
    "            conv3 = self.convolution(reshaped_X, 3, self.width, self.num_filter)\n",
    "            conv3 = self.convolution(conv3, 4, 1, self.num_filter*2)\n",
    "            conv3 = self.convolution(conv3, 1, 1, self.num_filter//4, activation=False)\n",
    "            batch, height, width, depth = conv3.get_shape().as_list()\n",
    "            conv3 = tf.reshape(conv3, [-1, height*width*depth])\n",
    "            \n",
    "            conv4 = self.convolution(reshaped_X, 4, self.width, self.num_filter)\n",
    "            conv4 = self.convolution(conv4, 4, 1, self.num_filter*2)\n",
    "            conv4 = self.convolution(conv4, 1, 1, self.num_filter//4, activation=False)\n",
    "            batch, height, width, depth = conv4.get_shape().as_list()\n",
    "            conv4 = tf.reshape(conv4, [-1, height*width*depth])\n",
    "            \n",
    "            conv5 = self.convolution(reshaped_X, 5, self.width, self.num_filter)\n",
    "            conv5 = self.convolution(conv5, 4, 1, self.num_filter*2)\n",
    "            conv5 = self.convolution(conv5, 1, 1, self.num_filter//4, activation=False)\n",
    "            batch, height, width, depth = conv5.get_shape().as_list()\n",
    "            conv5 = tf.reshape(conv5, [-1, height*width*depth])\n",
    "            \n",
    "            conv6 = self.convolution(reshaped_X, 6, self.width, self.num_filter)\n",
    "            conv6 = self.convolution(conv6, 3, 1, self.num_filter*2)\n",
    "            conv6 = self.convolution(conv6, 1, 1, self.num_filter//4, activation=False)\n",
    "            batch, height, width, depth = conv6.get_shape().as_list()\n",
    "            conv6 = tf.reshape(conv6, [-1, height*width*depth])\n",
    "            \n",
    "            conv7 = self.convolution(reshaped_X, 7, self.width, self.num_filter)\n",
    "            conv7 = self.convolution(conv7, 2, 1, self.num_filter*2)\n",
    "            conv7 = self.convolution(conv7, 1, 1, self.num_filter//4, activation=False)\n",
    "            batch, height, width, depth = conv7.get_shape().as_list()\n",
    "            conv7 = tf.reshape(conv7, [-1, height*width*depth])\n",
    "            \n",
    "            conv8 = self.convolution(reshaped_X, 8, self.width, self.num_filter)\n",
    "            conv8 = self.convolution(conv8, 1, 1, self.num_filter*2)\n",
    "            conv8 = self.convolution(conv8, 1, 1, self.num_filter//8, activation=False)\n",
    "            batch, height, width, depth = conv8.get_shape().as_list()\n",
    "            conv8 = tf.reshape(conv8, [-1, height*width*depth])\n",
    "            #################\n",
    "            \n",
    "            \n",
    "            ## Classifier ##\n",
    "            conv_result = tf.concat([conv1, conv2, conv3, conv4, conv5, conv6, conv7, conv8], axis=1)\n",
    "            \n",
    "            if is_fc : \n",
    "                dense= tf.layers.dense(conv_result, self.fc_num_unit)\n",
    "                norm = tf.contrib.layers.layer_norm(dense)\n",
    "                relu = tf.nn.relu(norm)\n",
    "                self.logit = tf.layers.dense(norm, self.output_dim)\n",
    "            else :\n",
    "                self.logit = tf.layers.dense(conv_result,  self.output_dim)\n",
    "                \n",
    "            self.softmax = tf.nn.softmax(self.logit)\n",
    "            ################\n",
    "            \n",
    "            \n",
    "            ## Learning ##\n",
    "            if cost_function == \"f1\" :\n",
    "                self.numerator = tf.reduce_sum(self.softmax*self.Y)\n",
    "                self.denominator = tf.reduce_sum(self.softmax*self.Y + self.Y)\n",
    "                self.cost = -2 * self.numerator / self.denominator\n",
    "                \n",
    "            else :\n",
    "                self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logit, labels=self.Y))\n",
    "\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "            \n",
    "            self.prediction = tf.equal(tf.argmax(self.logit, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.prediction, tf.float32))    \n",
    "            ##############\n",
    "        \n",
    "        \n",
    "    def train(self, X_input, Y_input, learning_rate, training=True):\n",
    "        feed_dict = {self.X: X_input, self.Y: Y_input, self.learning_rate: learning_rate, self.training: training}\n",
    "        _, cost = self.sess.run([self.optimizer, self.cost], feed_dict=feed_dict)\n",
    "        \n",
    "        return _, cost\n",
    "    \n",
    "    def predict(self, X_input, training=False):\n",
    "        feed_dict = {self.X: X_input, self.training: training}\n",
    "        result = self.sess.run([self.logit], feed_dict=feed_dict)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input):\n",
    "        size = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for idx in range(0, size, self.batch_size):\n",
    "            X_batch = X_input[idx:idx + batch_size]\n",
    "            Y_batch = Y_input[idx:idx + batch_size]\n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= size\n",
    "        total_acc /= size\n",
    "            \n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate1 = 0.001\n",
    "learning_rate2 = 0.001\n",
    "learning_rate3 = 0.001\n",
    "learning_rate4 = 0.001\n",
    "\n",
    "total_epoch = 120\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_ta_vl_va_lst = [[[[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]]],\n",
    "                  [[[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]]],\n",
    "                  [[[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]]],\n",
    "                  [[[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]]],\n",
    "                  [[[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]],\n",
    "                   [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]], [[],[],[],[],[],[]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_lst = []\n",
    "for idx in range(1) :\n",
    "    temp = []\n",
    "    for idx2 in range(17) :\n",
    "        if idx2 == 16 :\n",
    "            sess = tf.Session()\n",
    "            model = CNN(sess, \"model{}_{}\".format(idx, idx2))\n",
    "            model.build(500, 8, 38, 1, True, 26, 64, False, 128, tf.nn.relu, \"accuracy\", 4)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            print(idx, idx2)\n",
    "            temp.append(model)\n",
    "            continue\n",
    "        \n",
    "        sess = tf.Session()\n",
    "        model = CNN(sess, \"model{}_{}\".format(idx, idx2))\n",
    "        model.build(500, 8, 38, 1, True, 26, 64, False, 128, tf.nn.relu, \"accuracy\", 2)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        print(idx, idx2)\n",
    "        temp.append(model)\n",
    "        \n",
    "    model_lst.append(temp)\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "for cv_num in range(1) :\n",
    "    training_cv_lst = []\n",
    "    training_cv_label = []\n",
    "    valid_cv_lst= []\n",
    "    valid_cv_label = []\n",
    "    \n",
    "    if cv_num == 0 :\n",
    "        for num in range(17) :\n",
    "            training_cv_lst.append(np.concatenate([eval(\"total_lst{}\".format(num))[0],\n",
    "                                                   eval(\"total_lst{}\".format(num))[1],\n",
    "                                                   eval(\"total_lst{}\".format(num))[2],\n",
    "                                                   eval(\"total_lst{}\".format(num))[3]], axis=0))\n",
    "            training_cv_label.append(np.concatenate([eval(\"total_label{}\".format(num))[0],\n",
    "                                                     eval(\"total_label{}\".format(num))[1], \n",
    "                                                     eval(\"total_label{}\".format(num))[2], \n",
    "                                                     eval(\"total_label{}\".format(num))[3]], axis=0))\n",
    "            valid_cv_lst.append(eval(\"total_lst{}\".format(num))[4])\n",
    "            valid_cv_label.append(eval(\"total_label{}\".format(num))[4])\n",
    "        \n",
    "    elif cv_num == 1 :\n",
    "        for num in range(17) :\n",
    "            training_cv_lst.append(np.concatenate([eval(\"total_lst{}\".format(num))[0], \n",
    "                                                   eval(\"total_lst{}\".format(num))[1], \n",
    "                                                   eval(\"total_lst{}\".format(num))[2], \n",
    "                                                   eval(\"total_lst{}\".format(num))[4]], axis=0))\n",
    "            training_cv_label.append(np.concatenate([eval(\"total_label{}\".format(num))[0], \n",
    "                                                     eval(\"total_label{}\".format(num))[1], \n",
    "                                                     eval(\"total_label{}\".format(num))[2], \n",
    "                                                     eval(\"total_label{}\".format(num))[4]], axis=0))\n",
    "            valid_cv_lst.append(eval(\"total_lst{}\".format(num))[3])\n",
    "            valid_cv_label.append(eval(\"total_label{}\".format(num))[3])\n",
    "        \n",
    "    elif cv_num == 2 :\n",
    "        for num in range(17) :\n",
    "            training_cv_lst.append(np.concatenate([eval(\"total_lst{}\".format(num))[0], \n",
    "                                                   eval(\"total_lst{}\".format(num))[1], \n",
    "                                                   eval(\"total_lst{}\".format(num))[3], \n",
    "                                                   eval(\"total_lst{}\".format(num))[4]], axis=0))\n",
    "            training_cv_label.append(np.concatenate([eval(\"total_label{}\".format(num))[0], \n",
    "                                                     eval(\"total_label{}\".format(num))[1], \n",
    "                                                     eval(\"total_label{}\".format(num))[3], \n",
    "                                                     eval(\"total_label{}\".format(num))[4]], axis=0))\n",
    "            valid_cv_lst.append(eval(\"total_lst{}\".format(num))[2])\n",
    "            valid_cv_label.append(eval(\"total_label{}\".format(num))[2]) \n",
    "            \n",
    "    elif cv_num == 3 :\n",
    "        for num in range(17) :\n",
    "            training_cv_lst.append(np.concatenate([eval(\"total_lst{}\".format(num))[0], \n",
    "                                                   eval(\"total_lst{}\".format(num))[2], \n",
    "                                                   eval(\"total_lst{}\".format(num))[3], \n",
    "                                                   eval(\"total_lst{}\".format(num))[4]], axis=0))\n",
    "            training_cv_label.append(np.concatenate([eval(\"total_label{}\".format(num))[0], \n",
    "                                                     eval(\"total_label{}\".format(num))[2], \n",
    "                                                     eval(\"total_label{}\".format(num))[3], \n",
    "                                                     eval(\"total_label{}\".format(num))[4]], axis=0))\n",
    "            valid_cv_lst.append(eval(\"total_lst{}\".format(num))[1])\n",
    "            valid_cv_label.append(eval(\"total_label{}\".format(num))[1]) \n",
    "            \n",
    "    elif cv_num == 4 :\n",
    "        for num in range(17) :\n",
    "            training_cv_lst.append(np.concatenate([eval(\"total_lst{}\".format(num))[1], \n",
    "                                                   eval(\"total_lst{}\".format(num))[2], \n",
    "                                                   eval(\"total_lst{}\".format(num))[3], \n",
    "                                                   eval(\"total_lst{}\".format(num))[4]], axis=0))\n",
    "            training_cv_label.append(np.concatenate([eval(\"total_label{}\".format(num))[1],\n",
    "                                                     eval(\"total_label{}\".format(num))[2], \n",
    "                                                     eval(\"total_label{}\".format(num))[3], \n",
    "                                                     eval(\"total_label{}\".format(num))[4]], axis=0))\n",
    "            valid_cv_lst.append(eval(\"total_lst{}\".format(num))[0])\n",
    "            valid_cv_label.append(eval(\"total_label{}\".format(num))[0]) \n",
    "            \n",
    "    for epoch in range(total_epoch):\n",
    "        print(\"***epoch*** : \", cv_num, epoch)\n",
    "\n",
    "        if epoch == 0 :\n",
    "            learning_rate = learning_rate1\n",
    "        elif epoch == 25 :\n",
    "            learning_rate = learning_rate2\n",
    "        elif epoch == 40 :\n",
    "            learning_rate = learning_rate3\n",
    "        elif epoch == 60 :\n",
    "            learning_rate = learning_rate4\n",
    "\n",
    "        # train model\n",
    "        for model_num in range(17) :\n",
    "            print(\"log :\", model_num)\n",
    "\n",
    "            avg_cost = 0\n",
    "            total_batch = int(len(training_cv_lst[model_num])) // batch_size\n",
    "            idx = 0\n",
    "\n",
    "            for i in range(total_batch):\n",
    "                batch_xs, batch_ys = training_cv_lst[model_num][idx:idx+batch_size],training_cv_label[model_num][idx:idx+batch_size]\n",
    "\n",
    "                _, c = model_lst[cv_num][model_num].train(batch_xs, batch_ys, learning_rate)\n",
    "                avg_cost += c / total_batch\n",
    "\n",
    "                idx += batch_size\n",
    "\n",
    "        #train/valid cost & acc\n",
    "        for model_num in range(17) :\n",
    "            train_cost, train_acc = model_lst[cv_num][model_num].evaluate(training_cv_lst[model_num], training_cv_label[model_num])\n",
    "            valid_cost, valid_acc = model_lst[cv_num][model_num].evaluate(valid_cv_lst[model_num],valid_cv_label[model_num])\n",
    "            tl_ta_vl_va_lst[cv_num][model_num][0].append(train_cost)\n",
    "            tl_ta_vl_va_lst[cv_num][model_num][1].append(train_acc)\n",
    "            tl_ta_vl_va_lst[cv_num][model_num][2].append(valid_cost)\n",
    "            tl_ta_vl_va_lst[cv_num][model_num][3].append(valid_acc)\n",
    "            print(\"-- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(train_cost, train_acc*100, valid_cost, valid_acc*100))\n",
    "\n",
    "\n",
    "        #acuuracy\n",
    "        for model_num in range(17) :\n",
    "            print('Accuracy:', model_lst[cv_num][model_num].evaluate(valid_cv_lst[model_num], valid_cv_label[model_num])[1])\n",
    "\n",
    "\n",
    "        #f1 score\n",
    "        for model_num in range(16) :\n",
    "            f1 = f1_score(np.argmax(training_cv_label[model_num], 1), np.argmax(model_lst[cv_num][model_num].predict(training_cv_lst[model_num])[0], 1))\n",
    "            tl_ta_vl_va_lst[cv_num][model_num][4].append(f1)\n",
    "            print(\"train F1 score :\", f1)\n",
    "        for model_num in range(16) :\n",
    "            f1 = f1_score(np.argmax(valid_cv_label[model_num], 1), np.argmax(model_lst[cv_num][model_num].predict(valid_cv_lst[model_num])[0], 1))\n",
    "            tl_ta_vl_va_lst[cv_num][model_num][5].append(f1)\n",
    "            print(\"valid F1 score :\", f1)\n",
    "\n",
    "        print(\"\")\n",
    "        \n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <br></br><br></br><br></br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_num=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst[cv_num])) :\n",
    "    plt.plot(tl_ta_vl_va_lst[cv_num][idx][0], label='training'+str(idx))\n",
    "    plt.plot(tl_ta_vl_va_lst[cv_num][idx][2], label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst[cv_num])) :\n",
    "    plt.plot(tl_ta_vl_va_lst[cv_num][idx][1], label='training'+str(idx))\n",
    "    plt.plot(tl_ta_vl_va_lst[cv_num][idx][3], label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst[cv_num])) :\n",
    "    plt.plot(tl_ta_vl_va_lst[cv_num][idx][0], label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst[cv_num])) :\n",
    "    plt.plot(tl_ta_vl_va_lst[cv_num][idx][2], label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst[cv_num])) :\n",
    "    plt.plot(tl_ta_vl_va_lst[cv_num][idx][1], label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst[cv_num])) :\n",
    "    plt.plot(tl_ta_vl_va_lst[cv_num][idx][3], label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst[cv_num])-1) :\n",
    "    plt.plot(tl_ta_vl_va_lst[cv_num][idx][4], label='training'+str(idx))\n",
    "    plt.plot(tl_ta_vl_va_lst[cv_num][idx][5], label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <br></br><br></br><br></br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_valid(cv, fold=5) :\n",
    "    activity = cv.drop(\"label\", axis=1)\n",
    "    \n",
    "    activity1 = activity[activity[\"wk\"]==1].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity2 = activity[activity[\"wk\"]==2].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity3 = activity[activity[\"wk\"]==3].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity4 = activity[activity[\"wk\"]==4].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity5 = activity[activity[\"wk\"]==5].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity6 = activity[activity[\"wk\"]==6].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity7 = activity[activity[\"wk\"]==7].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity8 = activity[activity[\"wk\"]==8].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    \n",
    "    num_values = len(activity1.values[0])\n",
    "    activity = np.concatenate([activity1.values.reshape([-1, 1, num_values]), activity2.values.reshape([-1, 1, num_values]), \n",
    "                               activity3.values.reshape([-1, 1, num_values]), activity4.values.reshape([-1, 1, num_values]),\n",
    "                               activity5.values.reshape([-1, 1, num_values]), activity6.values.reshape([-1, 1, num_values]),\n",
    "                               activity7.values.reshape([-1, 1, num_values]), activity8.values.reshape([-1, 1, num_values])], axis=1)\n",
    "    \n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_ensemble(cv, pred, pred_id, fold=5) :\n",
    "    activity = cv.drop(\"label\", axis=1)\n",
    "    label = pd.concat([pd.DataFrame(sorted(list(set(pred_id.acc_id.tolist()))), columns = [\"acc_id\"]), pred], axis=1)\n",
    "\n",
    "    activity = pd.merge(activity, label, how='left', on='acc_id')\n",
    "    activity = activity[activity[\"label\"] < 0.7].drop(\"label\", axis=1)\n",
    "    acc_id = activity[[\"acc_id\"]]\n",
    "    \n",
    "    activity1 = activity[activity[\"wk\"]==1].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity2 = activity[activity[\"wk\"]==2].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity3 = activity[activity[\"wk\"]==3].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity4 = activity[activity[\"wk\"]==4].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity5 = activity[activity[\"wk\"]==5].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity6 = activity[activity[\"wk\"]==6].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity7 = activity[activity[\"wk\"]==7].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity8 = activity[activity[\"wk\"]==8].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    \n",
    "    num_values = len(activity1.values[0])\n",
    "    activity = np.concatenate([activity1.values.reshape([-1, 1, num_values]), activity2.values.reshape([-1, 1, num_values]), \n",
    "                               activity3.values.reshape([-1, 1, num_values]), activity4.values.reshape([-1, 1, num_values]),\n",
    "                               activity5.values.reshape([-1, 1, num_values]), activity6.values.reshape([-1, 1, num_values]),\n",
    "                               activity7.values.reshape([-1, 1, num_values]), activity8.values.reshape([-1, 1, num_values])], axis=1)\n",
    "\n",
    "    return activity, acc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_df(pred, pred_id) :\n",
    "    label = pd.concat([pd.DataFrame(sorted(list(set(pred_id.acc_id.tolist()))), columns = [\"acc_id\"]), pred], axis=1)\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = get_data_cv(\"OnlyExpanded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df_lst = []\n",
    "\n",
    "for cv_num in range(1) :\n",
    "    print(\"\")\n",
    "    \n",
    "    if cv_num == 0 :\n",
    "        valid_num = 4\n",
    "    elif cv_num == 1 :\n",
    "        valid_num = 3\n",
    "    elif cv_num == 2 :\n",
    "        valid_num = 2\n",
    "    elif cv_num == 3 :\n",
    "        valid_num = 1\n",
    "    elif cv_num == 4 :\n",
    "        valid_num = 0\n",
    "        \n",
    "    \n",
    "    # 초기 분기\n",
    "    valid_cv_lst = making_valid(cv_data[valid_num])\n",
    "    valid_cv_acc_id = cv_data[valid_num][[\"acc_id\"]]\n",
    "    \n",
    "    result0 = [model_lst[cv_num][0].sess.run(model_lst[cv_num][0].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][0].X : valid_cv_lst, model_lst[cv_num][0].training :False})][0][:,1]\n",
    "    result0 = list(result0)\n",
    "    \n",
    "    result1 = [model_lst[cv_num][1].sess.run(model_lst[cv_num][1].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][1].X : valid_cv_lst, model_lst[cv_num][1].training :False})][0][:,1]\n",
    "    result1 = list(result1)\n",
    "    \n",
    "    result2 = [model_lst[cv_num][2].sess.run(model_lst[cv_num][2].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][2].X : valid_cv_lst, model_lst[cv_num][2].training :False})][0][:,1]\n",
    "    result2 = list(result2)\n",
    "    \n",
    "    result3 = [model_lst[cv_num][3].sess.run(model_lst[cv_num][3].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][3].X : valid_cv_lst, model_lst[cv_num][3].training :False})][0][:,1]\n",
    "    result3 = list(result3)\n",
    "    \n",
    "    result_df0 = pd.DataFrame(result0).rename(columns = {0 : \"label\"})\n",
    "    result_df1 = pd.DataFrame(result1).rename(columns = {0 : \"label\"})\n",
    "    result_df2 = pd.DataFrame(result2).rename(columns = {0 : \"label\"})\n",
    "    result_df3 = pd.DataFrame(result3).rename(columns = {0 : \"label\"})\n",
    "\n",
    "    \n",
    "    # retain 분기\n",
    "    valid_cv_lst3, valid_cv_acc_id3 = making_ensemble(cv_data[valid_num], result_df3, valid_cv_acc_id)\n",
    "\n",
    "    result4 = [model_lst[cv_num][4].sess.run(model_lst[cv_num][4].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][4].X : valid_cv_lst3, \n",
    "                                                          model_lst[cv_num][4].training :False})][0][:,1]\n",
    "    result4 = list(result4)\n",
    "\n",
    "    result5 = [model_lst[cv_num][5].sess.run(model_lst[cv_num][5].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][5].X : valid_cv_lst3, model_lst[cv_num][5].training :False})][0][:,1]\n",
    "    result5 = list(result5)\n",
    "    \n",
    "    result6 = [model_lst[cv_num][6].sess.run(model_lst[cv_num][6].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][6].X : valid_cv_lst3, model_lst[cv_num][6].training :False})][0][:,1]\n",
    "    result6 = list(result6)\n",
    "    \n",
    "    result_df4 = pd.DataFrame(result4).rename(columns = {0 : \"label\"})\n",
    "    result_df5 = pd.DataFrame(result5).rename(columns = {0 : \"label\"})\n",
    "    result_df6 = pd.DataFrame(result6).rename(columns = {0 : \"label\"})\n",
    "    \n",
    "    valid_cv_lst6, valid_cv_acc_id6 = making_ensemble(cv_data[valid_num], result_df6, valid_cv_acc_id3)\n",
    "    valid_cv_lst4, valid_cv_acc_id4 = making_ensemble(cv_data[valid_num], result_df4, valid_cv_acc_id3)\n",
    "    valid_cv_lst5, valid_cv_acc_id5 = making_ensemble(cv_data[valid_num], result_df5, valid_cv_acc_id3)\n",
    "    \n",
    "    result7 = [model_lst[cv_num][7].sess.run(model_lst[cv_num][7].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][7].X : valid_cv_lst6, model_lst[cv_num][7].training :False})][0][:,1]\n",
    "    result7 = list(result7)\n",
    "    \n",
    "    result8 = [model_lst[cv_num][8].sess.run(model_lst[cv_num][8].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][8].X : valid_cv_lst4, model_lst[cv_num][8].training :False})][0][:,1]\n",
    "    result8 = list(result8)\n",
    "    \n",
    "    result9 = [model_lst[cv_num][9].sess.run(model_lst[cv_num][9].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][9].X : valid_cv_lst5, model_lst[cv_num][9].training :False})][0][:,1]\n",
    "    result9 = list(result9)\n",
    "    \n",
    "    result_df7 = pd.DataFrame(result7).rename(columns = {0 : \"label\"})\n",
    "    result_df8 = pd.DataFrame(result8).rename(columns = {0 : \"label\"})\n",
    "    result_df9 = pd.DataFrame(result9).rename(columns = {0 : \"label\"})\n",
    "    \n",
    "    \n",
    "    # week 분기\n",
    "    valid_cv_lst0, valid_cv_acc_id0 = making_ensemble(cv_data[valid_num], result_df0, valid_cv_acc_id)\n",
    "    \n",
    "    result10 = [model_lst[cv_num][10].sess.run(model_lst[cv_num][10].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][10].X : valid_cv_lst0, model_lst[cv_num][10].training :False})][0][:,1]\n",
    "    result10 = list(result10)\n",
    "    \n",
    "    result11 = [model_lst[cv_num][11].sess.run(model_lst[cv_num][11].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][11].X : valid_cv_lst0, model_lst[cv_num][11].training :False})][0][:,1]\n",
    "    result11 = list(result11)\n",
    "    \n",
    "    result12 = [model_lst[cv_num][12].sess.run(model_lst[cv_num][12].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][12].X : valid_cv_lst0, model_lst[cv_num][12].training :False})][0][:,1]\n",
    "    result12 = list(result12)\n",
    "    \n",
    "    result_df10 = pd.DataFrame(result10).rename(columns = {0 : \"label\"})\n",
    "    result_df11 = pd.DataFrame(result11).rename(columns = {0 : \"label\"})\n",
    "    result_df12 = pd.DataFrame(result12).rename(columns = {0 : \"label\"})\n",
    "    \n",
    "    valid_cv_lst12, valid_cv_acc_id12 = making_ensemble(cv_data[valid_num], result_df12, valid_cv_acc_id0)\n",
    "    valid_cv_lst10, valid_cv_acc_id10 = making_ensemble(cv_data[valid_num], result_df10, valid_cv_acc_id0)\n",
    "    valid_cv_lst11, valid_cv_acc_id11 = making_ensemble(cv_data[valid_num], result_df11, valid_cv_acc_id0)\n",
    "    \n",
    "    result13 = [model_lst[cv_num][13].sess.run(model_lst[cv_num][13].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][13].X : valid_cv_lst12, model_lst[cv_num][13].training :False})][0][:,1]\n",
    "    result13 = list(result13)\n",
    "    \n",
    "    result14 = [model_lst[cv_num][14].sess.run(model_lst[cv_num][14].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][14].X : valid_cv_lst10, model_lst[cv_num][14].training :False})][0][:,1]\n",
    "    result14 = list( result14)\n",
    "    \n",
    "    result15 = [model_lst[cv_num][15].sess.run(model_lst[cv_num][15].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][15].X : valid_cv_lst11, model_lst[cv_num][15].training :False})][0][:,1]\n",
    "    result15 = list(result15)\n",
    "    \n",
    "    result_df13 = pd.DataFrame(result13).rename(columns = {0 : \"label\"})\n",
    "    result_df14 = pd.DataFrame(result14).rename(columns = {0 : \"label\"})\n",
    "    result_df15 = pd.DataFrame(result15).rename(columns = {0 : \"label\"})\n",
    "    \n",
    "    \n",
    "    # 모든 label 예측\n",
    "    result16 = [model_lst[cv_num][16].sess.run(model_lst[cv_num][16].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][16].X : valid_cv_lst, model_lst[cv_num][16].training :False})][0][:,:]\n",
    "    result16 = list(result16)\n",
    "    \n",
    "    result_df16 = pd.DataFrame(result16).rename(columns = {0 : \"total_week\", 1: \"total_month\", 2:\"total_2month\", 3:\"total_retained\"})\n",
    "    \n",
    "    result_stack_df = pd.concat([making_df(result_df0, valid_cv_acc_id).set_index(\"acc_id\").rename(columns={\"label\" : \"week-tree\"}), \n",
    "                                 making_df(result_df1, valid_cv_acc_id).set_index(\"acc_id\").rename(columns={\"label\" : \"month-tree\"}), \n",
    "                                 making_df(result_df2, valid_cv_acc_id).set_index(\"acc_id\").rename(columns={\"label\" : \"2month-tree\"}), \n",
    "                                 making_df(result_df3, valid_cv_acc_id).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-tree\"}), \n",
    "                                 making_df(result_df4, valid_cv_acc_id3).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-week-tree\"}), \n",
    "                                 making_df(result_df5, valid_cv_acc_id3).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-month-tree\"}), \n",
    "                                 making_df(result_df6, valid_cv_acc_id3).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-2month-tree\"}), \n",
    "                                 making_df(result_df7, valid_cv_acc_id6).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-2month-week_month-tree\"}), \n",
    "                                 making_df(result_df8, valid_cv_acc_id4).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-week-month_2month-tree\"}),\n",
    "                                 making_df(result_df9, valid_cv_acc_id5).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-month-week_2month-tree\"}),\n",
    "                                 making_df(result_df10, valid_cv_acc_id0).set_index(\"acc_id\").rename(columns={\"label\" : \"week-month-tree\"}), \n",
    "                                 making_df(result_df11, valid_cv_acc_id0).set_index(\"acc_id\").rename(columns={\"label\" : \"week-2month-tree\"}), \n",
    "                                 making_df(result_df12, valid_cv_acc_id0).set_index(\"acc_id\").rename(columns={\"label\" : \"week-retained-tree\"}), \n",
    "                                 making_df(result_df13, valid_cv_acc_id12).set_index(\"acc_id\").rename(columns={\"label\" : \"week-retained-month_2month-tree\"}), \n",
    "                                 making_df(result_df14, valid_cv_acc_id10).set_index(\"acc_id\").rename(columns={\"label\" : \"week-month-2month_retained-tree\"}),\n",
    "                                 making_df(result_df15, valid_cv_acc_id11).set_index(\"acc_id\").rename(columns={\"label\" : \"week-2month-month_retained-tree\"}),\n",
    "                                 making_df(result_df16, valid_cv_acc_id).set_index(\"acc_id\").rename(columns={\"label\" : \"total\"})], axis=1)\n",
    "    \n",
    "    result_df_lst.append(result_stack_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_label_for_cv4 = pd.DataFrame(np.argmax(total_label16[4],axis=1)).rename(columns = {0 : \"label\"})\n",
    "\n",
    "print(len(valid_label_for_cv4))\n",
    "valid_label_for_cv4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_stack_df_label = pd.concat([result_stack_df.reset_index(), valid_label_for_cv4], axis=1).rename(columns = {\"index\" : \"acc_id\"}).set_index(\"acc_id\")\n",
    "\n",
    "print(len(result_stack_df_label))\n",
    "result_stack_df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_stack_df_label.to_csv(\"final_result/valid_250_epoch.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_cv2(csv, fold=1) :\n",
    "    activity= pd.read_csv(csv).drop(\"Unnamed: 0\", axis=1)\n",
    "    activity = activity[activity[\"label\"] == \"empty\"]\n",
    "    \n",
    "    activity = activity.sort_values([\"acc_id\",\"wk\"])[['acc_id', 'wk', 'cnt_clear_bam', 'cnt_clear_inzone_light','cnt_clear_inzone_normal', \n",
    "                                                      'cnt_clear_inzone_skilled', 'cnt_clear_inzone_solo', 'cnt_clear_raid', 'cnt_clear_raid_light',\n",
    "                                                      'cnt_dt', 'cnt_enter_bam', 'cnt_enter_inzone_light', 'cnt_enter_inzone_normal', \n",
    "                                                      'cnt_enter_inzone_skilled', 'cnt_enter_inzone_solo', 'cnt_enter_raid', 'cnt_enter_raid_light',\n",
    "                                                      'cnt_use_buffitem', 'district_chat', 'duel_cnt', 'duel_win', 'faction_chat', 'game_combat_time', \n",
    "                                                      'gathering_cnt', 'get_money','guild_chat', 'item_hongmun', 'making_cnt', 'normal_chat', \n",
    "                                                      'npc_exp', 'npc_hongmun', 'party_chat', 'partybattle_cnt', 'partybattle_win', 'play_time', \n",
    "                                                      'quest_exp', 'quest_hongmun', 'whisper_chat','first_week', 'payment_amount', 'label']]\n",
    "    \n",
    "    activity_lst = []\n",
    "    length = len(activity)//fold\n",
    "    idx = 0\n",
    "    for _ in range(fold) :\n",
    "        activity_lst.append(activity[idx:idx+length])\n",
    "        idx += length\n",
    "        \n",
    "    return activity_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_test(cv, fold=5) :\n",
    "    activity = cv.drop(\"label\", axis=1)\n",
    "    \n",
    "    activity1 = activity[activity[\"wk\"]==1].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity2 = activity[activity[\"wk\"]==2].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity3 = activity[activity[\"wk\"]==3].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity4 = activity[activity[\"wk\"]==4].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity5 = activity[activity[\"wk\"]==5].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity6 = activity[activity[\"wk\"]==6].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity7 = activity[activity[\"wk\"]==7].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity8 = activity[activity[\"wk\"]==8].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    \n",
    "    num_values = len(activity1.values[0])\n",
    "    activity = np.concatenate([activity1.values.reshape([-1, 1, num_values]), activity2.values.reshape([-1, 1, num_values]), \n",
    "                               activity3.values.reshape([-1, 1, num_values]), activity4.values.reshape([-1, 1, num_values]),\n",
    "                               activity5.values.reshape([-1, 1, num_values]), activity6.values.reshape([-1, 1, num_values]),\n",
    "                               activity7.values.reshape([-1, 1, num_values]), activity8.values.reshape([-1, 1, num_values])], axis=1)\n",
    "    \n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_data_cv2(\"OnlyExpanded.csv\")\n",
    "cv_data = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_lst = []\n",
    "\n",
    "for cv_num in range(1) :\n",
    "    print(\"\")\n",
    "    \n",
    "    if cv_num == 0 :\n",
    "        valid_num = 4\n",
    "    elif cv_num == 1 :\n",
    "        valid_num = 3\n",
    "    elif cv_num == 2 :\n",
    "        valid_num = 2\n",
    "    elif cv_num == 3 :\n",
    "        valid_num = 1\n",
    "    elif cv_num == 4 :\n",
    "        valid_num = 0\n",
    "    valid_num = 0\n",
    "    \n",
    "    # 초기 분기\n",
    "    valid_cv_lst = making_valid(cv_data[valid_num])\n",
    "    valid_cv_acc_id = cv_data[valid_num][[\"acc_id\"]]\n",
    "    \n",
    "    result0 = [model_lst[cv_num][0].sess.run(model_lst[cv_num][0].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][0].X : valid_cv_lst, model_lst[cv_num][0].training :False})][0][:,1]\n",
    "    result0 = list(result0)\n",
    "    \n",
    "    result1 = [model_lst[cv_num][1].sess.run(model_lst[cv_num][1].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][1].X : valid_cv_lst, model_lst[cv_num][1].training :False})][0][:,1]\n",
    "    result1 = list(result1)\n",
    "    \n",
    "    result2 = [model_lst[cv_num][2].sess.run(model_lst[cv_num][2].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][2].X : valid_cv_lst, model_lst[cv_num][2].training :False})][0][:,1]\n",
    "    result2 = list(result2)\n",
    "    \n",
    "    result3 = [model_lst[cv_num][3].sess.run(model_lst[cv_num][3].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][3].X : valid_cv_lst, model_lst[cv_num][3].training :False})][0][:,1]\n",
    "    result3 = list(result3)\n",
    "    \n",
    "    result_df0 = pd.DataFrame(result0).rename(columns = {0 : \"label\"})\n",
    "    result_df1 = pd.DataFrame(result1).rename(columns = {0 : \"label\"})\n",
    "    result_df2 = pd.DataFrame(result2).rename(columns = {0 : \"label\"})\n",
    "    result_df3 = pd.DataFrame(result3).rename(columns = {0 : \"label\"})\n",
    "\n",
    "    \n",
    "    # retain 분기\n",
    "    valid_cv_lst3, valid_cv_acc_id3 = making_ensemble(cv_data[valid_num], result_df3, valid_cv_acc_id)\n",
    "\n",
    "    result4 = [model_lst[cv_num][4].sess.run(model_lst[cv_num][4].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][4].X : valid_cv_lst3, \n",
    "                                                          model_lst[cv_num][4].training :False})][0][:,1]\n",
    "    result4 = list(result4)\n",
    "\n",
    "    result5 = [model_lst[cv_num][5].sess.run(model_lst[cv_num][5].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][5].X : valid_cv_lst3, model_lst[cv_num][5].training :False})][0][:,1]\n",
    "    result5 = list(result5)\n",
    "    \n",
    "    result6 = [model_lst[cv_num][6].sess.run(model_lst[cv_num][6].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][6].X : valid_cv_lst3, model_lst[cv_num][6].training :False})][0][:,1]\n",
    "    result6 = list(result6)\n",
    "    \n",
    "    result_df4 = pd.DataFrame(result4).rename(columns = {0 : \"label\"})\n",
    "    result_df5 = pd.DataFrame(result5).rename(columns = {0 : \"label\"})\n",
    "    result_df6 = pd.DataFrame(result6).rename(columns = {0 : \"label\"})\n",
    "    \n",
    "    valid_cv_lst6, valid_cv_acc_id6 = making_ensemble(cv_data[valid_num], result_df6, valid_cv_acc_id3)\n",
    "    valid_cv_lst4, valid_cv_acc_id4 = making_ensemble(cv_data[valid_num], result_df4, valid_cv_acc_id3)\n",
    "    valid_cv_lst5, valid_cv_acc_id5 = making_ensemble(cv_data[valid_num], result_df5, valid_cv_acc_id3)\n",
    "    \n",
    "    result7 = [model_lst[cv_num][7].sess.run(model_lst[cv_num][7].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][7].X : valid_cv_lst6, model_lst[cv_num][7].training :False})][0][:,1]\n",
    "    result7 = list(result7)\n",
    "    \n",
    "    result8 = [model_lst[cv_num][8].sess.run(model_lst[cv_num][8].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][8].X : valid_cv_lst4, model_lst[cv_num][8].training :False})][0][:,1]\n",
    "    result8 = list(result8)\n",
    "    \n",
    "    result9 = [model_lst[cv_num][9].sess.run(model_lst[cv_num][9].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][9].X : valid_cv_lst5, model_lst[cv_num][9].training :False})][0][:,1]\n",
    "    result9 = list(result9)\n",
    "    \n",
    "    result_df7 = pd.DataFrame(result7).rename(columns = {0 : \"label\"})\n",
    "    result_df8 = pd.DataFrame(result8).rename(columns = {0 : \"label\"})\n",
    "    result_df9 = pd.DataFrame(result9).rename(columns = {0 : \"label\"})\n",
    "    \n",
    "    \n",
    "    # week 분기\n",
    "    valid_cv_lst0, valid_cv_acc_id0 = making_ensemble(cv_data[valid_num], result_df0, valid_cv_acc_id)\n",
    "    \n",
    "    result10 = [model_lst[cv_num][10].sess.run(model_lst[cv_num][10].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][10].X : valid_cv_lst0, model_lst[cv_num][10].training :False})][0][:,1]\n",
    "    result10 = list(result10)\n",
    "    \n",
    "    result11 = [model_lst[cv_num][11].sess.run(model_lst[cv_num][11].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][11].X : valid_cv_lst0, model_lst[cv_num][11].training :False})][0][:,1]\n",
    "    result11 = list(result11)\n",
    "    \n",
    "    result12 = [model_lst[cv_num][12].sess.run(model_lst[cv_num][12].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][12].X : valid_cv_lst0, model_lst[cv_num][12].training :False})][0][:,1]\n",
    "    result12 = list(result12)\n",
    "    \n",
    "    result_df10 = pd.DataFrame(result10).rename(columns = {0 : \"label\"})\n",
    "    result_df11 = pd.DataFrame(result11).rename(columns = {0 : \"label\"})\n",
    "    result_df12 = pd.DataFrame(result12).rename(columns = {0 : \"label\"})\n",
    "    \n",
    "    valid_cv_lst12, valid_cv_acc_id12 = making_ensemble(cv_data[valid_num], result_df12, valid_cv_acc_id0)\n",
    "    valid_cv_lst10, valid_cv_acc_id10 = making_ensemble(cv_data[valid_num], result_df10, valid_cv_acc_id0)\n",
    "    valid_cv_lst11, valid_cv_acc_id11 = making_ensemble(cv_data[valid_num], result_df11, valid_cv_acc_id0)\n",
    "    \n",
    "    result13 = [model_lst[cv_num][13].sess.run(model_lst[cv_num][13].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][13].X : valid_cv_lst12, model_lst[cv_num][13].training :False})][0][:,1]\n",
    "    result13 = list(result13)\n",
    "    \n",
    "    result14 = [model_lst[cv_num][14].sess.run(model_lst[cv_num][14].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][14].X : valid_cv_lst10, model_lst[cv_num][14].training :False})][0][:,1]\n",
    "    result14 = list( result14)\n",
    "    \n",
    "    result15 = [model_lst[cv_num][15].sess.run(model_lst[cv_num][15].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][15].X : valid_cv_lst11, model_lst[cv_num][15].training :False})][0][:,1]\n",
    "    result15 = list(result15)\n",
    "    \n",
    "    result_df13 = pd.DataFrame(result13).rename(columns = {0 : \"label\"})\n",
    "    result_df14 = pd.DataFrame(result14).rename(columns = {0 : \"label\"})\n",
    "    result_df15 = pd.DataFrame(result15).rename(columns = {0 : \"label\"})\n",
    "    \n",
    "    \n",
    "    # 모든 label 예측\n",
    "    result16 = [model_lst[cv_num][16].sess.run(model_lst[cv_num][16].softmax, \n",
    "                                             feed_dict = {model_lst[cv_num][16].X : valid_cv_lst, model_lst[cv_num][16].training :False})][0][:,:]\n",
    "    result16 = list(result16)\n",
    "    \n",
    "    result_df16 = pd.DataFrame(result16).rename(columns = {0 : \"total_week\", 1: \"total_month\", 2:\"total_2month\", 3:\"total_retained\"})\n",
    "    \n",
    "    result_stack_df = pd.concat([making_df(result_df0, valid_cv_acc_id).set_index(\"acc_id\").rename(columns={\"label\" : \"week-tree\"}), \n",
    "                                 making_df(result_df1, valid_cv_acc_id).set_index(\"acc_id\").rename(columns={\"label\" : \"month-tree\"}), \n",
    "                                 making_df(result_df2, valid_cv_acc_id).set_index(\"acc_id\").rename(columns={\"label\" : \"2month-tree\"}), \n",
    "                                 making_df(result_df3, valid_cv_acc_id).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-tree\"}), \n",
    "                                 making_df(result_df4, valid_cv_acc_id3).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-week-tree\"}), \n",
    "                                 making_df(result_df5, valid_cv_acc_id3).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-month-tree\"}), \n",
    "                                 making_df(result_df6, valid_cv_acc_id3).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-2month-tree\"}), \n",
    "                                 making_df(result_df7, valid_cv_acc_id6).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-2month-week_month-tree\"}), \n",
    "                                 making_df(result_df8, valid_cv_acc_id4).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-week-month_2month-tree\"}),\n",
    "                                 making_df(result_df9, valid_cv_acc_id5).set_index(\"acc_id\").rename(columns={\"label\" : \"retained-month-week_2month-tree\"}),\n",
    "                                 making_df(result_df10, valid_cv_acc_id0).set_index(\"acc_id\").rename(columns={\"label\" : \"week-month-tree\"}), \n",
    "                                 making_df(result_df11, valid_cv_acc_id0).set_index(\"acc_id\").rename(columns={\"label\" : \"week-2month-tree\"}), \n",
    "                                 making_df(result_df12, valid_cv_acc_id0).set_index(\"acc_id\").rename(columns={\"label\" : \"week-retained-tree\"}), \n",
    "                                 making_df(result_df13, valid_cv_acc_id12).set_index(\"acc_id\").rename(columns={\"label\" : \"week-retained-month_2month-tree\"}), \n",
    "                                 making_df(result_df14, valid_cv_acc_id10).set_index(\"acc_id\").rename(columns={\"label\" : \"week-month-2month_retained-tree\"}),\n",
    "                                 making_df(result_df15, valid_cv_acc_id11).set_index(\"acc_id\").rename(columns={\"label\" : \"week-2month-month_retained-tree\"}),\n",
    "                                 making_df(result_df16, valid_cv_acc_id).set_index(\"acc_id\").rename(columns={\"label\" : \"total\"})], axis=1)\n",
    "    \n",
    "    result_df_lst.append(result_stack_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_stack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_stack_df.to_csv(\"final_result/test_250_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
