{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_csv(\"final_result/valid_250_epoch.csv\").rename(columns = {\"Unnamed: 0\" : \"acc_id\"}).fillna(0)\n",
    "\n",
    "print(len(valid))\n",
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"final_result/test_250_epoch.csv\").rename(columns = {\"Unnamed: 0\" : \"acc_id\"}).fillna(0)\n",
    "\n",
    "print(len(test))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  ['week-tree', 'total_week', 'retained-week-tree',\n",
    "             'month-tree', \"total_month\", 'retained-month-tree', 'retained-2month-week_month-tree', 'week-month-tree',\n",
    "             '2month-tree', \"total_2month\", 'retained-2month-tree', 'retained-week-month_2month-tree', 'retained-month-week_2month-tree', 'week-2month-tree', 'week-retained-month_2month-tree', \n",
    "             'retained-tree', \"total_retained\",'week-retained-tree', 'week-month-2month_retained-tree', 'week-2month-month_retained-tree']\n",
    "\n",
    "target = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "valid F1 score : 0.835019533206\n",
    "valid F1 score : 0.511169513798\n",
    "valid F1 score : 0.624146637987\n",
    "valid F1 score : 0.759031198686\n",
    "valid F1 score : 0.857057237039\n",
    "valid F1 score : 0.559139784946\n",
    "valid F1 score : 0.721834139352\n",
    "valid F1 score : 0.882810071495\n",
    "valid F1 score : 0.74330571304\n",
    "valid F1 score : 0.930932160033\n",
    "valid F1 score : 0.604991177212\n",
    "valid F1 score : 0.628211250119\n",
    "valid F1 score : 0.776022020593\n",
    "valid F1 score : 0.747978788142\n",
    "valid F1 score : 0.829327654396\n",
    "valid F1 score : 0.873835053613\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1_score(solution, submission):\n",
    "    a=pd.DataFrame(submission,columns=['Y_hat'])\n",
    "    b=pd.DataFrame(solution.tolist(),columns=['Y'])\n",
    "    c=pd.concat([a,b],axis=1)\n",
    "    \n",
    "    tot_table=c.groupby(['Y','Y_hat']).Y_hat.count().unstack()\n",
    "    accuracy=np.sum(np.diag(np.array(tot_table)))/len(c)\n",
    "     \n",
    "    f1_score=1/(np.mean(np.concatenate([1/np.diag(tot_table/tot_table.sum(axis=0)),1/np.diag(tot_table/tot_table.sum(axis=1))])))\n",
    "    print('final accuracy:%s'%(accuracy))    \n",
    "    print('final_f1_score:%s'%(f1_score))   \n",
    "    print()\n",
    "    \n",
    "    return f1_score \n",
    "\n",
    "my_scorer = make_scorer(my_f1_score, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 16000\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=200)\n",
    "xgb_grid = GridSearchCV(xgb, param_grid={}, scoring=my_scorer, cv=5, verbose=1)\n",
    "\n",
    "xgb_grid.fit(valid[:idx][features], valid[:idx][target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1_score2(solution, submission):\n",
    "    a=pd.DataFrame(submission,columns=['Y_hat'])\n",
    "    b=pd.DataFrame(solution,columns=['Y'])\n",
    "    c=pd.concat([a,b],axis=1)\n",
    "    \n",
    "    tot_table=c.groupby(['Y','Y_hat']).Y_hat.count().unstack()\n",
    "    accuracy=np.sum(np.diag(np.array(tot_table)))/len(c)\n",
    "     \n",
    "    f1_score=1/(np.mean(np.concatenate([1/np.diag(tot_table/tot_table.sum(axis=0)),1/np.diag(tot_table/tot_table.sum(axis=1))])))\n",
    "    return f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values = valid[features].values\n",
    "max_score = 0\n",
    "\n",
    "for idx0 in range(1,6) :\n",
    "    temp = 500-idx0\n",
    "    print()\n",
    "    print(\"----\",idx0,\"----\")\n",
    "    \n",
    "    for idx1 in range(1,6) :\n",
    "        temp -= idx1\n",
    "        \n",
    "        for idx2 in range(3) :\n",
    "            temp -= idx2\n",
    "            \n",
    "            for idx3 in range(1,6) :\n",
    "                temp -= idx3\n",
    "                \n",
    "                for idx4 in range(1,6) :\n",
    "                    temp -= idx4\n",
    "                    \n",
    "                    for idx5 in range(3) :\n",
    "                        temp -= idx5\n",
    "                        \n",
    "                        for idx6 in range(3) :\n",
    "                            temp -= idx6\n",
    "                            \n",
    "                            for idx7 in range(3) :\n",
    "                                temp -= idx7\n",
    "                                \n",
    "                                for idx8 in range(1,6) :\n",
    "                                    temp -= idx8\n",
    "                                    \n",
    "                                    for idx9 in range(1,6) :\n",
    "                                        temp -= idx9\n",
    "                                        \n",
    "                                        for idx10 in range(3) :\n",
    "                                            temp -= idx10\n",
    "                                            \n",
    "                                            for idx11 in range(3) :\n",
    "                                                temp -= idx11\n",
    "                                                \n",
    "                                                for idx12 in range(3) :\n",
    "                                                    temp -= idx12\n",
    "                                                    \n",
    "                                                    for idx13 in range(3) :\n",
    "                                                        temp -= idx13\n",
    "                                                        \n",
    "                                                        for idx14 in range(3) :\n",
    "                                                            temp -= idx14\n",
    "                                                            \n",
    "                                                            for idx15 in range(1,6) :\n",
    "                                                                temp -= idx15\n",
    "                                                                \n",
    "                                                                for idx16 in range(1,6) :\n",
    "                                                                    temp -= idx16\n",
    "                                                                    \n",
    "                                                                    for idx17 in range(3) :\n",
    "                                                                        temp -= idx17\n",
    "                                                                        \n",
    "                                                                        for idx18 in range(3) :\n",
    "                                                                            temp -= idx18\n",
    "                                                                            \n",
    "                                                                            for idx19 in range(3) :\n",
    "                                                                                week_1 = values[:,[0,1,2]]\n",
    "                                                                                week_2 = 1-values[:,[3,4,5,6,8,9,10,12,15,16]]\n",
    "                                                                                week_weight_1 = np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [0,1,2]])\n",
    "                                                                                week_weight_2 = np.array([6,6,3,3,6,6,3,3,6,6])-np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [3,4,5,6,8,9,10,12,15,16]])\n",
    "                                                                                \n",
    "                                                                                month_1 = values[:,[3,4,5,6,7]]\n",
    "                                                                                month_2 = 1-values[:,[0,1,2,8,9,10,11,13,14,15,16,17,19]]\n",
    "                                                                                month_weight_1 = np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [3,4,5,6,7]])\n",
    "                                                                                month_weight_2 = np.array([3,3,3,6,6,3,3,3,3,6,6,3,3])-np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [0,1,2,8,9,10,11,13,14,15,16,17,19]])\n",
    "                                                                                \n",
    "                                                                                month2_1 = values[:,[8,9,10,11,12,13,14]]\n",
    "                                                                                month2_2 = 1-values[:,[0,1,2,3,4,5,7,15,16,17,18]]\n",
    "                                                                                month2_weight_1 = np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [8,9,10,11,12,13,14]])\n",
    "                                                                                month2_weight_2 = np.array([6,6,3,6,6,3,3,6,6,3,3])-np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [0,1,2,3,4,5,7,15,16,17,18]])\n",
    "                                                                                \n",
    "                                                                                retained_1 = values[:,[15,16,17,18,19]]\n",
    "                                                                                retained_2 = 1-values[:,[0,1,3,4,7,8,9,13]]\n",
    "                                                                                retained_weight_1 = np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [15,16,17,18,19]])\n",
    "                                                                                retained_weight_2 = np.array([6,6,3,3,3,6,6,3])-np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [0,1,3,4,7,8,9,13]])\n",
    "                                                                                \n",
    "                                                                                week = (np.sum(week_1*week_weight_1, axis=1) + np.sum(week_2*week_weight_2, axis=1)) / (np.sum(week_weight_1) + np.sum(week_weight_2))\n",
    "                                                                                month = (np.sum(month_1*month_weight_1, axis=1) + np.sum(month_2*month_weight_2, axis=1)) / (np.sum(month_weight_1) + np.sum(month_weight_2))\n",
    "                                                                                month2 = (np.sum(month2_1*month2_weight_1, axis=1) + np.sum(month2_2*month2_weight_2, axis=1)) / (np.sum(month2_weight_1) + np.sum(month2_weight_2))\n",
    "                                                                                retained = (np.sum(retained_1*retained_weight_1, axis=1) + np.sum(retained_2*retained_weight_2, axis=1)) / (np.sum(retained_weight_1) + np.sum(retained_weight_2))\n",
    "                                                                                \n",
    "                                                                                result = np.concatenate([week.reshape([-1,1]), month.reshape([-1,1]), month2.reshape([-1,1]), retained.reshape([-1,1])], axis=1)\n",
    "                                                                                result_label = np.argmax(result, axis=1)\n",
    "                                                                                \n",
    "                                                                                score = my_f1_score2(result_label,valid[target].tolist())\n",
    "                                                                                \n",
    "                                                                                if score > max_score :\n",
    "                                                                                    max_score = score\n",
    "                                                                                    max_weight = np.array([eval(\"idx{}\".format(i)) for i in range(20)])\n",
    "                                                                                    print(max_score, max_weight)\n",
    "                                        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(lst, num_class=4) :\n",
    "    return np.eye(num_class)[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1_score2(solution, submission):\n",
    "    a=pd.DataFrame(submission,columns=['Y_hat'])\n",
    "    b=pd.DataFrame(solution,columns=['Y'])\n",
    "    c=pd.concat([a,b],axis=1)\n",
    "    \n",
    "    tot_table=c.groupby(['Y','Y_hat']).Y_hat.count().unstack()\n",
    "    accuracy=np.sum(np.diag(np.array(tot_table)))/len(c)\n",
    "     \n",
    "    f1_score=1/(np.mean(np.concatenate([1/np.diag(tot_table/tot_table.sum(axis=0)),1/np.diag(tot_table/tot_table.sum(axis=1))])))\n",
    "    return f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1_table(solution, submission):\n",
    "    a=pd.DataFrame(submission,columns=['Y_hat'])\n",
    "    b=pd.DataFrame(solution,columns=['Y'])\n",
    "    c=pd.concat([a,b],axis=1)\n",
    "    \n",
    "    tot_table=c.groupby(['Y','Y_hat']).Y_hat.count().unstack()\n",
    "    return tot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weight() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        \n",
    "    def convolution(self, input_X, kernel_size, width, num_filter, activation=True) :\n",
    "        conv = tf.layers.conv2d(input_X, filters=num_filter, kernel_size=[kernel_size, width], strides=1)\n",
    "        \n",
    "        if activation :\n",
    "            norm = tf.contrib.layers.layer_norm(conv)\n",
    "            relu = tf.nn.relu(norm)\n",
    "        \n",
    "            return relu\n",
    "        return conv\n",
    "        \n",
    "    def build(self, batch_size, input_dim, is_fc, fc_num_unit, output_dim) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            ## Setting ##\n",
    "            self.batch_size = batch_size\n",
    "            self.input_dim = input_dim\n",
    "            self.output_dim = output_dim\n",
    "            self.is_fc = is_fc\n",
    "            self.fc_num_unit = fc_num_unit\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, self.input_dim])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, self.output_dim])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            #############\n",
    "\n",
    "            \n",
    "            ## Weight ##\n",
    "            if self.is_fc : \n",
    "                self.fc_weight1 = tf.Variable(tf.random_normal([self.input_dim, self.fc_num_unit]))\n",
    "                self.fc_weight2 = tf.Variable(tf.random_normal([self.fc_num_unit, self.output_dim]))\n",
    "                \n",
    "                self.fc_weighted1 = tf.matmul(self.X, self.fc_weight1)\n",
    "                norm = tf.contrib.layers.layer_norm(self.fc_weighted1)\n",
    "                relu = tf.nn.relu(norm)\n",
    "                self.fc_weighted2 = tf.matmul(relu, self.fc_weight2)\n",
    "                \n",
    "                self.weighted =  self.fc_weighted2\n",
    "                \n",
    "            else :\n",
    "                self.weight = tf.Variable(tf.random_normal([self.input_dim, self.output_dim]))\n",
    "                self.weighted = tf.matmul(self.X, self.weight)\n",
    "            \n",
    "            self.logit = self.weighted\n",
    "            self.softmax = tf.nn.softmax(self.logit)\n",
    "            ################\n",
    "            \n",
    "            \n",
    "            ## Learning ##\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logit, labels=self.Y))\n",
    "\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.RMSPropOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "            \n",
    "            self.prediction = tf.equal(tf.argmax(self.logit, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.prediction, tf.float32))    \n",
    "            ##############\n",
    "        \n",
    "        \n",
    "    def train(self, X_input, Y_input, learning_rate, training=True):\n",
    "        feed_dict = {self.X: X_input, self.Y: Y_input, self.learning_rate: learning_rate, self.training: training}\n",
    "        _, cost = self.sess.run([self.optimizer, self.cost], feed_dict=feed_dict)\n",
    "        \n",
    "        return _, cost\n",
    "    \n",
    "    def predict(self, X_input, training=False):\n",
    "        feed_dict = {self.X: X_input, self.training: training}\n",
    "        result = self.sess.run([self.logit], feed_dict=feed_dict)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input):\n",
    "        size = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for idx in range(0, size, self.batch_size):\n",
    "            X_batch = X_input[idx:idx + batch_size]\n",
    "            Y_batch = Y_input[idx:idx + batch_size]\n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= size\n",
    "        total_acc /= size\n",
    "            \n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate1 = 0.01\n",
    "learning_rate2 = 0.005\n",
    "learning_rate3 = 0.001\n",
    "\n",
    "total_epoch = 40\n",
    "batch_size = 500\n",
    "\n",
    "tl_ta_vl_va_lst = [[[],[],[],[],[]], [[],[],[],[],[]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1 = tf.Session()\n",
    "model1 = Weight(sess1, \"model1\")\n",
    "model1.build(500, 20, True, 32, 4)\n",
    "sess1.run(tf.global_variables_initializer())\n",
    "\n",
    "sess2 = tf.Session()\n",
    "model2 = Weight(sess2, \"model2\")\n",
    "model2.build(500, 20, False, 32, 4)\n",
    "sess2.run(tf.global_variables_initializer())\n",
    "\n",
    "model_lst = [model1, model2]\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 16000\n",
    "\n",
    "training_lst = valid[:idx][features].values\n",
    "valid_lst = valid[idx:][features].values\n",
    "\n",
    "training_label = one_hot(valid[:idx][\"label\"])\n",
    "valid_label = one_hot(valid[idx:][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "# train my model\n",
    "for epoch in range(total_epoch):\n",
    "    avg_cost = [0]*len(model_lst)\n",
    "    total_batch = int(len(training_lst) / batch_size)\n",
    "    idx = 0\n",
    "    \n",
    "    if epoch == 0 :\n",
    "        learning_rate = learning_rate1\n",
    "    elif epoch == 10 :\n",
    "        learning_rate = learning_rate2\n",
    "    elif epoch == 25 :\n",
    "        learning_rate = learning_rate3\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = training_lst[idx:idx+batch_size],training_label[idx:idx+batch_size]\n",
    "        \n",
    "        for model_num, model in enumerate(model_lst) :\n",
    "            _, c = model.train(batch_xs, batch_ys, learning_rate)\n",
    "            avg_cost[model_num] += c / total_batch\n",
    "        \n",
    "        idx += batch_size\n",
    "        if i%10 == 0 :\n",
    "            print(\"log :\", i)\n",
    "            \n",
    "    #train/valid cost & acc\n",
    "    print(\"***epoch*** : \", epoch)\n",
    "    for model_num, model in enumerate(model_lst) :\n",
    "        train_cost, train_acc = model.evaluate(training_lst, training_label)\n",
    "        valid_cost, valid_acc = model.evaluate(valid_lst, valid_label)\n",
    "\n",
    "        tl_ta_vl_va_lst[model_num][0].append(train_cost)\n",
    "        tl_ta_vl_va_lst[model_num][1].append(train_acc)\n",
    "        tl_ta_vl_va_lst[model_num][2].append(valid_cost)\n",
    "        tl_ta_vl_va_lst[model_num][3].append(valid_acc)\n",
    "\n",
    "        print(\"-- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(train_cost, train_acc*100, valid_cost, valid_acc*100))\n",
    "    \n",
    "    for model_num, model in enumerate(model_lst) :\n",
    "        f1_score = my_f1_score2(np.argmax(model.predict(valid_lst)[0], axis=1), np.argmax(valid_label, axis=1))\n",
    "        tl_ta_vl_va_lst[model_num][4].append(f1_score)\n",
    "        print('f1 score:', f1_score)\n",
    "    print(\" \")\n",
    "\n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst)) :\n",
    "    plt.plot(tl_ta_vl_va_lst[idx][4], label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_f1_score2(np.argmax(valid[16000:][[\"total_week\", \"total_month\", \"total_2month\", \"total_retained\"]].values, axis=1), np.argmax(valid_label, axis=1)))\n",
    "my_f1_table(np.argmax(valid[16000:][[\"total_week\", \"total_month\", \"total_2month\", \"total_retained\"]].values, axis=1), np.argmax(valid_label, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_f1_score2(np.argmax(model_lst[0].predict(valid_lst)[0], axis=1), np.argmax(valid_label, axis=1)))\n",
    "my_f1_table(np.argmax(model_lst[0].predict(valid_lst)[0], axis=1), np.argmax(valid_label, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_f1_score2(np.argmax(model_lst[1].predict(valid_lst)[0], axis=1), np.argmax(valid_label, axis=1)))\n",
    "my_f1_table(np.argmax(model_lst[1].predict(valid_lst)[0], axis=1), np.argmax(valid_label, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_lst[0]\n",
    "pred1 = model.sess.run(model.softmax, feed_dict = {model.X : valid_lst, model.training:False})\n",
    "pred1_df = pd.DataFrame(pred1, columns = [\"model0_week\", \"model0_month\", \"model0_2month\", \"model0_retained\"])\n",
    "\n",
    "pred1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_lst[1]\n",
    "pred2 = model.sess.run(model.softmax, feed_dict = {model.X : valid_lst, model.training:False})\n",
    "pred2_df = pd.DataFrame(pred2, columns = [\"model1_week\", \"model1_month\", \"model1_2month\", \"model1_retained\"])\n",
    "\n",
    "pred2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.concat([pred1_df, pred2_df], axis=1)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_weight = []\n",
    "best_f1 = 0\n",
    "\n",
    "for idx0 in range(0, 31)  :\n",
    "    print()\n",
    "    print(\"-------\",idx0,\"-------\")\n",
    "    \n",
    "    for idx1 in range(0, 31)  :\n",
    "        for idx2 in range(0, 31)  :\n",
    "            for idx3 in range(0, 31)  :\n",
    "                pred_df[\"week\"] = (idx0*pred_df[\"model0_week\"] + (30-idx0)*pred_df[\"model1_week\"]) / 30\n",
    "                pred_df[\"month\"] = (idx1*pred_df[\"model0_month\"] + (30-idx1)*pred_df[\"model1_month\"]) / 30\n",
    "                pred_df[\"2month\"] = (idx2*pred_df[\"model0_2month\"] + (30-idx2)*pred_df[\"model1_2month\"]) / 30\n",
    "                pred_df[\"retained\"] = (idx3*pred_df[\"model0_retained\"] + (30-idx3)*pred_df[\"model1_retained\"]) / 30\n",
    "                \n",
    "                f1 = my_f1_score2(np.argmax(pred_df[[\"week\", \"month\", \"2month\", \"retained\"]].values, axis=1), np.argmax(valid_label, axis=1))\n",
    "                if f1 > best_f1 :\n",
    "                    best_f1 = f1\n",
    "                    best_weight = [idx0, idx1, idx2, idx3]\n",
    "                    print(best_f1, best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
