{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = pd.read_csv(\"user_vector.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "label = pd.read_csv(\"train_label.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label = label.sort_values(\"acc_id\")\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_lst = [int(x) for x in label.acc_id.tolist()]\n",
    "print(len(id_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_dic = {}\n",
    "for user in id_lst :\n",
    "    activity_dic[user] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(activity.head().values[0]))\n",
    "activity.head().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in activity.values :\n",
    "    activity_dic[int(data[0])].append([int(data[1])]+list(data[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_lst = [list(y) for y in activity_dic.items()]\n",
    "activity_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "day_1_lst = [x for x in activity_lst if x[1][0][0]==1]\n",
    "day_2_lst = [x for x in activity_lst if x[1][0][0]==2]\n",
    "day_3_lst = [x for x in activity_lst if x[1][0][0]==3]\n",
    "day_4_lst = [x for x in activity_lst if x[1][0][0]==4]\n",
    "day_5_lst = [x for x in activity_lst if x[1][0][0]==5]\n",
    "day_6_lst = [x for x in activity_lst if x[1][0][0]==6]\n",
    "day_7_lst = [x for x in activity_lst if x[1][0][0]==7]\n",
    "day_8_lst = [x for x in activity_lst if x[1][0][0]==8]\n",
    "\n",
    "print(len(day_1_lst))\n",
    "print(len(day_2_lst))\n",
    "print(len(day_3_lst))\n",
    "print(len(day_4_lst))\n",
    "print(len(day_5_lst))\n",
    "print(len(day_6_lst))\n",
    "print(len(day_7_lst))\n",
    "print(len(day_8_lst))\n",
    "\n",
    "print(\"\")\n",
    "print(len(day_1_lst)+len(day_2_lst)+len(day_3_lst)+len(day_4_lst)+len(day_5_lst)+len(day_6_lst)+len(day_7_lst)+len(day_8_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_1_dic = {}\n",
    "day_2_dic = {}\n",
    "day_3_dic = {}\n",
    "day_4_dic = {}\n",
    "day_5_dic = {}\n",
    "day_6_dic = {}\n",
    "day_7_dic = {}\n",
    "day_8_dic = {}\n",
    "\n",
    "day_1_id_lst = [x[0] for x in day_1_lst]\n",
    "day_2_id_lst = [x[0] for x in day_2_lst]\n",
    "day_3_id_lst = [x[0] for x in day_3_lst]\n",
    "day_4_id_lst = [x[0] for x in day_4_lst]\n",
    "day_5_id_lst = [x[0] for x in day_5_lst]\n",
    "day_6_id_lst = [x[0] for x in day_6_lst]\n",
    "day_7_id_lst = [x[0] for x in day_7_lst]\n",
    "day_8_id_lst = [x[0] for x in day_8_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = [1] + [0]*52\n",
    "EMPTY_TOKEN = [0,1] + [0]*51\n",
    "END_TOKEN = [0,0,1] + [0]*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in day_1_id_lst :\n",
    "    #day_1_dic[(user, 0)] = START_TOKEN\n",
    "    day_1_dic[(user, 1)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 2)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 3)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 4)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 5)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_2_id_lst :\n",
    "    #day_2_dic[(user, 0)] = START_TOKEN\n",
    "    day_2_dic[(user, 2)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 3)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 4)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 5)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 9)] = END_TOKEN   \n",
    "    \n",
    "for user in day_3_id_lst :\n",
    "    #day_3_dic[(user, 0)] = START_TOKEN\n",
    "    day_3_dic[(user, 3)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 4)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 5)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_4_id_lst :\n",
    "    #day_4_dic[(user, 0)] = START_TOKEN\n",
    "    day_4_dic[(user, 4)] = EMPTY_TOKEN\n",
    "    day_4_dic[(user, 5)] = EMPTY_TOKEN\n",
    "    day_4_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_4_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_4_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_4_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_5_id_lst :\n",
    "    #day_5_dic[(user, 0)] = START_TOKEN\n",
    "    day_5_dic[(user, 5)] = EMPTY_TOKEN\n",
    "    day_5_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_5_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_5_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_5_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_6_id_lst :\n",
    "    #day_6_dic[(user, 0)] = START_TOKEN\n",
    "    day_6_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_6_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_6_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_6_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_7_id_lst :\n",
    "    #day_7_dic[(user, 0)] = START_TOKEN\n",
    "    day_7_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_7_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_7_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_8_id_lst :\n",
    "    #day_8_dic[(user, 0)] = START_TOKEN\n",
    "    day_8_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    #day_8_dic[(user, 9)] = END_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in day_1_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_1_dic[(user, week)] = data2[1:]\n",
    "\n",
    "for data in day_2_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_2_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_3_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_3_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_4_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_4_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_5_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_5_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_6_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_6_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_7_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_7_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_8_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_8_dic[(user, week)] = data2[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dic = {\"week\":0 , \"month\" :1, \"2month\":2, \"retained\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2 = label.sort_values(by=\"acc_id\")\n",
    "label2[\"label\"] = label2[\"label\"].map(lambda x : label_dic[x])\n",
    "\n",
    "label2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(lst, num_class=4) :\n",
    "    return np.eye(num_class)[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_1_total_lst = []\n",
    "day_2_total_lst = []\n",
    "day_3_total_lst = []\n",
    "day_4_total_lst = []\n",
    "day_5_total_lst = []\n",
    "day_6_total_lst = []\n",
    "day_7_total_lst = []\n",
    "day_8_total_lst = []\n",
    "\n",
    "temp1 = list(day_1_dic.values())\n",
    "temp2 = list(day_2_dic.values())\n",
    "temp3 = list(day_3_dic.values())\n",
    "temp4 = list(day_4_dic.values())\n",
    "temp5 = list(day_5_dic.values())\n",
    "temp6 = list(day_6_dic.values())\n",
    "temp7 = list(day_7_dic.values())\n",
    "temp8 = list(day_8_dic.values())\n",
    "\n",
    "last1=0\n",
    "last2=0\n",
    "last3=0\n",
    "last4=0\n",
    "last5=0\n",
    "last6=0\n",
    "last7=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for now in range(0,len(temp1)+1,9) :\n",
    "    if now == 0 :\n",
    "        last1 = now\n",
    "        continue\n",
    "    \n",
    "    day_1_total_lst.append(temp1[last1:now])\n",
    "    last1=now\n",
    "    \n",
    "for now in range(0,len(temp2)+1,8) :\n",
    "    if now == 0 :\n",
    "        last2 = now\n",
    "        continue\n",
    "    \n",
    "    day_2_total_lst.append(temp2[last2:now])\n",
    "    last2=now\n",
    "    \n",
    "for now in range(0,len(temp3)+1,7) :\n",
    "    if now == 0 :\n",
    "        last3 = now\n",
    "        continue\n",
    "    \n",
    "    day_3_total_lst.append(temp3[last3:now])\n",
    "    last3=now\n",
    "    \n",
    "for now in range(0,len(temp4)+1,6) :\n",
    "    if now == 0 :\n",
    "        last4 = now\n",
    "        continue\n",
    "    \n",
    "    day_4_total_lst.append(temp4[last4:now])\n",
    "    last4=now\n",
    "    \n",
    "for now in range(0,len(temp5)+1,5) :\n",
    "    if now == 0 :\n",
    "        last5 = now\n",
    "        continue\n",
    "    \n",
    "    day_5_total_lst.append(temp5[last5:now])\n",
    "    last5=now\n",
    "    \n",
    "for now in range(0,len(temp6)+1,4) :\n",
    "    if now == 0 :\n",
    "        last6 = now\n",
    "        continue\n",
    "    \n",
    "    day_6_total_lst.append(temp6[last6:now])\n",
    "    last6=now\n",
    "    \n",
    "for now in range(0,len(temp7)+1,3) :\n",
    "    if now == 0 :\n",
    "        last7 = now\n",
    "        continue\n",
    "    \n",
    "    day_7_total_lst.append(temp7[last7:now])\n",
    "    last7=now\n",
    "\n",
    "day_8_total_lst = np.array(temp8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(day_1_total_lst))\n",
    "print(len(day_2_total_lst))\n",
    "print(len(day_3_total_lst))\n",
    "print(len(day_4_total_lst))\n",
    "print(len(day_5_total_lst))\n",
    "print(len(day_6_total_lst))\n",
    "print(len(day_7_total_lst))\n",
    "print(len(day_8_total_lst))\n",
    "\n",
    "print(\"\")\n",
    "print(len(day_1_total_lst) + len(day_2_total_lst) + len(day_3_total_lst) + len(day_4_total_lst) \\\n",
    "      + len(day_5_total_lst) + len(day_6_total_lst) + len(day_7_total_lst) + len(day_8_total_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dic = label2.set_index(\"acc_id\").to_dict()['label']\n",
    "print(len(label_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_1_total_label = one_hot([label_dic[x] for x in day_1_id_lst])\n",
    "day_2_total_label = one_hot([label_dic[x] for x in day_2_id_lst])\n",
    "day_3_total_label = one_hot([label_dic[x] for x in day_3_id_lst])\n",
    "day_4_total_label = one_hot([label_dic[x] for x in day_4_id_lst])\n",
    "day_5_total_label = one_hot([label_dic[x] for x in day_5_id_lst])\n",
    "day_6_total_label = one_hot([label_dic[x] for x in day_6_id_lst])\n",
    "day_7_total_label = one_hot([label_dic[x] for x in day_7_id_lst])\n",
    "day_8_total_label = one_hot([label_dic[x] for x in day_8_id_lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(day_1_total_label))\n",
    "print(len(day_2_total_label))\n",
    "print(len(day_3_total_label))\n",
    "print(len(day_4_total_label))\n",
    "print(len(day_5_total_label))\n",
    "print(len(day_6_total_label))\n",
    "print(len(day_7_total_label))\n",
    "print(len(day_8_total_label))\n",
    "\n",
    "print(\"\")\n",
    "print(len(day_1_total_label) + len(day_2_total_label) + len(day_3_total_label) + len(day_4_total_label) \\\n",
    "      + len(day_5_total_label) + len(day_6_total_label) + len(day_7_total_label) + len(day_8_total_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = len(day_1_total_lst)//6 *4\n",
    "idx2 = len(day_1_total_lst)//6 *5\n",
    "\n",
    "day_1_training_lst = np.array(day_1_total_lst[:idx1])\n",
    "day_1_valid_lst = np.array(day_1_total_lst[idx1:idx2])\n",
    "day_1_test_lst = np.array(day_1_total_lst[idx2:])\n",
    "\n",
    "day_1_training_label = np.array(day_1_total_label[:idx1])\n",
    "day_1_valid_label = np.array(day_1_total_label[idx1:idx2])\n",
    "day_1_test_label = np.array(day_1_total_label[idx2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = len(day_2_total_lst)//6 *4\n",
    "idx2 = len(day_2_total_lst)//6 *5\n",
    "\n",
    "day_2_training_lst = np.array(day_2_total_lst[:idx1])\n",
    "day_2_valid_lst = np.array(day_2_total_lst[idx1:idx2])\n",
    "day_2_test_lst = np.array(day_2_total_lst[idx2:])\n",
    "\n",
    "day_2_training_label = np.array(day_2_total_label[:idx1])\n",
    "day_2_valid_label = np.array(day_2_total_label[idx1:idx2])\n",
    "day_2_test_label = np.array(day_2_total_label[idx2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = len(day_3_total_lst)//6 *4\n",
    "idx2 = len(day_3_total_lst)//6 *5\n",
    "\n",
    "day_3_training_lst = np.array(day_3_total_lst[:idx1])\n",
    "day_3_valid_lst = np.array(day_3_total_lst[idx1:idx2])\n",
    "day_3_test_lst = np.array(day_3_total_lst[idx2:])\n",
    "\n",
    "day_3_training_label = np.array(day_3_total_label[:idx1])\n",
    "day_3_valid_label = np.array(day_3_total_label[idx1:idx2])\n",
    "day_3_test_label = np.array(day_3_total_label[idx2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = len(day_4_total_lst)//6 *4\n",
    "idx2 = len(day_4_total_lst)//6 *5\n",
    "\n",
    "day_4_training_lst = np.array(day_4_total_lst[:idx1])\n",
    "day_4_valid_lst = np.array(day_4_total_lst[idx1:idx2])\n",
    "day_4_test_lst = np.array(day_4_total_lst[idx2:])\n",
    "\n",
    "day_4_training_label = np.array(day_4_total_label[:idx1])\n",
    "day_4_valid_label = np.array(day_4_total_label[idx1:idx2])\n",
    "day_4_test_label = np.array(day_4_total_label[idx2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = len(day_5_total_lst)//6 *4\n",
    "idx2 = len(day_5_total_lst)//6 *5\n",
    "\n",
    "day_5_training_lst = np.array(day_5_total_lst[:idx1])\n",
    "day_5_valid_lst = np.array(day_5_total_lst[idx1:idx2])\n",
    "day_5_test_lst = np.array(day_5_total_lst[idx2:])\n",
    "\n",
    "day_5_training_label = np.array(day_5_total_label[:idx1])\n",
    "day_5_valid_label = np.array(day_5_total_label[idx1:idx2])\n",
    "day_5_test_label = np.array(day_5_total_label[idx2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = len(day_6_total_lst)//6 *4\n",
    "idx2 = len(day_6_total_lst)//6 *5\n",
    "\n",
    "day_6_training_lst = np.array(day_6_total_lst[:idx1])\n",
    "day_6_valid_lst = np.array(day_6_total_lst[idx1:idx2])\n",
    "day_6_test_lst = np.array(day_6_total_lst[idx2:])\n",
    "\n",
    "day_6_training_label = np.array(day_6_total_label[:idx1])\n",
    "day_6_valid_label = np.array(day_6_total_label[idx1:idx2])\n",
    "day_6_test_label = np.array(day_6_total_label[idx2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = len(day_7_total_lst)//6 *4\n",
    "idx2 = len(day_7_total_lst)//6 *5\n",
    "\n",
    "day_7_training_lst = np.array(day_7_total_lst[:idx1])\n",
    "day_7_valid_lst = np.array(day_7_total_lst[idx1:idx2])\n",
    "day_7_test_lst = np.array(day_7_total_lst[idx2:])\n",
    "\n",
    "day_7_training_label = np.array(day_7_total_label[:idx1])\n",
    "day_7_valid_label = np.array(day_7_total_label[idx1:idx2])\n",
    "day_7_test_label = np.array(day_7_total_label[idx2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = len(day_8_total_lst)//6 *4\n",
    "idx2 = len(day_8_total_lst)//6 *5\n",
    "\n",
    "day_8_training_lst = np.array(day_8_total_lst[:idx1])\n",
    "day_8_valid_lst = np.array(day_8_total_lst[idx1:idx2])\n",
    "day_8_test_lst = np.array(day_8_total_lst[idx2:])\n",
    "\n",
    "day_8_training_label = np.array(day_8_total_label[:idx1])\n",
    "day_8_valid_label = np.array(day_8_total_label[idx1:idx2])\n",
    "day_8_test_label = np.array(day_8_total_label[idx2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 53\n",
    "input_class = 4\n",
    "hidden_layer1 = 128\n",
    "hidden_layer2 = 256\n",
    "hidden_layer3 = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "  \n",
    "    def build(self, input_length) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, input_length, input_size])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, input_class])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            \n",
    "            cell1 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer1)\n",
    "            dropout1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "            cell2 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer1)\n",
    "            multi_cell = tf.nn.rnn_cell.MultiRNNCell([dropout1, cell2])\n",
    "            \n",
    "            output, state = tf.nn.dynamic_rnn(multi_cell, self.X, dtype=tf.float32)\n",
    "            output = tf.transpose(output,[1,0,2])[-1]\n",
    "            \n",
    "            dense1= tf.layers.dense(inputs=output, units=hidden_layer2, activation=tf.nn.relu)\n",
    "            dropout = tf.layers.dropout(dense1)\n",
    "            dense2 = tf.layers.dense(inputs=dropout, units=input_class)\n",
    "            self.logits = dense2\n",
    "\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            \n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, X_input, training=False):\n",
    "        return self.sess.run(self.logits,feed_dict={self.X: X_input, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, X_input, Y_input, training=False):\n",
    "        return self.sess.run(self.accuracy,feed_dict={self.X: X_input,self.Y: Y_input, self.training: training})\n",
    "\n",
    "    def train(self, X_input, Y_input, learning_rate,training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.X: X_input, self.Y: Y_input, self.learning_rate:learning_rate,self.training: training})\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input, batch_size):\n",
    "        N = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for i in range(0, N, batch_size):\n",
    "            X_batch = X_input[i:i + batch_size]\n",
    "            Y_batch = Y_input[i:i + batch_size]\n",
    "                \n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= N\n",
    "        total_acc /= N\n",
    "            \n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "  \n",
    "    def build(self, input_length) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, input_length, input_size])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, input_class])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            \n",
    "            cell1 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer2)\n",
    "            dropout1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "            cell2 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer2)\n",
    "            multi_cell = tf.nn.rnn_cell.MultiRNNCell([dropout1, cell2])\n",
    "            \n",
    "            output, state = tf.nn.dynamic_rnn(multi_cell, self.X, dtype=tf.float32)\n",
    "            output = tf.transpose(output,[1,0,2])[-1]\n",
    "            \n",
    "            dense1= tf.layers.dense(inputs=output, units=hidden_layer3, activation=tf.nn.relu)\n",
    "            dropout = tf.layers.dropout(dense1)\n",
    "            dense2 = tf.layers.dense(inputs=dropout, units=input_class)\n",
    "            self.logits = dense2\n",
    "\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            \n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, X_input, training=False):\n",
    "        return self.sess.run(self.logits,feed_dict={self.X: X_input, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, X_input, Y_input, training=False):\n",
    "        return self.sess.run(self.accuracy,feed_dict={self.X: X_input,self.Y: Y_input, self.training: training})\n",
    "\n",
    "    def train(self, X_input, Y_input, learning_rate,training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.X: X_input, self.Y: Y_input, self.learning_rate:learning_rate,self.training: training})\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input, batch_size):\n",
    "        N = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for i in range(0, N, batch_size):\n",
    "            X_batch = X_input[i:i + batch_size]\n",
    "            Y_batch = Y_input[i:i + batch_size]\n",
    "                \n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= N\n",
    "        total_acc /= N\n",
    "            \n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "  \n",
    "    def build(self, input_length) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, input_length, input_size])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, input_class])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            \n",
    "            cell1 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer1)\n",
    "            dropout1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "            cell2 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer1)\n",
    "            dropout2 = tf.nn.rnn_cell.DropoutWrapper(cell2, output_keep_prob=0.5)\n",
    "            cell3 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer1)\n",
    "            \n",
    "            multi_cell = tf.nn.rnn_cell.MultiRNNCell([dropout1, dropout2, cell3])\n",
    "            \n",
    "            output, state = tf.nn.dynamic_rnn(multi_cell, self.X, dtype=tf.float32)\n",
    "            output = tf.transpose(output,[1,0,2])[-1]\n",
    "            \n",
    "            dense1= tf.layers.dense(inputs=output, units=hidden_layer2, activation=tf.nn.relu)\n",
    "            dropout = tf.layers.dropout(dense1)\n",
    "            dense2 = tf.layers.dense(inputs=dropout, units=input_class)\n",
    "            self.logits = dense2\n",
    "\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            \n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, X_input, training=False):\n",
    "        return self.sess.run(self.logits,feed_dict={self.X: X_input, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, X_input, Y_input, training=False):\n",
    "        return self.sess.run(self.accuracy,feed_dict={self.X: X_input,self.Y: Y_input, self.training: training})\n",
    "\n",
    "    def train(self, X_input, Y_input, learning_rate,training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.X: X_input, self.Y: Y_input, self.learning_rate:learning_rate,self.training: training})\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input, batch_size):\n",
    "        N = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for i in range(0, N, batch_size):\n",
    "            X_batch = X_input[i:i + batch_size]\n",
    "            Y_batch = Y_input[i:i + batch_size]\n",
    "                \n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= N\n",
    "        total_acc /= N\n",
    "            \n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model4() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "  \n",
    "    def build(self, input_length) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, input_length, input_size])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, input_class])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            \n",
    "            cell1 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer2)\n",
    "            dropout1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "            cell2 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer2)\n",
    "            dropout2 = tf.nn.rnn_cell.DropoutWrapper(cell2, output_keep_prob=0.5)\n",
    "            cell3 = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer2)\n",
    "            \n",
    "            multi_cell = tf.nn.rnn_cell.MultiRNNCell([dropout1, dropout2, cell3])\n",
    "            \n",
    "            output, state = tf.nn.dynamic_rnn(multi_cell, self.X, dtype=tf.float32)\n",
    "            output = tf.transpose(output,[1,0,2])[-1]\n",
    "            \n",
    "            dense1= tf.layers.dense(inputs=output, units=hidden_layer3, activation=tf.nn.relu)\n",
    "            dropout = tf.layers.dropout(dense1)\n",
    "            dense2 = tf.layers.dense(inputs=dropout, units=input_class)\n",
    "            self.logits = dense2\n",
    "\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            \n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, X_input, training=False):\n",
    "        return self.sess.run(self.logits,feed_dict={self.X: X_input, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, X_input, Y_input, training=False):\n",
    "        return self.sess.run(self.accuracy,feed_dict={self.X: X_input,self.Y: Y_input, self.training: training})\n",
    "\n",
    "    def train(self, X_input, Y_input, learning_rate,training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.X: X_input, self.Y: Y_input, self.learning_rate:learning_rate,self.training: training})\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input, batch_size):\n",
    "        N = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for i in range(0, N, batch_size):\n",
    "            X_batch = X_input[i:i + batch_size]\n",
    "            Y_batch = Y_input[i:i + batch_size]\n",
    "                \n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= N\n",
    "        total_acc /= N\n",
    "            \n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model5() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "  \n",
    "    def build(self, input_length=1) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, input_size])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, input_class])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "                  \n",
    "            dense1= tf.layers.dense(inputs=self.X, units=hidden_layer1, activation=tf.nn.relu)\n",
    "            dropout1 = tf.layers.dropout(dense1)\n",
    "            \n",
    "            dense2= tf.layers.dense(inputs=dropout1, units=hidden_layer1, activation=tf.nn.relu)\n",
    "            dropout2 = tf.layers.dropout(dense2)\n",
    "            \n",
    "            dense3= tf.layers.dense(inputs=dropout2, units=hidden_layer2, activation=tf.nn.relu)\n",
    "            dropout3 = tf.layers.dropout(dense3)\n",
    "            \n",
    "            dense4= tf.layers.dense(inputs=dropout3, units=hidden_layer1, activation=tf.nn.relu)\n",
    "            dropout4 = tf.layers.dropout(dense4)\n",
    "            \n",
    "            dense5 = tf.layers.dense(inputs=dropout4, units=input_class)\n",
    "            self.logits = dense5\n",
    "\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            \n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, X_input, training=False):\n",
    "        return self.sess.run(self.logits,feed_dict={self.X: X_input, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, X_input, Y_input, training=False):\n",
    "        return self.sess.run(self.accuracy,feed_dict={self.X: X_input,self.Y: Y_input, self.training: training})\n",
    "\n",
    "    def train(self, X_input, Y_input, learning_rate,training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.X: X_input, self.Y: Y_input, self.learning_rate:learning_rate,self.training: training})\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input, batch_size):\n",
    "        N = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for i in range(0, N, batch_size):\n",
    "            X_batch = X_input[i:i + batch_size]\n",
    "            Y_batch = Y_input[i:i + batch_size]\n",
    "                \n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= N\n",
    "        total_acc /= N\n",
    "            \n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate1 = 0.01\n",
    "learning_rate2 = 0.008\n",
    "learning_rate3 = 0.005\n",
    "learning_rate4 = 0.002\n",
    "\n",
    "total_epoch = 100\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_1_train_losses1 = []\n",
    "day_1_train_accs1 = []\n",
    "day_1_valid_losses1 = []\n",
    "day_1_valid_accs1 = []\n",
    "\n",
    "day_1_train_losses2 = []\n",
    "day_1_train_accs2 = []\n",
    "day_1_valid_losses2 = []\n",
    "day_1_valid_accs2 = []\n",
    "\n",
    "day_1_train_losses3 = []\n",
    "day_1_train_accs3 = []\n",
    "day_1_valid_losses3 = []\n",
    "day_1_valid_accs3 = []\n",
    "\n",
    "day_1_train_losses4 = []\n",
    "day_1_train_accs4 = []\n",
    "day_1_valid_losses4 = []\n",
    "day_1_valid_accs4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_2_train_losses1 = []\n",
    "day_2_train_accs1 = []\n",
    "day_2_valid_losses1 = []\n",
    "day_2_valid_accs1 = []\n",
    "\n",
    "day_2_train_losses2 = []\n",
    "day_2_train_accs2 = []\n",
    "day_2_valid_losses2 = []\n",
    "day_2_valid_accs2 = []\n",
    "\n",
    "day_2_train_losses3 = []\n",
    "day_2_train_accs3 = []\n",
    "day_2_valid_losses3 = []\n",
    "day_2_valid_accs3 = []\n",
    "\n",
    "day_2_train_losses4 = []\n",
    "day_2_train_accs4 = []\n",
    "day_2_valid_losses4 = []\n",
    "day_2_valid_accs4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_3_train_losses1 = []\n",
    "day_3_train_accs1 = []\n",
    "day_3_valid_losses1 = []\n",
    "day_3_valid_accs1 = []\n",
    "\n",
    "day_3_train_losses2 = []\n",
    "day_3_train_accs2 = []\n",
    "day_3_valid_losses2 = []\n",
    "day_3_valid_accs2 = []\n",
    "\n",
    "day_3_train_losses3 = []\n",
    "day_3_train_accs3 = []\n",
    "day_3_valid_losses3 = []\n",
    "day_3_valid_accs3 = []\n",
    "\n",
    "day_3_train_losses4 = []\n",
    "day_3_train_accs4 = []\n",
    "day_3_valid_losses4 = []\n",
    "day_3_valid_accs4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_4_train_losses1 = []\n",
    "day_4_train_accs1 = []\n",
    "day_4_valid_losses1 = []\n",
    "day_4_valid_accs1 = []\n",
    "\n",
    "day_4_train_losses2 = []\n",
    "day_4_train_accs2 = []\n",
    "day_4_valid_losses2 = []\n",
    "day_4_valid_accs2 = []\n",
    "\n",
    "day_4_train_losses3 = []\n",
    "day_4_train_accs3 = []\n",
    "day_4_valid_losses3 = []\n",
    "day_4_valid_accs3 = []\n",
    "\n",
    "day_4_train_losses4 = []\n",
    "day_4_train_accs4 = []\n",
    "day_4_valid_losses4 = []\n",
    "day_4_valid_accs4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_5_train_losses1 = []\n",
    "day_5_train_accs1 = []\n",
    "day_5_valid_losses1 = []\n",
    "day_5_valid_accs1 = []\n",
    "\n",
    "day_5_train_losses2 = []\n",
    "day_5_train_accs2 = []\n",
    "day_5_valid_losses2 = []\n",
    "day_5_valid_accs2 = []\n",
    "\n",
    "day_5_train_losses3 = []\n",
    "day_5_train_accs3 = []\n",
    "day_5_valid_losses3 = []\n",
    "day_5_valid_accs3 = []\n",
    "\n",
    "day_5_train_losses4 = []\n",
    "day_5_train_accs4 = []\n",
    "day_5_valid_losses4 = []\n",
    "day_5_valid_accs4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_6_train_losses1 = []\n",
    "day_6_train_accs1 = []\n",
    "day_6_valid_losses1 = []\n",
    "day_6_valid_accs1 = []\n",
    "\n",
    "day_6_train_losses2 = []\n",
    "day_6_train_accs2 = []\n",
    "day_6_valid_losses2 = []\n",
    "day_6_valid_accs2 = []\n",
    "\n",
    "day_6_train_losses3 = []\n",
    "day_6_train_accs3 = []\n",
    "day_6_valid_losses3 = []\n",
    "day_6_valid_accs3 = []\n",
    "\n",
    "day_6_train_losses4 = []\n",
    "day_6_train_accs4 = []\n",
    "day_6_valid_losses4 = []\n",
    "day_6_valid_accs4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_7_train_losses1 = []\n",
    "day_7_train_accs1 = []\n",
    "day_7_valid_losses1 = []\n",
    "day_7_valid_accs1 = []\n",
    "\n",
    "day_7_train_losses2 = []\n",
    "day_7_train_accs2 = []\n",
    "day_7_valid_losses2 = []\n",
    "day_7_valid_accs2 = []\n",
    "\n",
    "day_7_train_losses3 = []\n",
    "day_7_train_accs3 = []\n",
    "day_7_valid_losses3 = []\n",
    "day_7_valid_accs3 = []\n",
    "\n",
    "day_7_train_losses4 = []\n",
    "day_7_train_accs4 = []\n",
    "day_7_valid_losses4 = []\n",
    "day_7_valid_accs4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_8_train_losses1 = []\n",
    "day_8_train_accs1 = []\n",
    "day_8_valid_losses1 = []\n",
    "day_8_valid_accs1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "day_1_model1 = Model1(sess, \"day_1_model1\")\n",
    "day_1_model2 = Model2(sess, \"day_1_model2\")\n",
    "day_1_model3 = Model3(sess, \"day_1_model3\")\n",
    "day_1_model4 = Model4(sess, \"day_1_model4\")\n",
    "day_1_model1.build(9)\n",
    "day_1_model2.build(9)\n",
    "day_1_model3.build(9)\n",
    "day_1_model4.build(9)\n",
    "\n",
    "day_2_model1 = Model1(sess, \"day_2_model1\")\n",
    "day_2_model2 = Model2(sess, \"day_2_model2\")\n",
    "day_2_model3 = Model3(sess, \"day_2_model3\")\n",
    "day_2_model4 = Model4(sess, \"day_2_model4\")\n",
    "day_2_model1.build(8)\n",
    "day_2_model2.build(8)\n",
    "day_2_model3.build(8)\n",
    "day_2_model4.build(8)\n",
    "\n",
    "day_3_model1 = Model1(sess, \"day_3_model1\")\n",
    "day_3_model2 = Model2(sess, \"day_3_model2\")\n",
    "day_3_model3 = Model3(sess, \"day_3_model3\")\n",
    "day_3_model4 = Model4(sess, \"day_3_model4\")\n",
    "day_3_model1.build(7)\n",
    "day_3_model2.build(7)\n",
    "day_3_model3.build(7)\n",
    "day_3_model4.build(7)\n",
    "\n",
    "day_4_model1 = Model1(sess, \"day_4_model1\")\n",
    "day_4_model2 = Model2(sess, \"day_4_model2\")\n",
    "day_4_model3 = Model3(sess, \"day_4_model3\")\n",
    "day_4_model4 = Model4(sess, \"day_4_model4\")\n",
    "day_4_model1.build(6)\n",
    "day_4_model2.build(6)\n",
    "day_4_model3.build(6)\n",
    "day_4_model4.build(6)\n",
    "\n",
    "day_5_model1 = Model1(sess, \"day_5_model1\")\n",
    "day_5_model2 = Model2(sess, \"day_5_model2\")\n",
    "day_5_model3 = Model3(sess, \"day_5_model3\")\n",
    "day_5_model4 = Model4(sess, \"day_5_model4\")\n",
    "day_5_model1.build(5)\n",
    "day_5_model2.build(5)\n",
    "day_5_model3.build(5)\n",
    "day_5_model4.build(5)\n",
    "\n",
    "day_6_model1 = Model1(sess, \"day_6_model1\")\n",
    "day_6_model2 = Model2(sess, \"day_6_model2\")\n",
    "day_6_model3 = Model3(sess, \"day_6_model3\")\n",
    "day_6_model4 = Model4(sess, \"day_6_model4\")\n",
    "day_6_model1.build(4)\n",
    "day_6_model2.build(4)\n",
    "day_6_model3.build(4)\n",
    "day_6_model4.build(4)\n",
    "\n",
    "day_7_model1 = Model1(sess, \"day_7_model1\")\n",
    "day_7_model2 = Model2(sess, \"day_7_model2\")\n",
    "day_7_model3 = Model3(sess, \"day_7_model3\")\n",
    "day_7_model4 = Model4(sess, \"day_7_model4\")\n",
    "day_7_model1.build(3)\n",
    "day_7_model2.build(3)\n",
    "day_7_model3.build(3)\n",
    "day_7_model4.build(3)\n",
    "\n",
    "day_8_model1 = Model5(sess, \"day_8_model1\")\n",
    "day_8_model1.build()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "# train my model\n",
    "for epoch in range(total_epoch):\n",
    "    avg_cost1 = 0\n",
    "    avg_cost2 = 0\n",
    "    avg_cost3 = 0\n",
    "    avg_cost4 = 0\n",
    "    \n",
    "    total_batch = int(len(day_1_training_lst) / batch_size)\n",
    "    idx = 0\n",
    "    \n",
    "    if epoch == 0 :\n",
    "        learning_rate = learning_rate1\n",
    "    elif epoch == 50 :\n",
    "        learning_rate = learning_rate2\n",
    "    elif epoch == 70 :\n",
    "        learning_rate = learning_rate3\n",
    "    elif epoch == 90 :\n",
    "        learning_rate = learning_rate4\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = day_1_training_lst[idx:idx+batch_size],day_1_training_label[idx:idx+batch_size]\n",
    "        \n",
    "        c1, _ = day_1_model1.train(batch_xs, batch_ys, learning_rate)\n",
    "        c2, _ = day_1_model2.train(batch_xs, batch_ys, learning_rate)\n",
    "        c3, _ = day_1_model3.train(batch_xs, batch_ys, learning_rate)\n",
    "        c4, _ = day_1_model4.train(batch_xs, batch_ys, learning_rate)\n",
    "        \n",
    "        avg_cost1 += c1 / total_batch\n",
    "        avg_cost2 += c2 / total_batch\n",
    "        avg_cost3 += c3 / total_batch\n",
    "        avg_cost4 += c4 / total_batch\n",
    "        \n",
    "        idx += batch_size\n",
    "            \n",
    "    #train cost & acc\n",
    "    cost1, acc1 = day_1_model1.evaluate(day_1_training_lst, day_1_training_label, batch_size = batch_size)\n",
    "    cost2, acc2 = day_1_model2.evaluate(day_1_training_lst, day_1_training_label, batch_size = batch_size)\n",
    "    cost3, acc3 = day_1_model3.evaluate(day_1_training_lst, day_1_training_label, batch_size = batch_size)\n",
    "    cost4, acc4 = day_1_model4.evaluate(day_1_training_lst, day_1_training_label, batch_size = batch_size)\n",
    "    \n",
    "    day_1_train_losses1.append(cost1)\n",
    "    day_1_train_accs1.append(acc1)\n",
    "    day_1_train_losses2.append(cost2)\n",
    "    day_1_train_accs2.append(acc2)\n",
    "    day_1_train_losses3.append(cost3)\n",
    "    day_1_train_accs3.append(acc3)\n",
    "    day_1_train_losses4.append(cost4)\n",
    "    day_1_train_accs4.append(acc4)\n",
    "    \n",
    "    #test cost & acc\n",
    "    v_cost1, v_acc1 = day_1_model1.evaluate(day_1_valid_lst, day_1_valid_label, batch_size = batch_size)\n",
    "    v_cost2, v_acc2 = day_1_model2.evaluate(day_1_valid_lst, day_1_valid_label, batch_size = batch_size)\n",
    "    v_cost3, v_acc3 = day_1_model3.evaluate(day_1_valid_lst, day_1_valid_label, batch_size = batch_size)\n",
    "    v_cost4, v_acc4 = day_1_model4.evaluate(day_1_valid_lst, day_1_valid_label, batch_size = batch_size)\n",
    "    \n",
    "    day_1_valid_losses1.append(v_cost1)\n",
    "    day_1_valid_accs1.append(v_acc1)\n",
    "    day_1_valid_losses2.append(v_cost2)\n",
    "    day_1_valid_accs2.append(v_acc2)\n",
    "    day_1_valid_losses3.append(v_cost3)\n",
    "    day_1_valid_accs3.append(v_acc3)\n",
    "    day_1_valid_losses4.append(v_cost4)\n",
    "    day_1_valid_accs4.append(v_acc4)\n",
    "    \n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost1, acc1*100, v_cost1, v_acc1*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost2, acc2*100, v_cost2, v_acc2*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost3, acc3*100, v_cost3, v_acc3*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost4, acc4*100, v_cost4, v_acc4*100))\n",
    "    print('Accuracy:', day_1_model1.get_accuracy(day_1_test_lst, day_1_test_label))\n",
    "    print('Accuracy:', day_1_model2.get_accuracy(day_1_test_lst, day_1_test_label))\n",
    "    print('Accuracy:', day_1_model3.get_accuracy(day_1_test_lst, day_1_test_label))\n",
    "    print('Accuracy:', day_1_model4.get_accuracy(day_1_test_lst, day_1_test_label))\n",
    "    \n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_1_training_label, 1), np.argmax(day_1_model1.predict(day_1_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_1_training_label, 1), np.argmax(day_1_model2.predict(day_1_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_1_training_label, 1), np.argmax(day_1_model3.predict(day_1_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_1_training_label, 1), np.argmax(day_1_model4.predict(day_1_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_1_valid_label, 1), np.argmax(day_1_model1.predict(day_1_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_1_valid_label, 1), np.argmax(day_1_model2.predict(day_1_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_1_valid_label, 1), np.argmax(day_1_model3.predict(day_1_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_1_valid_label, 1), np.argmax(day_1_model4.predict(day_1_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_1_test_label, 1), np.argmax(day_1_model1.predict(day_1_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_1_test_label, 1), np.argmax(day_1_model2.predict(day_1_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_1_test_label, 1), np.argmax(day_1_model3.predict(day_1_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_1_test_label, 1), np.argmax(day_1_model4.predict(day_1_test_lst), 1), average=\"weighted\"))\n",
    "    print(\" \")\n",
    "\n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "# train my model\n",
    "for epoch in range(total_epoch):\n",
    "    avg_cost1 = 0\n",
    "    avg_cost2 = 0\n",
    "    avg_cost3 = 0\n",
    "    avg_cost4 = 0\n",
    "    \n",
    "    total_batch = int(len(day_2_training_lst) / batch_size)\n",
    "    idx = 0\n",
    "    \n",
    "    if epoch == 0 :\n",
    "        learning_rate = learning_rate1\n",
    "    elif epoch == 50 :\n",
    "        learning_rate = learning_rate2\n",
    "    elif epoch == 70 :\n",
    "        learning_rate = learning_rate3\n",
    "    elif epoch == 90 :\n",
    "        learning_rate = learning_rate4\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = day_2_training_lst[idx:idx+batch_size],day_2_training_label[idx:idx+batch_size]\n",
    "        \n",
    "        c1, _ = day_2_model1.train(batch_xs, batch_ys, learning_rate)\n",
    "        c2, _ = day_2_model2.train(batch_xs, batch_ys, learning_rate)\n",
    "        c3, _ = day_2_model3.train(batch_xs, batch_ys, learning_rate)\n",
    "        c4, _ = day_2_model4.train(batch_xs, batch_ys, learning_rate)\n",
    "        \n",
    "        avg_cost1 += c1 / total_batch\n",
    "        avg_cost2 += c2 / total_batch\n",
    "        avg_cost3 += c3 / total_batch\n",
    "        avg_cost4 += c4 / total_batch\n",
    "        \n",
    "        idx += batch_size\n",
    "            \n",
    "    #train cost & acc\n",
    "    cost1, acc1 = day_2_model1.evaluate(day_2_training_lst, day_2_training_label, batch_size = batch_size)\n",
    "    cost2, acc2 = day_2_model2.evaluate(day_2_training_lst, day_2_training_label, batch_size = batch_size)\n",
    "    cost3, acc3 = day_2_model3.evaluate(day_2_training_lst, day_2_training_label, batch_size = batch_size)\n",
    "    cost4, acc4 = day_2_model4.evaluate(day_2_training_lst, day_2_training_label, batch_size = batch_size)\n",
    "    \n",
    "    day_2_train_losses1.append(cost1)\n",
    "    day_2_train_accs1.append(acc1)\n",
    "    day_2_train_losses2.append(cost2)\n",
    "    day_2_train_accs2.append(acc2)\n",
    "    day_2_train_losses3.append(cost3)\n",
    "    day_2_train_accs3.append(acc3)\n",
    "    day_2_train_losses4.append(cost4)\n",
    "    day_2_train_accs4.append(acc4)\n",
    "    \n",
    "    #test cost & acc\n",
    "    v_cost1, v_acc1 = day_2_model1.evaluate(day_2_valid_lst, day_2_valid_label, batch_size = batch_size)\n",
    "    v_cost2, v_acc2 = day_2_model2.evaluate(day_2_valid_lst, day_2_valid_label, batch_size = batch_size)\n",
    "    v_cost3, v_acc3 = day_2_model3.evaluate(day_2_valid_lst, day_2_valid_label, batch_size = batch_size)\n",
    "    v_cost4, v_acc4 = day_2_model4.evaluate(day_2_valid_lst, day_2_valid_label, batch_size = batch_size)\n",
    "    \n",
    "    day_2_valid_losses1.append(v_cost1)\n",
    "    day_2_valid_accs1.append(v_acc1)\n",
    "    day_2_valid_losses2.append(v_cost2)\n",
    "    day_2_valid_accs2.append(v_acc2)\n",
    "    day_2_valid_losses3.append(v_cost3)\n",
    "    day_2_valid_accs3.append(v_acc3)\n",
    "    day_2_valid_losses4.append(v_cost4)\n",
    "    day_2_valid_accs4.append(v_acc4)\n",
    "    \n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost1, acc1*100, v_cost1, v_acc1*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost2, acc2*100, v_cost2, v_acc2*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost3, acc3*100, v_cost3, v_acc3*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost4, acc4*100, v_cost4, v_acc4*100))\n",
    "    print('Accuracy:', day_2_model1.get_accuracy(day_2_test_lst, day_2_test_label))\n",
    "    print('Accuracy:', day_2_model2.get_accuracy(day_2_test_lst, day_2_test_label))\n",
    "    print('Accuracy:', day_2_model3.get_accuracy(day_2_test_lst, day_2_test_label))\n",
    "    print('Accuracy:', day_2_model4.get_accuracy(day_2_test_lst, day_2_test_label))\n",
    "    \n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_2_training_label, 1), np.argmax(day_2_model1.predict(day_2_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_2_training_label, 1), np.argmax(day_2_model2.predict(day_2_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_2_training_label, 1), np.argmax(day_2_model3.predict(day_2_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_2_training_label, 1), np.argmax(day_2_model4.predict(day_2_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_2_valid_label, 1), np.argmax(day_2_model1.predict(day_2_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_2_valid_label, 1), np.argmax(day_2_model2.predict(day_2_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_2_valid_label, 1), np.argmax(day_2_model3.predict(day_2_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_2_valid_label, 1), np.argmax(day_2_model4.predict(day_2_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_2_test_label, 1), np.argmax(day_2_model1.predict(day_2_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_2_test_label, 1), np.argmax(day_2_model2.predict(day_2_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_2_test_label, 1), np.argmax(day_2_model3.predict(day_2_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_2_test_label, 1), np.argmax(day_2_model4.predict(day_2_test_lst), 1), average=\"weighted\"))\n",
    "    print(\" \")\n",
    "\n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "# train my model\n",
    "for epoch in range(total_epoch):\n",
    "    avg_cost1 = 0\n",
    "    avg_cost2 = 0\n",
    "    avg_cost3 = 0\n",
    "    avg_cost4 = 0\n",
    "    \n",
    "    total_batch = int(len(day_3_training_lst) / batch_size)\n",
    "    idx = 0\n",
    "    \n",
    "    if epoch == 0 :\n",
    "        learning_rate = learning_rate1\n",
    "    elif epoch == 50 :\n",
    "        learning_rate = learning_rate2\n",
    "    elif epoch == 70 :\n",
    "        learning_rate = learning_rate3\n",
    "    elif epoch == 90 :\n",
    "        learning_rate = learning_rate4\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = day_3_training_lst[idx:idx+batch_size],day_3_training_label[idx:idx+batch_size]\n",
    "        \n",
    "        c1, _ = day_3_model1.train(batch_xs, batch_ys, learning_rate)\n",
    "        c2, _ = day_3_model2.train(batch_xs, batch_ys, learning_rate)\n",
    "        c3, _ = day_3_model3.train(batch_xs, batch_ys, learning_rate)\n",
    "        c4, _ = day_3_model4.train(batch_xs, batch_ys, learning_rate)\n",
    "        \n",
    "        avg_cost1 += c1 / total_batch\n",
    "        avg_cost2 += c2 / total_batch\n",
    "        avg_cost3 += c3 / total_batch\n",
    "        avg_cost4 += c4 / total_batch\n",
    "        \n",
    "        idx += batch_size\n",
    "            \n",
    "    #train cost & acc\n",
    "    cost1, acc1 = day_3_model1.evaluate(day_3_training_lst, day_3_training_label, batch_size = batch_size)\n",
    "    cost2, acc2 = day_3_model2.evaluate(day_3_training_lst, day_3_training_label, batch_size = batch_size)\n",
    "    cost3, acc3 = day_3_model3.evaluate(day_3_training_lst, day_3_training_label, batch_size = batch_size)\n",
    "    cost4, acc4 = day_3_model4.evaluate(day_3_training_lst, day_3_training_label, batch_size = batch_size)\n",
    "    \n",
    "    day_3_train_losses1.append(cost1)\n",
    "    day_3_train_accs1.append(acc1)\n",
    "    day_3_train_losses2.append(cost2)\n",
    "    day_3_train_accs2.append(acc2)\n",
    "    day_3_train_losses3.append(cost3)\n",
    "    day_3_train_accs3.append(acc3)\n",
    "    day_3_train_losses4.append(cost4)\n",
    "    day_3_train_accs4.append(acc4)\n",
    "    \n",
    "    #test cost & acc\n",
    "    v_cost1, v_acc1 = day_3_model1.evaluate(day_3_valid_lst, day_3_valid_label, batch_size = batch_size)\n",
    "    v_cost2, v_acc2 = day_3_model2.evaluate(day_3_valid_lst, day_3_valid_label, batch_size = batch_size)\n",
    "    v_cost3, v_acc3 = day_3_model3.evaluate(day_3_valid_lst, day_3_valid_label, batch_size = batch_size)\n",
    "    v_cost4, v_acc4 = day_3_model4.evaluate(day_3_valid_lst, day_3_valid_label, batch_size = batch_size)\n",
    "    \n",
    "    day_3_valid_losses1.append(v_cost1)\n",
    "    day_3_valid_accs1.append(v_acc1)\n",
    "    day_3_valid_losses2.append(v_cost2)\n",
    "    day_3_valid_accs2.append(v_acc2)\n",
    "    day_3_valid_losses3.append(v_cost3)\n",
    "    day_3_valid_accs3.append(v_acc3)\n",
    "    day_3_valid_losses4.append(v_cost4)\n",
    "    day_3_valid_accs4.append(v_acc4)\n",
    "    \n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost1, acc1*100, v_cost1, v_acc1*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost2, acc2*100, v_cost2, v_acc2*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost3, acc3*100, v_cost3, v_acc3*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost4, acc4*100, v_cost4, v_acc4*100))\n",
    "    print('Accuracy:', day_3_model1.get_accuracy(day_3_test_lst, day_3_test_label))\n",
    "    print('Accuracy:', day_3_model2.get_accuracy(day_3_test_lst, day_3_test_label))\n",
    "    print('Accuracy:', day_3_model3.get_accuracy(day_3_test_lst, day_3_test_label))\n",
    "    print('Accuracy:', day_3_model4.get_accuracy(day_3_test_lst, day_3_test_label))\n",
    "    \n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_3_training_label, 1), np.argmax(day_3_model1.predict(day_3_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_3_training_label, 1), np.argmax(day_3_model2.predict(day_3_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_3_training_label, 1), np.argmax(day_3_model3.predict(day_3_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_3_training_label, 1), np.argmax(day_3_model4.predict(day_3_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_3_valid_label, 1), np.argmax(day_3_model1.predict(day_3_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_3_valid_label, 1), np.argmax(day_3_model2.predict(day_3_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_3_valid_label, 1), np.argmax(day_3_model3.predict(day_3_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_3_valid_label, 1), np.argmax(day_3_model4.predict(day_3_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_3_test_label, 1), np.argmax(day_3_model1.predict(day_3_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_3_test_label, 1), np.argmax(day_3_model2.predict(day_3_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_3_test_label, 1), np.argmax(day_3_model3.predict(day_3_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_3_test_label, 1), np.argmax(day_3_model4.predict(day_3_test_lst), 1), average=\"weighted\"))\n",
    "    print(\" \")\n",
    "\n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "# train my model\n",
    "for epoch in range(total_epoch):\n",
    "    avg_cost1 = 0\n",
    "    avg_cost2 = 0\n",
    "    avg_cost3 = 0\n",
    "    avg_cost4 = 0\n",
    "    \n",
    "    total_batch = int(len(day_4_training_lst) / batch_size)\n",
    "    idx = 0\n",
    "    \n",
    "    if epoch == 0 :\n",
    "        learning_rate = learning_rate1\n",
    "    elif epoch == 50 :\n",
    "        learning_rate = learning_rate2\n",
    "    elif epoch == 70 :\n",
    "        learning_rate = learning_rate3\n",
    "    elif epoch == 90 :\n",
    "        learning_rate = learning_rate4\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = day_4_training_lst[idx:idx+batch_size],day_4_training_label[idx:idx+batch_size]\n",
    "        \n",
    "        c1, _ = day_4_model1.train(batch_xs, batch_ys, learning_rate)\n",
    "        c2, _ = day_4_model2.train(batch_xs, batch_ys, learning_rate)\n",
    "        c3, _ = day_4_model3.train(batch_xs, batch_ys, learning_rate)\n",
    "        c4, _ = day_4_model4.train(batch_xs, batch_ys, learning_rate)\n",
    "        \n",
    "        avg_cost1 += c1 / total_batch\n",
    "        avg_cost2 += c2 / total_batch\n",
    "        avg_cost3 += c3 / total_batch\n",
    "        avg_cost4 += c4 / total_batch\n",
    "        \n",
    "        idx += batch_size\n",
    "            \n",
    "    #train cost & acc\n",
    "    cost1, acc1 = day_4_model1.evaluate(day_4_training_lst, day_4_training_label, batch_size = batch_size)\n",
    "    cost2, acc2 = day_4_model2.evaluate(day_4_training_lst, day_4_training_label, batch_size = batch_size)\n",
    "    cost3, acc3 = day_4_model3.evaluate(day_4_training_lst, day_4_training_label, batch_size = batch_size)\n",
    "    cost4, acc4 = day_4_model4.evaluate(day_4_training_lst, day_4_training_label, batch_size = batch_size)\n",
    "    \n",
    "    day_4_train_losses1.append(cost1)\n",
    "    day_4_train_accs1.append(acc1)\n",
    "    day_4_train_losses2.append(cost2)\n",
    "    day_4_train_accs2.append(acc2)\n",
    "    day_4_train_losses3.append(cost3)\n",
    "    day_4_train_accs3.append(acc3)\n",
    "    day_4_train_losses4.append(cost4)\n",
    "    day_4_train_accs4.append(acc4)\n",
    "    \n",
    "    #test cost & acc\n",
    "    v_cost1, v_acc1 = day_4_model1.evaluate(day_4_valid_lst, day_4_valid_label, batch_size = batch_size)\n",
    "    v_cost2, v_acc2 = day_4_model2.evaluate(day_4_valid_lst, day_4_valid_label, batch_size = batch_size)\n",
    "    v_cost3, v_acc3 = day_4_model3.evaluate(day_4_valid_lst, day_4_valid_label, batch_size = batch_size)\n",
    "    v_cost4, v_acc4 = day_4_model4.evaluate(day_4_valid_lst, day_4_valid_label, batch_size = batch_size)\n",
    "    \n",
    "    day_4_valid_losses1.append(v_cost1)\n",
    "    day_4_valid_accs1.append(v_acc1)\n",
    "    day_4_valid_losses2.append(v_cost2)\n",
    "    day_4_valid_accs2.append(v_acc2)\n",
    "    day_4_valid_losses3.append(v_cost3)\n",
    "    day_4_valid_accs3.append(v_acc3)\n",
    "    day_4_valid_losses4.append(v_cost4)\n",
    "    day_4_valid_accs4.append(v_acc4)\n",
    "    \n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost1, acc1*100, v_cost1, v_acc1*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost2, acc2*100, v_cost2, v_acc2*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost3, acc3*100, v_cost3, v_acc3*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost4, acc4*100, v_cost4, v_acc4*100))\n",
    "    print('Accuracy:', day_4_model1.get_accuracy(day_4_test_lst, day_4_test_label))\n",
    "    print('Accuracy:', day_4_model2.get_accuracy(day_4_test_lst, day_4_test_label))\n",
    "    print('Accuracy:', day_4_model3.get_accuracy(day_4_test_lst, day_4_test_label))\n",
    "    print('Accuracy:', day_4_model4.get_accuracy(day_4_test_lst, day_4_test_label))\n",
    "    \n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_4_training_label, 1), np.argmax(day_4_model1.predict(day_4_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_4_training_label, 1), np.argmax(day_4_model2.predict(day_4_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_4_training_label, 1), np.argmax(day_4_model3.predict(day_4_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_4_training_label, 1), np.argmax(day_4_model4.predict(day_4_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_4_valid_label, 1), np.argmax(day_4_model1.predict(day_4_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_4_valid_label, 1), np.argmax(day_4_model2.predict(day_4_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_4_valid_label, 1), np.argmax(day_4_model3.predict(day_4_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_4_valid_label, 1), np.argmax(day_4_model4.predict(day_4_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_4_test_label, 1), np.argmax(day_4_model1.predict(day_4_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_4_test_label, 1), np.argmax(day_4_model2.predict(day_4_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_4_test_label, 1), np.argmax(day_4_model3.predict(day_4_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_4_test_label, 1), np.argmax(day_4_model4.predict(day_4_test_lst), 1), average=\"weighted\"))\n",
    "    print(\" \")\n",
    "\n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "# train my model\n",
    "for epoch in range(total_epoch):\n",
    "    avg_cost1 = 0\n",
    "    avg_cost2 = 0\n",
    "    avg_cost3 = 0\n",
    "    avg_cost4 = 0\n",
    "    \n",
    "    total_batch = int(len(day_5_training_lst) / batch_size)\n",
    "    idx = 0\n",
    "    \n",
    "    if epoch == 0 :\n",
    "        learning_rate = learning_rate1\n",
    "    elif epoch == 50 :\n",
    "        learning_rate = learning_rate2\n",
    "    elif epoch == 70 :\n",
    "        learning_rate = learning_rate3\n",
    "    elif epoch == 90 :\n",
    "        learning_rate = learning_rate4\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = day_5_training_lst[idx:idx+batch_size],day_5_training_label[idx:idx+batch_size]\n",
    "        \n",
    "        c1, _ = day_5_model1.train(batch_xs, batch_ys, learning_rate)\n",
    "        c2, _ = day_5_model2.train(batch_xs, batch_ys, learning_rate)\n",
    "        c3, _ = day_5_model3.train(batch_xs, batch_ys, learning_rate)\n",
    "        c4, _ = day_5_model4.train(batch_xs, batch_ys, learning_rate)\n",
    "        \n",
    "        avg_cost1 += c1 / total_batch\n",
    "        avg_cost2 += c2 / total_batch\n",
    "        avg_cost3 += c3 / total_batch\n",
    "        avg_cost4 += c4 / total_batch\n",
    "        \n",
    "        idx += batch_size\n",
    "            \n",
    "    #train cost & acc\n",
    "    cost1, acc1 = day_5_model1.evaluate(day_5_training_lst, day_5_training_label, batch_size = batch_size)\n",
    "    cost2, acc2 = day_5_model2.evaluate(day_5_training_lst, day_5_training_label, batch_size = batch_size)\n",
    "    cost3, acc3 = day_5_model3.evaluate(day_5_training_lst, day_5_training_label, batch_size = batch_size)\n",
    "    cost4, acc4 = day_5_model4.evaluate(day_5_training_lst, day_5_training_label, batch_size = batch_size)\n",
    "    \n",
    "    day_5_train_losses1.append(cost1)\n",
    "    day_5_train_accs1.append(acc1)\n",
    "    day_5_train_losses2.append(cost2)\n",
    "    day_5_train_accs2.append(acc2)\n",
    "    day_5_train_losses3.append(cost3)\n",
    "    day_5_train_accs3.append(acc3)\n",
    "    day_5_train_losses4.append(cost4)\n",
    "    day_5_train_accs4.append(acc4)\n",
    "    \n",
    "    #test cost & acc\n",
    "    v_cost1, v_acc1 = day_5_model1.evaluate(day_5_valid_lst, day_5_valid_label, batch_size = batch_size)\n",
    "    v_cost2, v_acc2 = day_5_model2.evaluate(day_5_valid_lst, day_5_valid_label, batch_size = batch_size)\n",
    "    v_cost3, v_acc3 = day_5_model3.evaluate(day_5_valid_lst, day_5_valid_label, batch_size = batch_size)\n",
    "    v_cost4, v_acc4 = day_5_model4.evaluate(day_5_valid_lst, day_5_valid_label, batch_size = batch_size)\n",
    "    \n",
    "    day_5_valid_losses1.append(v_cost1)\n",
    "    day_5_valid_accs1.append(v_acc1)\n",
    "    day_5_valid_losses2.append(v_cost2)\n",
    "    day_5_valid_accs2.append(v_acc2)\n",
    "    day_5_valid_losses3.append(v_cost3)\n",
    "    day_5_valid_accs3.append(v_acc3)\n",
    "    day_5_valid_losses4.append(v_cost4)\n",
    "    day_5_valid_accs4.append(v_acc4)\n",
    "    \n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost1, acc1*100, v_cost1, v_acc1*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost2, acc2*100, v_cost2, v_acc2*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost3, acc3*100, v_cost3, v_acc3*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost4, acc4*100, v_cost4, v_acc4*100))\n",
    "    print('Accuracy:', day_5_model1.get_accuracy(day_5_test_lst, day_5_test_label))\n",
    "    print('Accuracy:', day_5_model2.get_accuracy(day_5_test_lst, day_5_test_label))\n",
    "    print('Accuracy:', day_5_model3.get_accuracy(day_5_test_lst, day_5_test_label))\n",
    "    print('Accuracy:', day_5_model4.get_accuracy(day_5_test_lst, day_5_test_label))\n",
    "    \n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_5_training_label, 1), np.argmax(day_5_model1.predict(day_5_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_5_training_label, 1), np.argmax(day_5_model2.predict(day_5_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_5_training_label, 1), np.argmax(day_5_model3.predict(day_5_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_5_training_label, 1), np.argmax(day_5_model4.predict(day_5_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_5_valid_label, 1), np.argmax(day_5_model1.predict(day_5_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_5_valid_label, 1), np.argmax(day_5_model2.predict(day_5_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_5_valid_label, 1), np.argmax(day_5_model3.predict(day_5_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_5_valid_label, 1), np.argmax(day_5_model4.predict(day_5_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_5_test_label, 1), np.argmax(day_5_model1.predict(day_5_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_5_test_label, 1), np.argmax(day_5_model2.predict(day_5_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_5_test_label, 1), np.argmax(day_5_model3.predict(day_5_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_5_test_label, 1), np.argmax(day_5_model4.predict(day_5_test_lst), 1), average=\"weighted\"))\n",
    "    print(\" \")\n",
    "\n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "# train my model\n",
    "for epoch in range(total_epoch):\n",
    "    avg_cost1 = 0\n",
    "    avg_cost2 = 0\n",
    "    avg_cost3 = 0\n",
    "    avg_cost4 = 0\n",
    "    \n",
    "    total_batch = int(len(day_6_training_lst) / batch_size)\n",
    "    idx = 0\n",
    "    \n",
    "    if epoch == 0 :\n",
    "        learning_rate = learning_rate1\n",
    "    elif epoch == 50 :\n",
    "        learning_rate = learning_rate2\n",
    "    elif epoch == 70 :\n",
    "        learning_rate = learning_rate3\n",
    "    elif epoch == 90 :\n",
    "        learning_rate = learning_rate4\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = day_6_training_lst[idx:idx+batch_size],day_6_training_label[idx:idx+batch_size]\n",
    "        \n",
    "        c1, _ = day_6_model1.train(batch_xs, batch_ys, learning_rate)\n",
    "        c2, _ = day_6_model2.train(batch_xs, batch_ys, learning_rate)\n",
    "        c3, _ = day_6_model3.train(batch_xs, batch_ys, learning_rate)\n",
    "        c4, _ = day_6_model4.train(batch_xs, batch_ys, learning_rate)\n",
    "        \n",
    "        avg_cost1 += c1 / total_batch\n",
    "        avg_cost2 += c2 / total_batch\n",
    "        avg_cost3 += c3 / total_batch\n",
    "        avg_cost4 += c4 / total_batch\n",
    "        \n",
    "        idx += batch_size\n",
    "            \n",
    "    #train cost & acc\n",
    "    cost1, acc1 = day_6_model1.evaluate(day_6_training_lst, day_6_training_label, batch_size = batch_size)\n",
    "    cost2, acc2 = day_6_model2.evaluate(day_6_training_lst, day_6_training_label, batch_size = batch_size)\n",
    "    cost3, acc3 = day_6_model3.evaluate(day_6_training_lst, day_6_training_label, batch_size = batch_size)\n",
    "    cost4, acc4 = day_6_model4.evaluate(day_6_training_lst, day_6_training_label, batch_size = batch_size)\n",
    "    \n",
    "    day_6_train_losses1.append(cost1)\n",
    "    day_6_train_accs1.append(acc1)\n",
    "    day_6_train_losses2.append(cost2)\n",
    "    day_6_train_accs2.append(acc2)\n",
    "    day_6_train_losses3.append(cost3)\n",
    "    day_6_train_accs3.append(acc3)\n",
    "    day_6_train_losses4.append(cost4)\n",
    "    day_6_train_accs4.append(acc4)\n",
    "    \n",
    "    #test cost & acc\n",
    "    v_cost1, v_acc1 = day_6_model1.evaluate(day_6_valid_lst, day_6_valid_label, batch_size = batch_size)\n",
    "    v_cost2, v_acc2 = day_6_model2.evaluate(day_6_valid_lst, day_6_valid_label, batch_size = batch_size)\n",
    "    v_cost3, v_acc3 = day_6_model3.evaluate(day_6_valid_lst, day_6_valid_label, batch_size = batch_size)\n",
    "    v_cost4, v_acc4 = day_6_model4.evaluate(day_6_valid_lst, day_6_valid_label, batch_size = batch_size)\n",
    "    \n",
    "    day_6_valid_losses1.append(v_cost1)\n",
    "    day_6_valid_accs1.append(v_acc1)\n",
    "    day_6_valid_losses2.append(v_cost2)\n",
    "    day_6_valid_accs2.append(v_acc2)\n",
    "    day_6_valid_losses3.append(v_cost3)\n",
    "    day_6_valid_accs3.append(v_acc3)\n",
    "    day_6_valid_losses4.append(v_cost4)\n",
    "    day_6_valid_accs4.append(v_acc4)\n",
    "    \n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost1, acc1*100, v_cost1, v_acc1*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost2, acc2*100, v_cost2, v_acc2*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost3, acc3*100, v_cost3, v_acc3*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost4, acc4*100, v_cost4, v_acc4*100))\n",
    "    print('Accuracy:', day_6_model1.get_accuracy(day_6_test_lst, day_6_test_label))\n",
    "    print('Accuracy:', day_6_model2.get_accuracy(day_6_test_lst, day_6_test_label))\n",
    "    print('Accuracy:', day_6_model3.get_accuracy(day_6_test_lst, day_6_test_label))\n",
    "    print('Accuracy:', day_6_model4.get_accuracy(day_6_test_lst, day_6_test_label))\n",
    "    \n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_6_training_label, 1), np.argmax(day_6_model1.predict(day_6_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_6_training_label, 1), np.argmax(day_6_model2.predict(day_6_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_6_training_label, 1), np.argmax(day_6_model3.predict(day_6_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_6_training_label, 1), np.argmax(day_6_model4.predict(day_6_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_6_valid_label, 1), np.argmax(day_6_model1.predict(day_6_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_6_valid_label, 1), np.argmax(day_6_model2.predict(day_6_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_6_valid_label, 1), np.argmax(day_6_model3.predict(day_6_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_6_valid_label, 1), np.argmax(day_6_model4.predict(day_6_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_6_test_label, 1), np.argmax(day_6_model1.predict(day_6_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_6_test_label, 1), np.argmax(day_6_model2.predict(day_6_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_6_test_label, 1), np.argmax(day_6_model3.predict(day_6_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_6_test_label, 1), np.argmax(day_6_model4.predict(day_6_test_lst), 1), average=\"weighted\"))\n",
    "    print(\" \")\n",
    "\n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "# train my model\n",
    "for epoch in range(total_epoch):\n",
    "    avg_cost1 = 0\n",
    "    avg_cost2 = 0\n",
    "    avg_cost3 = 0\n",
    "    avg_cost4 = 0\n",
    "    \n",
    "    total_batch = int(len(day_7_training_lst) / batch_size)\n",
    "    idx = 0\n",
    "    \n",
    "    if epoch == 0 :\n",
    "        learning_rate = learning_rate1\n",
    "    elif epoch == 50 :\n",
    "        learning_rate = learning_rate2\n",
    "    elif epoch == 70 :\n",
    "        learning_rate = learning_rate3\n",
    "    elif epoch == 90 :\n",
    "        learning_rate = learning_rate4\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = day_7_training_lst[idx:idx+batch_size],day_7_training_label[idx:idx+batch_size]\n",
    "        \n",
    "        c1, _ = day_7_model1.train(batch_xs, batch_ys, learning_rate)\n",
    "        c2, _ = day_7_model2.train(batch_xs, batch_ys, learning_rate)\n",
    "        c3, _ = day_7_model3.train(batch_xs, batch_ys, learning_rate)\n",
    "        c4, _ = day_7_model4.train(batch_xs, batch_ys, learning_rate)\n",
    "        \n",
    "        avg_cost1 += c1 / total_batch\n",
    "        avg_cost2 += c2 / total_batch\n",
    "        avg_cost3 += c3 / total_batch\n",
    "        avg_cost4 += c4 / total_batch\n",
    "        \n",
    "        idx += batch_size\n",
    "            \n",
    "    #train cost & acc\n",
    "    cost1, acc1 = day_7_model1.evaluate(day_7_training_lst, day_7_training_label, batch_size = batch_size)\n",
    "    cost2, acc2 = day_7_model2.evaluate(day_7_training_lst, day_7_training_label, batch_size = batch_size)\n",
    "    cost3, acc3 = day_7_model3.evaluate(day_7_training_lst, day_7_training_label, batch_size = batch_size)\n",
    "    cost4, acc4 = day_7_model4.evaluate(day_7_training_lst, day_7_training_label, batch_size = batch_size)\n",
    "    \n",
    "    day_7_train_losses1.append(cost1)\n",
    "    day_7_train_accs1.append(acc1)\n",
    "    day_7_train_losses2.append(cost2)\n",
    "    day_7_train_accs2.append(acc2)\n",
    "    day_7_train_losses3.append(cost3)\n",
    "    day_7_train_accs3.append(acc3)\n",
    "    day_7_train_losses4.append(cost4)\n",
    "    day_7_train_accs4.append(acc4)\n",
    "    \n",
    "    #test cost & acc\n",
    "    v_cost1, v_acc1 = day_7_model1.evaluate(day_7_valid_lst, day_7_valid_label, batch_size = batch_size)\n",
    "    v_cost2, v_acc2 = day_7_model2.evaluate(day_7_valid_lst, day_7_valid_label, batch_size = batch_size)\n",
    "    v_cost3, v_acc3 = day_7_model3.evaluate(day_7_valid_lst, day_7_valid_label, batch_size = batch_size)\n",
    "    v_cost4, v_acc4 = day_7_model4.evaluate(day_7_valid_lst, day_7_valid_label, batch_size = batch_size)\n",
    "    \n",
    "    day_7_valid_losses1.append(v_cost1)\n",
    "    day_7_valid_accs1.append(v_acc1)\n",
    "    day_7_valid_losses2.append(v_cost2)\n",
    "    day_7_valid_accs2.append(v_acc2)\n",
    "    day_7_valid_losses3.append(v_cost3)\n",
    "    day_7_valid_accs3.append(v_acc3)\n",
    "    day_7_valid_losses4.append(v_cost4)\n",
    "    day_7_valid_accs4.append(v_acc4)\n",
    "    \n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost1, acc1*100, v_cost1, v_acc1*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost2, acc2*100, v_cost2, v_acc2*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost3, acc3*100, v_cost3, v_acc3*100))\n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost4, acc4*100, v_cost4, v_acc4*100))\n",
    "    print('Accuracy:', day_7_model1.get_accuracy(day_7_test_lst, day_7_test_label))\n",
    "    print('Accuracy:', day_7_model2.get_accuracy(day_7_test_lst, day_7_test_label))\n",
    "    print('Accuracy:', day_7_model3.get_accuracy(day_7_test_lst, day_7_test_label))\n",
    "    print('Accuracy:', day_7_model4.get_accuracy(day_7_test_lst, day_7_test_label))\n",
    "    \n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_7_training_label, 1), np.argmax(day_7_model1.predict(day_7_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_7_training_label, 1), np.argmax(day_7_model2.predict(day_7_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_7_training_label, 1), np.argmax(day_7_model3.predict(day_7_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_7_training_label, 1), np.argmax(day_7_model4.predict(day_7_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_7_valid_label, 1), np.argmax(day_7_model1.predict(day_7_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_7_valid_label, 1), np.argmax(day_7_model2.predict(day_7_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_7_valid_label, 1), np.argmax(day_7_model3.predict(day_7_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_7_valid_label, 1), np.argmax(day_7_model4.predict(day_7_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_7_test_label, 1), np.argmax(day_7_model1.predict(day_7_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_7_test_label, 1), np.argmax(day_7_model2.predict(day_7_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_7_test_label, 1), np.argmax(day_7_model3.predict(day_7_test_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_7_test_label, 1), np.argmax(day_7_model4.predict(day_7_test_lst), 1), average=\"weighted\"))\n",
    "    print(\" \")\n",
    "\n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "# train my model\n",
    "for epoch in range(total_epoch):\n",
    "    avg_cost1 = 0\n",
    "\n",
    "    \n",
    "    total_batch = int(len(day_8_training_lst) / batch_size)\n",
    "    idx = 0\n",
    "    \n",
    "    if epoch == 0 :\n",
    "        learning_rate = learning_rate1\n",
    "    elif epoch == 50 :\n",
    "        learning_rate = learning_rate2\n",
    "    elif epoch == 70 :\n",
    "        learning_rate = learning_rate3\n",
    "    elif epoch == 90 :\n",
    "        learning_rate = learning_rate4\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = day_8_training_lst[idx:idx+batch_size],day_8_training_label[idx:idx+batch_size]\n",
    "        \n",
    "        c1, _ = day_8_model1.train(batch_xs, batch_ys, learning_rate)\n",
    "        avg_cost1 += c1 / total_batch\n",
    "        idx += batch_size\n",
    "            \n",
    "    #train cost & acc\n",
    "    cost1, acc1 = day_8_model1.evaluate(day_8_training_lst, day_8_training_label, batch_size = batch_size)\n",
    "    day_8_train_losses1.append(cost1)\n",
    "    day_8_train_accs1.append(acc1)\n",
    "\n",
    "    \n",
    "    #test cost & acc\n",
    "    v_cost1, v_acc1 = day_8_model1.evaluate(day_8_valid_lst, day_8_valid_label, batch_size = batch_size)\n",
    "    day_8_valid_losses1.append(v_cost1)\n",
    "    day_8_valid_accs1.append(v_acc1)\n",
    "\n",
    "    \n",
    "    print(\"epoch : \", epoch, \" -- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(cost1, acc1*100, v_cost1, v_acc1*100))\n",
    "    print('Accuracy :', day_8_model1.get_accuracy(day_8_test_lst, day_8_test_label))\n",
    "    \n",
    "    print(\"train F1 score :\", f1_score(np.argmax(day_8_training_label, 1), np.argmax(day_8_model1.predict(day_8_training_lst), 1), average=\"weighted\"))\n",
    "    print(\"valid F1 score :\", f1_score(np.argmax(day_8_valid_label, 1), np.argmax(day_8_model1.predict(day_8_valid_lst), 1), average=\"weighted\"))\n",
    "    print(\"test  F1 score :\", f1_score(np.argmax(day_8_test_label, 1), np.argmax(day_8_model1.predict(day_8_test_lst), 1), average=\"weighted\"))\n",
    "    print(\" \")\n",
    "\n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_1_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_1_valid_losses\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_2_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_2_valid_losses\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_3_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_3_valid_losses\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_4_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_4_valid_losses\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_5_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_5_valid_losses\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_6_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_6_valid_losses\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_7_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_7_valid_losses\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eval(\"day_8_train_losses\"+str(1)), label='training'+str(1))\n",
    "plt.plot(eval(\"day_8_valid_losses\"+str(1)), label='valid'+str(1))\n",
    "plt.title(\"model\"+str(1))\n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_1_train_accs\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_1_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_2_train_accs\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_2_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_3_train_accs\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_3_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_4_train_accs\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_4_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_5_train_accs\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_5_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_6_train_accs\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_6_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_7_train_accs\"+str(idx)), label='training'+str(idx))\n",
    "    plt.plot(eval(\"day_7_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eval(\"day_8_train_accs\"+str(1)), label='training'+str(1))\n",
    "plt.plot(eval(\"day_8_valid_accs\"+str(1)), label='valid'+str(1))\n",
    "plt.title(\"model\"+str(1))\n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_1_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_2_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_3_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_4_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_5_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_6_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_7_train_losses\"+str(idx)), label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eval(\"day_8_train_losses\"+str(1)), label='training'+str(1))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_1_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_2_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_3_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_4_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_5_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_6_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_7_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1,5) :\n",
    "    plt.plot(eval(\"day_8_valid_accs\"+str(idx)), label='valid'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './advanced_RNN/original_user_vector/original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = pd.read_csv(\"user_vector_test.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = activity.groupby(\"acc_id\").count().reset_index()[[\"acc_id\"]]\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_lst = [int(x) for x in label.acc_id.tolist()]\n",
    "print(len(id_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_dic = {}\n",
    "for user in id_lst :\n",
    "    activity_dic[user] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(activity.head().values[0]))\n",
    "activity.head().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in activity.values :\n",
    "    activity_dic[int(data[0])].append([int(data[1])]+list(data[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_lst = [list(y) for y in activity_dic.items()]\n",
    "activity_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_1_lst = [x for x in activity_lst if x[1][0][0]==1]\n",
    "day_2_lst = [x for x in activity_lst if x[1][0][0]==2]\n",
    "day_3_lst = [x for x in activity_lst if x[1][0][0]==3]\n",
    "day_4_lst = [x for x in activity_lst if x[1][0][0]==4]\n",
    "day_5_lst = [x for x in activity_lst if x[1][0][0]==5]\n",
    "day_6_lst = [x for x in activity_lst if x[1][0][0]==6]\n",
    "day_7_lst = [x for x in activity_lst if x[1][0][0]==7]\n",
    "day_8_lst = [x for x in activity_lst if x[1][0][0]==8]\n",
    "\n",
    "print(len(day_1_lst))\n",
    "print(len(day_2_lst))\n",
    "print(len(day_3_lst))\n",
    "print(len(day_4_lst))\n",
    "print(len(day_5_lst))\n",
    "print(len(day_6_lst))\n",
    "print(len(day_7_lst))\n",
    "print(len(day_8_lst))\n",
    "\n",
    "print(\"\")\n",
    "print(len(day_1_lst)+len(day_2_lst)+len(day_3_lst)+len(day_4_lst)+len(day_5_lst)+len(day_6_lst)+len(day_7_lst)+len(day_8_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_1_dic = {}\n",
    "day_2_dic = {}\n",
    "day_3_dic = {}\n",
    "day_4_dic = {}\n",
    "day_5_dic = {}\n",
    "day_6_dic = {}\n",
    "day_7_dic = {}\n",
    "day_8_dic = {}\n",
    "\n",
    "day_1_id_lst = [x[0] for x in day_1_lst]\n",
    "day_2_id_lst = [x[0] for x in day_2_lst]\n",
    "day_3_id_lst = [x[0] for x in day_3_lst]\n",
    "day_4_id_lst = [x[0] for x in day_4_lst]\n",
    "day_5_id_lst = [x[0] for x in day_5_lst]\n",
    "day_6_id_lst = [x[0] for x in day_6_lst]\n",
    "day_7_id_lst = [x[0] for x in day_7_lst]\n",
    "day_8_id_lst = [x[0] for x in day_8_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = [1] + [0]*52\n",
    "EMPTY_TOKEN = [0,1] + [0]*51\n",
    "END_TOKEN = [0,0,1] + [0]*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in day_1_id_lst :\n",
    "    #day_1_dic[(user, 0)] = START_TOKEN\n",
    "    day_1_dic[(user, 1)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 2)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 3)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 4)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 5)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_1_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_2_id_lst :\n",
    "    #day_2_dic[(user, 0)] = START_TOKEN\n",
    "    day_2_dic[(user, 2)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 3)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 4)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 5)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_2_dic[(user, 9)] = END_TOKEN   \n",
    "    \n",
    "for user in day_3_id_lst :\n",
    "    #day_3_dic[(user, 0)] = START_TOKEN\n",
    "    day_3_dic[(user, 3)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 4)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 5)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_3_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_4_id_lst :\n",
    "    #day_4_dic[(user, 0)] = START_TOKEN\n",
    "    day_4_dic[(user, 4)] = EMPTY_TOKEN\n",
    "    day_4_dic[(user, 5)] = EMPTY_TOKEN\n",
    "    day_4_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_4_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_4_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_4_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_5_id_lst :\n",
    "    #day_5_dic[(user, 0)] = START_TOKEN\n",
    "    day_5_dic[(user, 5)] = EMPTY_TOKEN\n",
    "    day_5_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_5_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_5_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_5_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_6_id_lst :\n",
    "    #day_6_dic[(user, 0)] = START_TOKEN\n",
    "    day_6_dic[(user, 6)] = EMPTY_TOKEN\n",
    "    day_6_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_6_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_6_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_7_id_lst :\n",
    "    #day_7_dic[(user, 0)] = START_TOKEN\n",
    "    day_7_dic[(user, 7)] = EMPTY_TOKEN\n",
    "    day_7_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    day_7_dic[(user, 9)] = END_TOKEN\n",
    "    \n",
    "for user in day_8_id_lst :\n",
    "    #day_8_dic[(user, 0)] = START_TOKEN\n",
    "    day_8_dic[(user, 8)] = EMPTY_TOKEN\n",
    "    #day_8_dic[(user, 9)] = END_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in day_1_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_1_dic[(user, week)] = data2[1:]\n",
    "\n",
    "for data in day_2_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_2_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_3_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_3_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_4_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_4_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_5_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_5_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_6_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_6_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_7_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_7_dic[(user, week)] = data2[1:]\n",
    "        \n",
    "for data in day_8_lst :\n",
    "    user = data[0]\n",
    "    lst = data[1]\n",
    "    \n",
    "    for data2 in lst :\n",
    "        week = data2[0]\n",
    "        day_8_dic[(user, week)] = data2[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_1_total_lst = []\n",
    "day_2_total_lst = []\n",
    "day_3_total_lst = []\n",
    "day_4_total_lst = []\n",
    "day_5_total_lst = []\n",
    "day_6_total_lst = []\n",
    "day_7_total_lst = []\n",
    "day_8_total_lst = []\n",
    "\n",
    "temp1 = list(day_1_dic.values())\n",
    "temp2 = list(day_2_dic.values())\n",
    "temp3 = list(day_3_dic.values())\n",
    "temp4 = list(day_4_dic.values())\n",
    "temp5 = list(day_5_dic.values())\n",
    "temp6 = list(day_6_dic.values())\n",
    "temp7 = list(day_7_dic.values())\n",
    "temp8 = list(day_8_dic.values())\n",
    "\n",
    "last1=0\n",
    "last2=0\n",
    "last3=0\n",
    "last4=0\n",
    "last5=0\n",
    "last6=0\n",
    "last7=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for now in range(0,len(temp1)+1,9) :\n",
    "    if now == 0 :\n",
    "        last1 = now\n",
    "        continue\n",
    "    \n",
    "    day_1_total_lst.append(temp1[last1:now])\n",
    "    last1=now\n",
    "    \n",
    "for now in range(0,len(temp2)+1,8) :\n",
    "    if now == 0 :\n",
    "        last2 = now\n",
    "        continue\n",
    "    \n",
    "    day_2_total_lst.append(temp2[last2:now])\n",
    "    last2=now\n",
    "    \n",
    "for now in range(0,len(temp3)+1,7) :\n",
    "    if now == 0 :\n",
    "        last3 = now\n",
    "        continue\n",
    "    \n",
    "    day_3_total_lst.append(temp3[last3:now])\n",
    "    last3=now\n",
    "    \n",
    "for now in range(0,len(temp4)+1,6) :\n",
    "    if now == 0 :\n",
    "        last4 = now\n",
    "        continue\n",
    "    \n",
    "    day_4_total_lst.append(temp4[last4:now])\n",
    "    last4=now\n",
    "    \n",
    "for now in range(0,len(temp5)+1,5) :\n",
    "    if now == 0 :\n",
    "        last5 = now\n",
    "        continue\n",
    "    \n",
    "    day_5_total_lst.append(temp5[last5:now])\n",
    "    last5=now\n",
    "    \n",
    "for now in range(0,len(temp6)+1,4) :\n",
    "    if now == 0 :\n",
    "        last6 = now\n",
    "        continue\n",
    "    \n",
    "    day_6_total_lst.append(temp6[last6:now])\n",
    "    last6=now\n",
    "    \n",
    "for now in range(0,len(temp7)+1,3) :\n",
    "    if now == 0 :\n",
    "        last7 = now\n",
    "        continue\n",
    "    \n",
    "    day_7_total_lst.append(temp7[last7:now])\n",
    "    last7=now\n",
    "\n",
    "day_8_total_lst = np.array(temp8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(day_1_total_lst))\n",
    "print(len(day_2_total_lst))\n",
    "print(len(day_3_total_lst))\n",
    "print(len(day_4_total_lst))\n",
    "print(len(day_5_total_lst))\n",
    "print(len(day_6_total_lst))\n",
    "print(len(day_7_total_lst))\n",
    "print(len(day_8_total_lst))\n",
    "\n",
    "print(\"\")\n",
    "print(len(day_1_total_lst) + len(day_2_total_lst) + len(day_3_total_lst) + len(day_4_total_lst) \\\n",
    "      + len(day_5_total_lst) + len(day_6_total_lst) + len(day_7_total_lst) + len(day_8_total_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_1_test_lst = np.array(day_1_total_lst)\n",
    "day_2_test_lst = np.array(day_2_total_lst)\n",
    "day_3_test_lst = np.array(day_3_total_lst)\n",
    "day_4_test_lst = np.array(day_4_total_lst)\n",
    "day_5_test_lst = np.array(day_5_total_lst)\n",
    "day_6_test_lst = np.array(day_6_total_lst)\n",
    "day_7_test_lst = np.array(day_7_total_lst)\n",
    "day_8_test_lst = np.array(day_8_total_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_11 = np.argmax(day_1_model1.predict(day_1_test_lst), axis=1)\n",
    "result_12 = np.argmax(day_1_model2.predict(day_1_test_lst), axis=1)\n",
    "result_13 = np.argmax(day_1_model3.predict(day_1_test_lst), axis=1)\n",
    "result_14 = np.argmax(day_1_model4.predict(day_1_test_lst), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_21 = np.argmax(day_2_model1.predict(day_2_test_lst), axis=1)\n",
    "result_22 = np.argmax(day_2_model2.predict(day_2_test_lst), axis=1)\n",
    "result_23 = np.argmax(day_2_model3.predict(day_2_test_lst), axis=1)\n",
    "result_24 = np.argmax(day_2_model4.predict(day_2_test_lst), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_31 = np.argmax(day_3_model1.predict(day_3_test_lst), axis=1)\n",
    "result_32 = np.argmax(day_3_model2.predict(day_3_test_lst), axis=1)\n",
    "result_33 = np.argmax(day_3_model3.predict(day_3_test_lst), axis=1)\n",
    "result_34 = np.argmax(day_3_model4.predict(day_3_test_lst), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_41 = np.argmax(day_4_model1.predict(day_4_test_lst), axis=1)\n",
    "result_42 = np.argmax(day_4_model2.predict(day_4_test_lst), axis=1)\n",
    "result_43 = np.argmax(day_4_model3.predict(day_4_test_lst), axis=1)\n",
    "result_44 = np.argmax(day_4_model4.predict(day_4_test_lst), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_51 = np.argmax(day_5_model1.predict(day_5_test_lst), axis=1)\n",
    "result_52 = np.argmax(day_5_model2.predict(day_5_test_lst), axis=1)\n",
    "result_53 = np.argmax(day_5_model3.predict(day_5_test_lst), axis=1)\n",
    "result_54 = np.argmax(day_5_model4.predict(day_5_test_lst), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_61 = np.argmax(day_6_model1.predict(day_6_test_lst), axis=1)\n",
    "result_62 = np.argmax(day_6_model2.predict(day_6_test_lst), axis=1)\n",
    "result_63 = np.argmax(day_6_model3.predict(day_6_test_lst), axis=1)\n",
    "result_64 = np.argmax(day_6_model4.predict(day_6_test_lst), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_71 = np.argmax(day_7_model1.predict(day_7_test_lst), axis=1)\n",
    "result_72 = np.argmax(day_7_model2.predict(day_7_test_lst), axis=1)\n",
    "result_73 = np.argmax(day_7_model3.predict(day_7_test_lst), axis=1)\n",
    "result_74 = np.argmax(day_7_model4.predict(day_7_test_lst), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_81 = np.argmax(day_8_model1.predict(day_8_test_lst), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(result_lst) :\n",
    "    final_result = []\n",
    "    \n",
    "    for data in result_lst :\n",
    "        temp = sorted([(0, data.count(0)),(1, data.count(1)),(2, data.count(2)),(3, data.count(3))], key=lambda x :x[1], reverse=True)\n",
    "        final_result.append(temp[0][0])\n",
    "        \n",
    "    return pd.Series(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {0 : \"acc_id\", 1:\"model1\", 2:\"model2\", 3:\"model3\", 4:\"model4\"}\n",
    "\n",
    "result_1 = pd.DataFrame(list(zip(day_1_id_lst, result_11, result_12, result_13, result_14))).rename(columns = dic)\n",
    "result_2 = pd.DataFrame(list(zip(day_2_id_lst, result_21, result_22, result_23, result_24))).rename(columns = dic)\n",
    "result_3 = pd.DataFrame(list(zip(day_3_id_lst, result_31, result_32, result_33, result_34))).rename(columns = dic)\n",
    "result_4 = pd.DataFrame(list(zip(day_4_id_lst, result_41, result_42, result_43, result_44))).rename(columns = dic)\n",
    "result_5 = pd.DataFrame(list(zip(day_5_id_lst, result_51, result_52, result_53, result_54))).rename(columns = dic)\n",
    "result_6 = pd.DataFrame(list(zip(day_6_id_lst, result_61, result_62, result_63, result_64))).rename(columns = dic)\n",
    "result_7 = pd.DataFrame(list(zip(day_7_id_lst, result_71, result_72, result_73, result_74))).rename(columns = dic)\n",
    "result_8 = pd.DataFrame(list(zip(day_8_id_lst, result_81))).rename(columns = dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1[\"result\"] = voting(list(zip(result_1.model1,result_1.model2,result_1.model3,result_1.model4)))\n",
    "result_2[\"result\"] = voting(list(zip(result_2.model1,result_2.model2,result_2.model3,result_2.model4)))\n",
    "result_3[\"result\"] = voting(list(zip(result_3.model1,result_3.model2,result_3.model3,result_3.model4)))\n",
    "result_4[\"result\"] = voting(list(zip(result_4.model1,result_4.model2,result_4.model3,result_4.model4)))\n",
    "result_5[\"result\"] = voting(list(zip(result_5.model1,result_5.model2,result_5.model3,result_5.model4)))\n",
    "result_6[\"result\"] = voting(list(zip(result_6.model1,result_6.model2,result_6.model3,result_6.model4)))\n",
    "result_7[\"result\"] = voting(list(zip(result_7.model1,result_7.model2,result_7.model3,result_7.model4)))\n",
    "result_8[\"result\"] = result_8.model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lst = [result_1[[\"acc_id\",\"result\"]], result_2[[\"acc_id\",\"result\"]], result_3[[\"acc_id\",\"result\"]], result_4[[\"acc_id\",\"result\"]],\n",
    "              result_5[[\"acc_id\",\"result\"]], result_6[[\"acc_id\",\"result\"]], result_7[[\"acc_id\",\"result\"]], result_8[[\"acc_id\",\"result\"]], ]\n",
    "\n",
    "total_result = pd.concat(result_lst).sort_values(\"acc_id\")\n",
    "total_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result.to_csv(\"./result/original_user_vector/original.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id_df = pd.read_csv(\"test_user_id.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "test_user_id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id_dic = {}\n",
    "\n",
    "for kv in test_user_id_df.values :\n",
    "    test_user_id_dic[kv[1]] = kv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dic = {0 : \"week\", 1 : \"month\", 2:\"2month\", 3 :\"retain\"}\n",
    "\n",
    "total_result[\"acc_id\"] = total_result[\"acc_id\"].map(lambda x: test_user_id_dic[x])\n",
    "total_result[\"result\"] = total_result[\"result\"].map(lambda x: label_dic[x])\n",
    "total_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result2 = total_result.set_index(\"acc_id\").rename(columns = {\"result\" : \"label\"})\n",
    "total_result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result2.to_csv(\"./result/original_user_vector/original_with_acc_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
