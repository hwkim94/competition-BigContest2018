{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = pd.read_csv(\"data/preprocessed_company.csv\", encoding='cp949')\n",
    "company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_lst = sorted(list(set(list(company[\"고객사\"]))))\n",
    "\n",
    "print(len(company_lst))\n",
    "print(\"\")\n",
    "print(company_lst[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br> <br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://www.nicebizinfo.com/ep/EP0100M001GE.nice?itgSrch=\"\n",
    "base_url2 = \"https://www.nicebizinfo.com/ep/EP0100M002GE.nice?kiscode=\"\n",
    "regex = \"'.*'\"\n",
    "\n",
    "dic = {}\n",
    "error_lst = []\n",
    "\n",
    "for idx, cp in enumerate(company_lst[1500:]) :\n",
    "    time.sleep(5)\n",
    "    \n",
    "    if idx%20 == 0 :\n",
    "        print(\"---------------\",idx,\"---------------\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "    try :\n",
    "        req = requests.get(base_url + cp, headers={\"User-Agent\" : \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36\"})\n",
    "        html = req.text\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "        rolling_base = soup.find_all(\"span\", {\"class\" : \"fz14 fwb ml10 fErr\"})\n",
    "\n",
    "        id_lst = []\n",
    "        for tag in rolling_base :\n",
    "            id_lst.append(re.search(regex, str(tag)).group().replace(\"'\",\"\"))\n",
    "\n",
    "        if not id_lst :\n",
    "            error_lst.append(cp)\n",
    "            print(\"error1\",idx, cp)\n",
    "\n",
    "        result_lst = []\n",
    "        cnt=1\n",
    "        for k_id in id_lst :\n",
    "            time.sleep(2)\n",
    "            req = requests.get(base_url2 + k_id,  headers={\"User-Agent\" : \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36\"})\n",
    "            html = req.text\n",
    "            soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "            rolling_base = soup.find_all(\"table\")\n",
    "            try :\n",
    "                result = rolling_base[0].find_all(\"strong\")\n",
    "            except :\n",
    "                error_lst.append(cp + \":\" + str(cnt))\n",
    "                print(\"error2\", idx, cp, cnt)\n",
    "\n",
    "            temp = []\n",
    "            for tag in result :\n",
    "                temp.append(str(tag).replace(\"<strong>\", \"\").replace(\"</strong>\", \"\"))\n",
    "\n",
    "            result_lst.append(temp)\n",
    "            cnt+=1\n",
    "\n",
    "        dic[cp] = result_lst\n",
    "        \n",
    "    except :\n",
    "        error_lst.append(cp)\n",
    "        print(\"error3\",idx, cp)\n",
    "        time.sleep(3061) ## ip차단 당한 경우 30분 정도 접속 불가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dic = {}\n",
    "length = 0\n",
    "\n",
    "for key, values in dic.items() :\n",
    "    temp = []\n",
    "    \n",
    "    for value in values :\n",
    "        temp.append(str(value))\n",
    "        \n",
    "    if len(values) > length :\n",
    "        length = len(values)\n",
    "    \n",
    "    new_dic[key] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_lst = new_dic.items()\n",
    "dic_lst2 = []\n",
    "\n",
    "for key, lst in dic_lst :\n",
    "    for idx in range(length-len(lst)) :\n",
    "        lst.append(\"[]\")\n",
    "    dic_lst2.append([key]+ lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"crawling_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
