{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(lst, num_class=4) :\n",
    "    return np.eye(num_class)[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def making_data(csv) :\n",
    "    activity = pd.read_csv(csv).drop(\"Unnamed: 0\", axis=1)\n",
    "    label = activity[[\"acc_id\", \"label\"]]\n",
    "    \n",
    "    activity = activity[activity[\"label\"] != \"empty\"]\n",
    "    activity = activity.drop(\"label\", axis=1)\n",
    "    label = label[label[\"label\"] != \"empty\"]\n",
    "    \n",
    "    activity = activity.sort_values([\"acc_id\",\"wk\"])[['acc_id', 'wk', 'cnt_clear_bam', 'cnt_clear_inzone_light','cnt_clear_inzone_normal', \n",
    "                                                  'cnt_clear_inzone_skilled', 'cnt_clear_inzone_solo', 'cnt_clear_raid', 'cnt_clear_raid_light',\n",
    "                                                  'cnt_dt', 'cnt_enter_bam', 'cnt_enter_inzone_light', 'cnt_enter_inzone_normal', \n",
    "                                                  'cnt_enter_inzone_skilled', 'cnt_enter_inzone_solo', 'cnt_enter_raid', 'cnt_enter_raid_light',\n",
    "                                                  'cnt_use_buffitem', 'district_chat', 'duel_cnt', 'duel_win', 'faction_chat', 'game_combat_time', \n",
    "                                                  'gathering_cnt', 'get_money','guild_chat', 'item_hongmun', 'making_cnt', 'normal_chat', \n",
    "                                                  'npc_exp', 'npc_hongmun', 'party_chat', 'partybattle_cnt', 'partybattle_win', 'play_time', \n",
    "                                                  'quest_exp', 'quest_hongmun', 'whisper_chat','first_week', 'payment_amount']]\n",
    "    label = label.sort_values(\"acc_id\")\n",
    "    \n",
    "    label_lst = sorted(list(set([tuple(x) for x in label.values])))\n",
    "    label = pd.DataFrame(label_lst, columns = [\"acc_id\", \"label\"])\n",
    "    \n",
    "    activity1 = activity[activity[\"wk\"]==1].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity2 = activity[activity[\"wk\"]==2].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity3 = activity[activity[\"wk\"]==3].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity4 = activity[activity[\"wk\"]==4].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity5 = activity[activity[\"wk\"]==5].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity6 = activity[activity[\"wk\"]==6].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity7 = activity[activity[\"wk\"]==7].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity8 = activity[activity[\"wk\"]==8].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    \n",
    "    num_values = len(activity1.values[0])\n",
    "    \n",
    "    activity = np.concatenate([activity1.values.reshape([-1, 1, num_values]), activity2.values.reshape([-1, 1, num_values]), \n",
    "                               activity3.values.reshape([-1, 1, num_values]), activity4.values.reshape([-1, 1, num_values]),\n",
    "                               activity5.values.reshape([-1, 1, num_values]), activity6.values.reshape([-1, 1, num_values]),\n",
    "                               activity7.values.reshape([-1, 1, num_values]), activity8.values.reshape([-1, 1, num_values])], axis=1)\n",
    "    \n",
    "    label_dic = {\"week\":0 , \"month\" :1, \"2month\":2, \"retained\":3}\n",
    "\n",
    "    label2 = label.sort_values(by=\"acc_id\")\n",
    "    label2[\"label\"] = label2[\"label\"].map(lambda x : label_dic[x])\n",
    "    \n",
    "    total_lst = activity\n",
    "    label_dic = label2.label.tolist()\n",
    "    total_label = one_hot(label_dic)\n",
    "    \n",
    "    return total_lst, total_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_lst, total_label = making_data(\"OnlyExpanded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx1 = len(total_lst)//5 *4\n",
    "\n",
    "training_lst = np.array(total_lst[:idx1])\n",
    "valid_lst = np.array(total_lst[idx1:])\n",
    "\n",
    "training_label = np.array(total_label[:idx1])\n",
    "valid_label = np.array(total_label[idx1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 8, 38)\n",
      "(100000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(total_lst).shape)\n",
    "print(np.array(total_label).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        \n",
    "    def build(self, batch_size, length, dim, is_embedding, emb_width, num_unit, is_fc, fc_num_unit, fc_activation, cost_function, output_dim) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            ## Setting ##\n",
    "            self.batch_size = batch_size\n",
    "            self.length = length\n",
    "            self.dim = dim\n",
    "            self.is_embedding = is_embedding\n",
    "            self.emb_width = emb_width\n",
    "            self.num_unit = num_unit\n",
    "            self.is_fc = is_fc\n",
    "            self.fc_num_unit = fc_num_unit\n",
    "            self.fc_activation = fc_activation\n",
    "            self.output_dim = output_dim\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [self.batch_size, self.length, self.dim])\n",
    "            self.Y = tf.placeholder(tf.float32, [self.batch_size, self.output_dim])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            #############\n",
    "            \n",
    "            \n",
    "            ## Embedding ##\n",
    "            if self.is_embedding :\n",
    "                W_emb = tf.Variable(tf.random_normal([self.width, self.emb_width]))\n",
    "                self.X = tf.concat(self.X, tf.matmul(self.X, W_emb), axis=2)\n",
    "            ###############\n",
    "            \n",
    "            \n",
    "            ## RNN ##\n",
    "            f_cell1 = tf.nn.rnn_cell.BasicLSTMCell(self.num_unit)\n",
    "            f_cell2 = tf.nn.rnn_cell.BasicLSTMCell(self.num_unit)\n",
    "            f_multi_cell = tf.nn.rnn_cell.MultiRNNCell([f_cell1, f_cell2])\n",
    "            \n",
    "            b_cell1 = tf.nn.rnn_cell.BasicLSTMCell(self.num_unit)\n",
    "            b_cell2 = tf.nn.rnn_cell.BasicLSTMCell(self.num_unit)\n",
    "            b_multi_cell = tf.nn.rnn_cell.MultiRNNCell([b_cell1, b_cell2])\n",
    "            \n",
    "            \n",
    "            f_output, f_state = tf.nn.dynamic_rnn(f_multi_cell, self.X, dtype=tf.float32,  scope=\"forward\")\n",
    "            b_output, b_state = tf.nn.dynamic_rnn(b_multi_cell, tf.reverse(self.X, axis=[1]), dtype=tf.float32, scope=\"backward\")\n",
    "            \n",
    "            f_output = tf.transpose(f_output,[1,0,2])[-1]\n",
    "            b_output = tf.transpose(b_output,[1,0,2])[-1]\n",
    "            \n",
    "            rnn_result = tf.concat([f_output, b_output], axis=1)\n",
    "            #########\n",
    "            \n",
    "            \n",
    "            ## Classifier ##\n",
    "            if is_fc : \n",
    "                dense= tf.layers.dense(rnn_result, self.fc_num_unit)\n",
    "                norm = tf.contrib.layers.layer_norm(dense)\n",
    "                relu = tf.nn.relu(norm)\n",
    "                self.logit = tf.layers.dense(norm, 4)\n",
    "            else :\n",
    "                self.logit = tf.layers.dense(rnn_result, 4)\n",
    "                \n",
    "            self.softmax = tf.nn.softmax(self.logit)\n",
    "            ################\n",
    "            \n",
    "            \n",
    "            ## Learning ##\n",
    "            if cost_function == \"f1\" :\n",
    "                self.numerator = tf.reduce_sum(self.softmax*self.Y)\n",
    "                self.denominator = tf.reduce_sum(self.softmax*self.Y + self.Y)\n",
    "                self.cost = -2 * self.numerator / self.denominator\n",
    "                \n",
    "            else :\n",
    "                self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logit, labels=self.Y))\n",
    "\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "            \n",
    "            self.prediction = tf.equal(tf.argmax(self.logit, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.prediction, tf.float32))    \n",
    "            ##############\n",
    "        \n",
    "        \n",
    "    def train(self, X_input, Y_input, learning_rate, training=True):\n",
    "        feed_dict = {self.X: X_input, self.Y: Y_input, self.learning_rate: learning_rate, self.training: training}\n",
    "        _, cost = self.sess.run([self.optimizer, self.cost], feed_dict=feed_dict)\n",
    "        \n",
    "        return _, cost\n",
    "    \n",
    "    def predict(self, X_input, training=False):\n",
    "        feed_dict = {self.X: X_input, self.training: training}\n",
    "        result = self.sess.run([self.logit], feed_dict=feed_dict)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input):\n",
    "        size = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for idx in range(0, size, self.batch_size):\n",
    "            X_batch = X_input[idx:idx + batch_size]\n",
    "            Y_batch = Y_input[idx:idx + batch_size]\n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= size\n",
    "        total_acc /= size\n",
    "            \n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate1 = 0.02\n",
    "learning_rate2 = 0.01\n",
    "learning_rate3 = 0.005\n",
    "learning_rate4 = 0.001\n",
    "\n",
    "total_epoch = 80\n",
    "batch_size = 500\n",
    "input_dim = np.array(total_lst).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "is_pass = False\n",
    "model_lst = []\n",
    "\n",
    "for is_embedding in [False, True] :\n",
    "    for emb_width in [64,128] :\n",
    "        if not is_pass :\n",
    "            is_pass = True\n",
    "            continue\n",
    "            \n",
    "        for num_unit in [128, 256, 512] :\n",
    "            for is_fc in [False, True] :\n",
    "                for cost in [\"accuracy\"] :\n",
    "                    print(idx) \n",
    "                    sess = tf.Session()\n",
    "                    model = RNN(sess, \"model{}\".format(idx))\n",
    "                    model.build(500, 8, 38, False, emb_width, num_unit, is_fc, 128, tf.nn.relu, cost, 4)\n",
    "                    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "                    model_lst.append(model)\n",
    "                    idx +=1\n",
    "            \n",
    "tl_ta_vl_va_lst = [[[],[],[],[]]]*len(model_lst)\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started!\n",
      "\n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  0\n",
      "-- train 0.76192(65.9%), valid0.76696(65.6%)\n",
      "-- train 1.05949(48.9%), valid1.05823(48.7%)\n",
      "-- train 0.83424(63.4%), valid0.83269(63.5%)\n",
      "-- train 1.20945(43.7%), valid1.21164(44.0%)\n",
      "-- train 0.88797(61.2%), valid0.88182(61.3%)\n",
      "-- train 1.04645(54.9%), valid1.03499(55.0%)\n",
      "-- train 0.80557(64.7%), valid0.80656(64.8%)\n",
      "-- train 0.98487(54.0%), valid0.98022(53.6%)\n",
      "-- train 0.84316(62.3%), valid0.83941(62.6%)\n",
      "-- train 1.01065(54.9%), valid1.00706(55.2%)\n",
      "-- train 0.97852(58.2%), valid0.97071(58.1%)\n",
      "-- train 1.35105(38.8%), valid1.35165(38.9%)\n",
      "-- train 0.77423(65.5%), valid0.77648(65.6%)\n",
      "-- train 0.97550(57.6%), valid0.96746(58.1%)\n",
      "-- train 0.87407(62.1%), valid0.86899(62.4%)\n",
      "-- train 1.21669(40.7%), valid1.21722(40.6%)\n",
      "-- train 0.92335(55.4%), valid0.92183(55.0%)\n",
      "-- train 1.16206(43.9%), valid1.15564(44.7%)\n",
      "Accuracy: 0.655950000882\n",
      "Accuracy: 0.487349999696\n",
      "Accuracy: 0.63465000391\n",
      "Accuracy: 0.440249998122\n",
      "Accuracy: 0.612699998915\n",
      "Accuracy: 0.550100000203\n",
      "Accuracy: 0.648049999774\n",
      "Accuracy: 0.536149998754\n",
      "Accuracy: 0.626349999011\n",
      "Accuracy: 0.552350000292\n",
      "Accuracy: 0.581349995732\n",
      "Accuracy: 0.388849999756\n",
      "Accuracy: 0.655750001967\n",
      "Accuracy: 0.580700001866\n",
      "Accuracy: 0.623550000787\n",
      "Accuracy: 0.406299997866\n",
      "Accuracy: 0.550499998033\n",
      "Accuracy: 0.44659999907\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  1\n",
      "-- train 0.73454(67.4%), valid0.74373(67.0%)\n",
      "-- train 0.86722(61.7%), valid0.86150(62.0%)\n",
      "-- train 0.78938(65.5%), valid0.79246(65.3%)\n",
      "-- train 0.99620(54.5%), valid0.99084(54.8%)\n",
      "-- train 0.85992(60.7%), valid0.85979(60.8%)\n",
      "-- train 0.85759(63.3%), valid0.85598(63.2%)\n",
      "-- train 0.73137(67.8%), valid0.73876(67.6%)\n",
      "-- train 0.81381(64.6%), valid0.81300(64.7%)\n",
      "-- train 0.79372(64.6%), valid0.79705(64.5%)\n",
      "-- train 0.84466(63.7%), valid0.83669(64.2%)\n",
      "-- train 0.85691(63.6%), valid0.85536(63.8%)\n",
      "-- train 1.21231(40.8%), valid1.21439(40.7%)\n",
      "-- train 0.72207(68.0%), valid0.73233(67.8%)\n",
      "-- train 0.83906(63.5%), valid0.83913(63.5%)\n",
      "-- train 0.79437(64.2%), valid0.79989(64.0%)\n",
      "-- train 0.90000(60.1%), valid0.89458(60.3%)\n",
      "-- train 0.90731(57.0%), valid0.90289(56.8%)\n",
      "-- train 0.94833(59.0%), valid0.94486(59.0%)\n",
      "Accuracy: 0.6696999982\n",
      "Accuracy: 0.619600005448\n",
      "Accuracy: 0.653350006044\n",
      "Accuracy: 0.547600003332\n",
      "Accuracy: 0.608300003409\n",
      "Accuracy: 0.63219999969\n",
      "Accuracy: 0.676049999893\n",
      "Accuracy: 0.64675000459\n",
      "Accuracy: 0.645000000298\n",
      "Accuracy: 0.6418500036\n",
      "Accuracy: 0.638000006974\n",
      "Accuracy: 0.407149998844\n",
      "Accuracy: 0.677949993312\n",
      "Accuracy: 0.634699998796\n",
      "Accuracy: 0.640299998224\n",
      "Accuracy: 0.603449998796\n",
      "Accuracy: 0.568250001967\n",
      "Accuracy: 0.589899995923\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  2\n",
      "-- train 0.70846(68.5%), valid0.72058(68.0%)\n",
      "-- train 0.79979(65.3%), valid0.79968(65.5%)\n",
      "-- train 0.76766(66.4%), valid0.77371(66.2%)\n",
      "-- train 0.86440(61.1%), valid0.86042(61.4%)\n",
      "-- train 0.85046(63.5%), valid0.84946(63.7%)\n",
      "-- train 0.83997(62.9%), valid0.83607(63.0%)\n",
      "-- train 0.71765(68.3%), valid0.72916(67.9%)\n",
      "-- train 0.77839(66.1%), valid0.78234(66.0%)\n",
      "-- train 0.76918(65.4%), valid0.77541(65.2%)\n",
      "-- train 0.81980(64.0%), valid0.81760(64.4%)\n",
      "-- train 0.84373(63.4%), valid0.84251(63.4%)\n",
      "-- train 1.19143(42.2%), valid1.19584(42.1%)\n",
      "-- train 0.70901(68.4%), valid0.71908(68.0%)\n",
      "-- train 0.77672(65.9%), valid0.77917(65.9%)\n",
      "-- train 0.73788(67.6%), valid0.75036(67.3%)\n",
      "-- train 0.81014(64.0%), valid0.81159(64.1%)\n",
      "-- train 0.86503(62.9%), valid0.86532(63.3%)\n",
      "-- train 0.89459(60.7%), valid0.88768(60.8%)\n",
      "Accuracy: 0.679649996758\n",
      "Accuracy: 0.65490000546\n",
      "Accuracy: 0.661900003254\n",
      "Accuracy: 0.613749997318\n",
      "Accuracy: 0.637350000441\n",
      "Accuracy: 0.630050000548\n",
      "Accuracy: 0.678750000894\n",
      "Accuracy: 0.659800000489\n",
      "Accuracy: 0.65189999789\n",
      "Accuracy: 0.643649998307\n",
      "Accuracy: 0.633650000393\n",
      "Accuracy: 0.421499997377\n",
      "Accuracy: 0.679949998856\n",
      "Accuracy: 0.659149998426\n",
      "Accuracy: 0.672749999166\n",
      "Accuracy: 0.640549997985\n",
      "Accuracy: 0.632800003886\n",
      "Accuracy: 0.608349995315\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  3\n",
      "-- train 0.69677(69.2%), valid0.71349(68.7%)\n",
      "-- train 0.77425(66.7%), valid0.77695(66.6%)\n",
      "-- train 0.74871(67.2%), valid0.75753(66.8%)\n",
      "-- train 0.82367(63.3%), valid0.82197(63.1%)\n",
      "-- train 0.84834(62.0%), valid0.84731(61.9%)\n",
      "-- train 0.82039(63.9%), valid0.81763(64.4%)\n",
      "-- train 0.70051(69.0%), valid0.71619(68.6%)\n",
      "-- train 0.75128(66.9%), valid0.75610(66.9%)\n",
      "-- train 0.74439(67.3%), valid0.75401(67.2%)\n",
      "-- train 0.81671(64.5%), valid0.81638(64.7%)\n",
      "-- train 0.84423(62.5%), valid0.84630(62.6%)\n",
      "-- train 1.19766(39.6%), valid1.19898(39.7%)\n",
      "-- train 0.69617(69.4%), valid0.71158(68.7%)\n",
      "-- train 0.75869(67.0%), valid0.76577(67.0%)\n",
      "-- train 0.71845(67.6%), valid0.73364(67.2%)\n",
      "-- train 0.76465(66.9%), valid0.77407(66.8%)\n",
      "-- train 0.82909(63.9%), valid0.83165(64.2%)\n",
      "-- train 0.82974(62.9%), valid0.82785(63.1%)\n",
      "Accuracy: 0.68654999733\n",
      "Accuracy: 0.666150005162\n",
      "Accuracy: 0.667849999666\n",
      "Accuracy: 0.631150002778\n",
      "Accuracy: 0.61875000149\n",
      "Accuracy: 0.644400002062\n",
      "Accuracy: 0.685799998045\n",
      "Accuracy: 0.669299997389\n",
      "Accuracy: 0.672049999237\n",
      "Accuracy: 0.647450006008\n",
      "Accuracy: 0.625599999726\n",
      "Accuracy: 0.397150000185\n",
      "Accuracy: 0.686649997532\n",
      "Accuracy: 0.669949996471\n",
      "Accuracy: 0.67214999795\n",
      "Accuracy: 0.667900002003\n",
      "Accuracy: 0.642000003159\n",
      "Accuracy: 0.631300000846\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  4\n",
      "-- train 0.68169(69.8%), valid0.70577(68.9%)\n",
      "-- train 0.74904(67.2%), valid0.75767(66.6%)\n",
      "-- train 0.73510(67.2%), valid0.74626(67.1%)\n",
      "-- train 0.80767(64.2%), valid0.80848(64.4%)\n",
      "-- train 0.82515(63.4%), valid0.82977(63.4%)\n",
      "-- train 0.82907(63.6%), valid0.83021(63.8%)\n",
      "-- train 0.68788(69.7%), valid0.71297(68.5%)\n",
      "-- train 0.74428(67.1%), valid0.75249(66.9%)\n",
      "-- train 0.73306(67.2%), valid0.74463(67.1%)\n",
      "-- train 0.75402(67.0%), valid0.75601(67.2%)\n",
      "-- train 0.85803(64.2%), valid0.86357(63.9%)\n",
      "-- train 1.10797(50.5%), valid1.10148(50.8%)\n",
      "-- train 0.68299(69.5%), valid0.70536(68.6%)\n",
      "-- train 0.73513(67.6%), valid0.74315(67.5%)\n",
      "-- train 0.72566(67.8%), valid0.74433(67.2%)\n",
      "-- train 0.76263(66.1%), valid0.77408(65.8%)\n",
      "-- train 0.82375(63.1%), valid0.83087(63.1%)\n",
      "-- train 0.81000(64.3%), valid0.81114(64.5%)\n",
      "Accuracy: 0.689149999619\n",
      "Accuracy: 0.66589999795\n",
      "Accuracy: 0.670600001514\n",
      "Accuracy: 0.644049994648\n",
      "Accuracy: 0.634250000119\n",
      "Accuracy: 0.637700003386\n",
      "Accuracy: 0.684749995172\n",
      "Accuracy: 0.669100005925\n",
      "Accuracy: 0.670600000024\n",
      "Accuracy: 0.671549999714\n",
      "Accuracy: 0.639499999583\n",
      "Accuracy: 0.507849996537\n",
      "Accuracy: 0.685949997604\n",
      "Accuracy: 0.675050000846\n",
      "Accuracy: 0.671750003099\n",
      "Accuracy: 0.657800002396\n",
      "Accuracy: 0.631350001693\n",
      "Accuracy: 0.644599999487\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  5\n",
      "-- train 0.67338(70.1%), valid0.70147(69.2%)\n",
      "-- train 0.73676(67.8%), valid0.74507(67.4%)\n",
      "-- train 0.71371(68.1%), valid0.73100(67.6%)\n",
      "-- train 0.76902(66.5%), valid0.77185(66.6%)\n",
      "-- train 0.83284(62.9%), valid0.83842(63.3%)\n",
      "-- train 0.82394(63.3%), valid0.82891(63.4%)\n",
      "-- train 0.68112(70.0%), valid0.71013(69.1%)\n",
      "-- train 0.71720(67.6%), valid0.72716(67.3%)\n",
      "-- train 0.70915(68.6%), valid0.72580(68.1%)\n",
      "-- train 0.74979(67.3%), valid0.75361(67.3%)\n",
      "-- train 0.84307(62.8%), valid0.84985(62.8%)\n",
      "-- train 0.87400(61.7%), valid0.87236(61.6%)\n",
      "-- train 0.67662(69.8%), valid0.70235(69.2%)\n",
      "-- train 0.72197(68.2%), valid0.73337(68.0%)\n",
      "-- train 0.70419(69.0%), valid0.72651(68.3%)\n",
      "-- train 0.74241(67.2%), valid0.75297(66.8%)\n",
      "-- train 0.82480(62.5%), valid0.83482(62.5%)\n",
      "-- train 0.78786(65.1%), valid0.79158(65.2%)\n",
      "Accuracy: 0.691500000656\n",
      "Accuracy: 0.674150000513\n",
      "Accuracy: 0.675649999082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.665650001168\n",
      "Accuracy: 0.632500000298\n",
      "Accuracy: 0.633949999511\n",
      "Accuracy: 0.691049993038\n",
      "Accuracy: 0.672750003636\n",
      "Accuracy: 0.681399999559\n",
      "Accuracy: 0.672650004923\n",
      "Accuracy: 0.627999998629\n",
      "Accuracy: 0.616449998319\n",
      "Accuracy: 0.69184999913\n",
      "Accuracy: 0.680049997568\n",
      "Accuracy: 0.683350001276\n",
      "Accuracy: 0.668349997699\n",
      "Accuracy: 0.62539999783\n",
      "Accuracy: 0.652049997449\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  6\n",
      "-- train 0.66171(70.5%), valid0.69748(69.5%)\n",
      "-- train 0.72352(68.4%), valid0.73441(68.0%)\n",
      "-- train 0.70751(68.6%), valid0.72367(68.1%)\n",
      "-- train 0.76590(66.4%), valid0.77135(66.6%)\n",
      "-- train 0.82298(62.2%), valid0.82846(62.0%)\n",
      "-- train 0.79682(65.2%), valid0.79946(65.2%)\n",
      "-- train 0.67658(70.2%), valid0.70907(69.1%)\n",
      "-- train 0.71998(67.9%), valid0.73224(67.4%)\n",
      "-- train 0.70552(68.9%), valid0.72296(68.3%)\n",
      "-- train 0.73860(67.6%), valid0.74320(68.0%)\n",
      "-- train 0.90650(60.9%), valid0.91428(60.7%)\n",
      "-- train 0.87149(60.3%), valid0.87333(59.8%)\n",
      "-- train 0.67265(70.1%), valid0.70468(69.0%)\n",
      "-- train 0.71039(68.6%), valid0.72423(68.1%)\n",
      "-- train 0.69283(69.2%), valid0.71802(68.3%)\n",
      "-- train 0.73233(67.7%), valid0.74216(67.7%)\n",
      "-- train 0.82883(62.1%), valid0.83546(61.5%)\n",
      "-- train 0.78226(65.6%), valid0.78572(65.4%)\n",
      "Accuracy: 0.695449997485\n",
      "Accuracy: 0.680449996889\n",
      "Accuracy: 0.680999995768\n",
      "Accuracy: 0.666100001335\n",
      "Accuracy: 0.619550001621\n",
      "Accuracy: 0.652300001681\n",
      "Accuracy: 0.690999995172\n",
      "Accuracy: 0.67405000031\n",
      "Accuracy: 0.682799997926\n",
      "Accuracy: 0.679600004852\n",
      "Accuracy: 0.60664999783\n",
      "Accuracy: 0.597599999607\n",
      "Accuracy: 0.69034999907\n",
      "Accuracy: 0.681049998105\n",
      "Accuracy: 0.682800000906\n",
      "Accuracy: 0.676749998331\n",
      "Accuracy: 0.6153499946\n",
      "Accuracy: 0.653599999845\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  7\n",
      "-- train 0.66420(70.4%), valid0.70309(69.3%)\n",
      "-- train 0.71413(68.3%), valid0.73095(67.7%)\n",
      "-- train 0.71293(68.1%), valid0.73347(67.4%)\n",
      "-- train 0.76766(66.3%), valid0.77093(66.4%)\n",
      "-- train 0.81221(64.2%), valid0.81308(64.2%)\n",
      "-- train 0.80193(64.7%), valid0.80681(64.8%)\n",
      "-- train 0.66145(70.6%), valid0.70225(69.3%)\n",
      "-- train 0.70443(68.4%), valid0.72201(68.0%)\n",
      "-- train 0.69948(68.9%), valid0.71926(68.3%)\n",
      "-- train 0.73019(67.1%), valid0.74062(66.7%)\n",
      "-- train 0.83402(63.0%), valid0.83543(63.3%)\n",
      "-- train 0.87349(61.2%), valid0.87083(61.5%)\n",
      "-- train 0.66963(69.8%), valid0.70476(68.7%)\n",
      "-- train 0.73212(67.7%), valid0.74712(67.1%)\n",
      "-- train 0.68679(69.0%), valid0.71595(68.0%)\n",
      "-- train 0.71607(68.6%), valid0.72939(68.1%)\n",
      "-- train 0.88902(58.2%), valid0.89162(57.8%)\n",
      "-- train 0.77904(66.4%), valid0.78359(66.4%)\n",
      "Accuracy: 0.692749996483\n",
      "Accuracy: 0.677199998498\n",
      "Accuracy: 0.674299997091\n",
      "Accuracy: 0.663500000536\n",
      "Accuracy: 0.642300002277\n",
      "Accuracy: 0.648149999976\n",
      "Accuracy: 0.693049997091\n",
      "Accuracy: 0.680499996245\n",
      "Accuracy: 0.683350002766\n",
      "Accuracy: 0.667499998212\n",
      "Accuracy: 0.633249996603\n",
      "Accuracy: 0.615449999273\n",
      "Accuracy: 0.687000003457\n",
      "Accuracy: 0.671050000191\n",
      "Accuracy: 0.680099996924\n",
      "Accuracy: 0.680549997091\n",
      "Accuracy: 0.577599996328\n",
      "Accuracy: 0.663750000298\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  8\n",
      "-- train 0.65714(70.7%), valid0.70299(69.2%)\n",
      "-- train 0.69987(68.9%), valid0.71637(68.3%)\n",
      "-- train 0.73819(67.4%), valid0.75592(67.4%)\n",
      "-- train 0.74523(67.7%), valid0.75298(67.5%)\n",
      "-- train 0.80675(65.2%), valid0.81151(65.4%)\n",
      "-- train 0.77865(65.6%), valid0.78425(65.4%)\n",
      "-- train 0.65510(70.7%), valid0.69678(69.4%)\n",
      "-- train 0.69518(68.9%), valid0.71185(68.6%)\n",
      "-- train 0.69746(69.2%), valid0.71828(68.5%)\n",
      "-- train 0.73138(66.8%), valid0.74142(66.4%)\n",
      "-- train 0.82087(64.5%), valid0.82865(64.4%)\n",
      "-- train 0.89165(62.8%), valid0.88951(63.0%)\n",
      "-- train 0.66574(70.2%), valid0.70584(68.7%)\n",
      "-- train 0.70161(69.0%), valid0.71967(68.4%)\n",
      "-- train 0.67780(69.9%), valid0.70990(68.6%)\n",
      "-- train 0.70989(68.6%), valid0.72420(68.0%)\n",
      "-- train 0.79952(65.5%), valid0.80553(65.3%)\n",
      "-- train 0.76997(66.8%), valid0.77777(66.4%)\n",
      "Accuracy: 0.692099998891\n",
      "Accuracy: 0.682899999619\n",
      "Accuracy: 0.673649995029\n",
      "Accuracy: 0.675050002337\n",
      "Accuracy: 0.654250000417\n",
      "Accuracy: 0.654200001061\n",
      "Accuracy: 0.69374999851\n",
      "Accuracy: 0.685749998689\n",
      "Accuracy: 0.685249996185\n",
      "Accuracy: 0.664300000668\n",
      "Accuracy: 0.643500000238\n",
      "Accuracy: 0.629550001025\n",
      "Accuracy: 0.686599996686\n",
      "Accuracy: 0.683649998903\n",
      "Accuracy: 0.685800001025\n",
      "Accuracy: 0.679599998891\n",
      "Accuracy: 0.653150002658\n",
      "Accuracy: 0.664200000465\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  9\n",
      "-- train 0.64913(71.0%), valid0.70117(69.4%)\n",
      "-- train 0.69528(69.0%), valid0.71176(68.5%)\n",
      "-- train 0.70864(68.6%), valid0.73101(68.1%)\n",
      "-- train 0.73484(67.9%), valid0.74478(67.7%)\n",
      "-- train 0.82810(63.6%), valid0.83592(63.8%)\n",
      "-- train 0.77093(66.9%), valid0.77579(66.9%)\n",
      "-- train 0.65506(70.8%), valid0.69843(69.6%)\n",
      "-- train 0.70218(69.2%), valid0.71842(68.4%)\n",
      "-- train 0.68488(69.6%), valid0.70740(68.8%)\n",
      "-- train 0.72408(67.6%), valid0.73530(67.0%)\n",
      "-- train 0.80291(65.3%), valid0.81350(65.0%)\n",
      "-- train 0.83178(63.6%), valid0.83101(63.7%)\n",
      "-- train 0.65895(70.6%), valid0.70069(69.5%)\n",
      "-- train 0.70151(68.8%), valid0.72361(67.8%)\n",
      "-- train 0.67248(69.9%), valid0.70799(68.9%)\n",
      "-- train 0.70659(68.9%), valid0.72277(68.2%)\n",
      "-- train 0.79160(65.8%), valid0.79811(65.7%)\n",
      "-- train 0.77891(65.0%), valid0.78494(65.1%)\n",
      "Accuracy: 0.693549999595\n",
      "Accuracy: 0.684949995577\n",
      "Accuracy: 0.681350003183\n",
      "Accuracy: 0.676999999583\n",
      "Accuracy: 0.638049998879\n",
      "Accuracy: 0.669199995697\n",
      "Accuracy: 0.695949994028\n",
      "Accuracy: 0.684450002015\n",
      "Accuracy: 0.688049998879\n",
      "Accuracy: 0.670099999011\n",
      "Accuracy: 0.650350001454\n",
      "Accuracy: 0.636749999225\n",
      "Accuracy: 0.695049999654\n",
      "Accuracy: 0.677800001204\n",
      "Accuracy: 0.689149998128\n",
      "Accuracy: 0.682299995422\n",
      "Accuracy: 0.656550002098\n",
      "Accuracy: 0.651350003481\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  10\n",
      "-- train 0.60790(72.5%), valid0.69144(69.7%)\n",
      "-- train 0.67554(69.9%), valid0.70322(69.0%)\n",
      "-- train 0.67493(69.6%), valid0.70773(68.9%)\n",
      "-- train 0.72240(68.4%), valid0.73636(67.8%)\n",
      "-- train 0.74482(67.1%), valid0.75782(67.0%)\n",
      "-- train 0.73738(67.7%), valid0.74840(67.5%)\n",
      "-- train 0.61524(72.3%), valid0.68262(70.0%)\n",
      "-- train 0.67404(70.3%), valid0.70180(69.4%)\n",
      "-- train 0.65892(70.4%), valid0.69906(69.2%)\n",
      "-- train 0.68805(69.2%), valid0.70463(68.8%)\n",
      "-- train 0.77142(66.1%), valid0.78290(66.1%)\n",
      "-- train 0.78936(65.6%), valid0.79429(65.6%)\n",
      "-- train 0.62201(71.8%), valid0.68462(70.0%)\n",
      "-- train 0.66856(70.2%), valid0.69932(69.1%)\n",
      "-- train 0.64226(71.3%), valid0.69535(69.7%)\n",
      "-- train 0.68202(69.8%), valid0.70596(68.9%)\n",
      "-- train 0.75464(66.3%), valid0.76696(65.9%)\n",
      "-- train 0.73893(67.7%), valid0.74833(67.4%)\n",
      "Accuracy: 0.696649998426\n",
      "Accuracy: 0.690299996734\n",
      "Accuracy: 0.688850004971\n",
      "Accuracy: 0.678399996459\n",
      "Accuracy: 0.670199993253\n",
      "Accuracy: 0.675049996376\n",
      "Accuracy: 0.700349999964\n",
      "Accuracy: 0.694299998879\n",
      "Accuracy: 0.692499996722\n",
      "Accuracy: 0.687750001252\n",
      "Accuracy: 0.660900004208\n",
      "Accuracy: 0.655900001526\n",
      "Accuracy: 0.699849995971\n",
      "Accuracy: 0.690850000083\n",
      "Accuracy: 0.696699996293\n",
      "Accuracy: 0.689199993014\n",
      "Accuracy: 0.65925000757\n",
      "Accuracy: 0.673700001836\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  11\n",
      "-- train 0.59230(73.1%), valid0.69508(70.0%)\n",
      "-- train 0.66593(70.2%), valid0.70021(69.2%)\n",
      "-- train 0.65650(70.6%), valid0.70106(69.4%)\n",
      "-- train 0.71179(68.5%), valid0.72630(68.1%)\n",
      "-- train 0.74605(67.3%), valid0.76190(66.9%)\n",
      "-- train 0.73091(67.9%), valid0.74508(67.6%)\n",
      "-- train 0.60428(72.8%), valid0.69678(69.9%)\n",
      "-- train 0.65727(70.8%), valid0.69203(69.7%)\n",
      "-- train 0.64641(70.8%), valid0.69663(69.3%)\n",
      "-- train 0.67818(69.7%), valid0.69952(69.1%)\n",
      "-- train 0.76020(66.6%), valid0.77408(66.6%)\n",
      "-- train 0.77928(66.0%), valid0.78678(66.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- train 0.61071(72.2%), valid0.68612(70.0%)\n",
      "-- train 0.66021(70.6%), valid0.69599(69.4%)\n",
      "-- train 0.63087(71.9%), valid0.69363(69.9%)\n",
      "-- train 0.66849(70.3%), valid0.70056(69.2%)\n",
      "-- train 0.74625(67.2%), valid0.76350(66.6%)\n",
      "-- train 0.72286(68.1%), valid0.73993(67.7%)\n",
      "Accuracy: 0.69960000217\n",
      "Accuracy: 0.691750000417\n",
      "Accuracy: 0.694349995255\n",
      "Accuracy: 0.680549997091\n",
      "Accuracy: 0.668800000846\n",
      "Accuracy: 0.676249994338\n",
      "Accuracy: 0.698950003088\n",
      "Accuracy: 0.697099995613\n",
      "Accuracy: 0.692649997771\n",
      "Accuracy: 0.691200000048\n",
      "Accuracy: 0.665899994969\n",
      "Accuracy: 0.660400000215\n",
      "Accuracy: 0.700450001657\n",
      "Accuracy: 0.694449996948\n",
      "Accuracy: 0.699250002205\n",
      "Accuracy: 0.691699996591\n",
      "Accuracy: 0.666049994528\n",
      "Accuracy: 0.676850003004\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  12\n",
      "-- train 0.58100(73.6%), valid0.70039(70.3%)\n",
      "-- train 0.66885(70.0%), valid0.70404(69.0%)\n",
      "-- train 0.64425(71.0%), valid0.70060(69.4%)\n",
      "-- train 0.70381(68.9%), valid0.72489(68.1%)\n",
      "-- train 0.72976(67.8%), valid0.74820(67.4%)\n",
      "-- train 0.72593(67.8%), valid0.73769(67.8%)\n",
      "-- train 0.58930(73.4%), valid0.69875(70.1%)\n",
      "-- train 0.65552(70.7%), valid0.69685(69.4%)\n",
      "-- train 0.63971(71.1%), valid0.70515(69.1%)\n",
      "-- train 0.67322(69.7%), valid0.69817(68.9%)\n",
      "-- train 0.75841(66.6%), valid0.77260(66.3%)\n",
      "-- train 0.77154(66.0%), valid0.77815(66.0%)\n",
      "-- train 0.59805(72.8%), valid0.69022(69.9%)\n",
      "-- train 0.65089(70.9%), valid0.69568(69.5%)\n",
      "-- train 0.61955(72.5%), valid0.69703(70.1%)\n",
      "-- train 0.65687(70.8%), valid0.69450(69.4%)\n",
      "-- train 0.74001(67.2%), valid0.76052(66.5%)\n",
      "-- train 0.71355(68.2%), valid0.73172(68.0%)\n",
      "Accuracy: 0.702699995041\n",
      "Accuracy: 0.689749997854\n",
      "Accuracy: 0.694350001216\n",
      "Accuracy: 0.680900001526\n",
      "Accuracy: 0.673800000548\n",
      "Accuracy: 0.678199996054\n",
      "Accuracy: 0.70094999969\n",
      "Accuracy: 0.694399999082\n",
      "Accuracy: 0.690799997747\n",
      "Accuracy: 0.689349997044\n",
      "Accuracy: 0.663249999285\n",
      "Accuracy: 0.66005000174\n",
      "Accuracy: 0.699399998784\n",
      "Accuracy: 0.694549997151\n",
      "Accuracy: 0.700750000775\n",
      "Accuracy: 0.694399999082\n",
      "Accuracy: 0.664599998295\n",
      "Accuracy: 0.679999996722\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  13\n",
      "-- train 0.57287(74.0%), valid0.70954(69.9%)\n",
      "-- train 0.65513(70.5%), valid0.69965(69.1%)\n",
      "-- train 0.63973(71.3%), valid0.70231(69.5%)\n",
      "-- train 0.71328(68.3%), valid0.73321(67.7%)\n",
      "-- train 0.72853(67.8%), valid0.74822(67.3%)\n",
      "-- train 0.72211(68.2%), valid0.73770(68.0%)\n",
      "-- train 0.58447(73.6%), valid0.70374(70.3%)\n",
      "-- train 0.64642(71.0%), valid0.69537(69.4%)\n",
      "-- train 0.63583(71.3%), valid0.70023(69.5%)\n",
      "-- train 0.66692(70.1%), valid0.69784(69.0%)\n",
      "-- train 0.75005(66.9%), valid0.76708(66.4%)\n",
      "-- train 0.77852(65.9%), valid0.78540(65.3%)\n",
      "-- train 0.58877(73.4%), valid0.69693(70.3%)\n",
      "-- train 0.65268(71.0%), valid0.70248(69.1%)\n",
      "-- train 0.61598(72.3%), valid0.70512(69.6%)\n",
      "-- train 0.64997(71.0%), valid0.69340(69.5%)\n",
      "-- train 0.73462(67.1%), valid0.75791(66.5%)\n",
      "-- train 0.71067(68.5%), valid0.72852(68.1%)\n",
      "Accuracy: 0.699049992859\n",
      "Accuracy: 0.691200000048\n",
      "Accuracy: 0.69509999752\n",
      "Accuracy: 0.677100001276\n",
      "Accuracy: 0.673000004888\n",
      "Accuracy: 0.680449996889\n",
      "Accuracy: 0.70285000056\n",
      "Accuracy: 0.694200000167\n",
      "Accuracy: 0.694749999046\n",
      "Accuracy: 0.689699994028\n",
      "Accuracy: 0.664200001955\n",
      "Accuracy: 0.653449995816\n",
      "Accuracy: 0.703299996257\n",
      "Accuracy: 0.691399997473\n",
      "Accuracy: 0.696349994838\n",
      "Accuracy: 0.695149996877\n",
      "Accuracy: 0.665300004184\n",
      "Accuracy: 0.680599999428\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  14\n",
      "-- train 0.57189(74.0%), valid0.72040(70.0%)\n",
      "-- train 0.65063(70.7%), valid0.70115(69.1%)\n",
      "-- train 0.63446(71.5%), valid0.70302(69.7%)\n",
      "-- train 0.69804(69.1%), valid0.71920(68.5%)\n",
      "-- train 0.72698(68.0%), valid0.74963(67.5%)\n",
      "-- train 0.72240(68.1%), valid0.73697(67.8%)\n",
      "-- train 0.58004(73.9%), valid0.71088(69.9%)\n",
      "-- train 0.63977(71.3%), valid0.69586(69.6%)\n",
      "-- train 0.62789(71.6%), valid0.70805(69.5%)\n",
      "-- train 0.66552(70.3%), valid0.69478(69.5%)\n",
      "-- train 0.75887(65.9%), valid0.77778(65.5%)\n",
      "-- train 0.75967(66.8%), valid0.76916(66.5%)\n",
      "-- train 0.58036(73.6%), valid0.70363(70.3%)\n",
      "-- train 0.64021(71.4%), valid0.69848(69.5%)\n",
      "-- train 0.61340(72.5%), valid0.70793(69.9%)\n",
      "-- train 0.65245(70.9%), valid0.69897(69.4%)\n",
      "-- train 0.72579(68.0%), valid0.74872(67.4%)\n",
      "-- train 0.71386(68.3%), valid0.72903(68.0%)\n",
      "Accuracy: 0.699699993432\n",
      "Accuracy: 0.691499997675\n",
      "Accuracy: 0.696699997783\n",
      "Accuracy: 0.685400001705\n",
      "Accuracy: 0.674699996412\n",
      "Accuracy: 0.677799993753\n",
      "Accuracy: 0.698949994147\n",
      "Accuracy: 0.695899999142\n",
      "Accuracy: 0.694899995625\n",
      "Accuracy: 0.69525000155\n",
      "Accuracy: 0.65530000329\n",
      "Accuracy: 0.665449994802\n",
      "Accuracy: 0.703349995613\n",
      "Accuracy: 0.694849999249\n",
      "Accuracy: 0.699200001359\n",
      "Accuracy: 0.694099996984\n",
      "Accuracy: 0.673699998856\n",
      "Accuracy: 0.679799999297\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n",
      "log : 130\n",
      "log : 140\n",
      "log : 150\n",
      "***epoch*** :  15\n",
      "-- train 0.56539(74.2%), valid0.73374(69.3%)\n",
      "-- train 0.64318(70.8%), valid0.69948(69.2%)\n",
      "-- train 0.62599(71.8%), valid0.70652(69.6%)\n",
      "-- train 0.69038(69.1%), valid0.71457(68.4%)\n",
      "-- train 0.71652(68.4%), valid0.74414(67.8%)\n",
      "-- train 0.72169(68.1%), valid0.73759(67.7%)\n",
      "-- train 0.57549(73.9%), valid0.71714(69.6%)\n",
      "-- train 0.63487(71.8%), valid0.69242(69.7%)\n",
      "-- train 0.62516(71.6%), valid0.70454(69.6%)\n",
      "-- train 0.65729(70.3%), valid0.69121(69.1%)\n",
      "-- train 0.74394(66.2%), valid0.76578(65.7%)\n",
      "-- train 0.75234(66.1%), valid0.76627(65.3%)\n",
      "-- train 0.58232(73.7%), valid0.71396(69.9%)\n",
      "-- train 0.63427(71.8%), valid0.69583(69.7%)\n",
      "-- train 0.60914(72.5%), valid0.71293(69.6%)\n",
      "-- train 0.64599(71.2%), valid0.69602(69.3%)\n",
      "-- train 0.72238(67.8%), valid0.74779(67.2%)\n",
      "-- train 0.69865(68.9%), valid0.71922(68.3%)\n",
      "Accuracy: 0.693449994922\n",
      "Accuracy: 0.692199999094\n",
      "Accuracy: 0.695749996603\n",
      "Accuracy: 0.684199997783\n",
      "Accuracy: 0.677500000596\n",
      "Accuracy: 0.676549996436\n",
      "Accuracy: 0.69604999423\n",
      "Accuracy: 0.696999998391\n",
      "Accuracy: 0.695549999177\n",
      "Accuracy: 0.691249997914\n",
      "Accuracy: 0.656650003791\n",
      "Accuracy: 0.653250002861\n",
      "Accuracy: 0.698749999702\n",
      "Accuracy: 0.696799997985\n",
      "Accuracy: 0.695999996364\n",
      "Accuracy: 0.692749999464\n",
      "Accuracy: 0.672099998593\n",
      "Accuracy: 0.68315000087\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "log : 40\n",
      "log : 50\n",
      "log : 60\n",
      "log : 70\n",
      "log : 80\n",
      "log : 90\n",
      "log : 100\n",
      "log : 110\n",
      "log : 120\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-db6de48a297d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mavg_cost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-50e00f0a2e93>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_input, Y_input, learning_rate, training)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "# train my model\n",
    "for epoch in range(total_epoch):\n",
    "    avg_cost = [0]*len(model_lst)\n",
    "    total_batch = int(len(training_lst) / batch_size)\n",
    "    idx = 0\n",
    "    \n",
    "    if epoch == 0 :\n",
    "        learning_rate = learning_rate1\n",
    "    elif epoch == 10 :\n",
    "        learning_rate = learning_rate2\n",
    "    elif epoch == 20 :\n",
    "        learning_rate = learning_rate3\n",
    "    elif epoch == 80 :\n",
    "        learning_rate = learning_rate4\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = training_lst[idx:idx+batch_size],training_label[idx:idx+batch_size]\n",
    "        \n",
    "        for model_num, model in enumerate(model_lst) :\n",
    "            _, c = model.train(batch_xs, batch_ys, learning_rate)\n",
    "            avg_cost[model_num] += c / total_batch\n",
    "        \n",
    "        idx += batch_size\n",
    "        if i%10 == 0 :\n",
    "            print(\"log :\", i)\n",
    "            \n",
    "    #train/valid cost & acc\n",
    "    print(\"***epoch*** : \", epoch)\n",
    "    for model_num, model in enumerate(model_lst) :\n",
    "        train_cost, train_acc = model.evaluate(training_lst, training_label)\n",
    "        valid_cost, valid_acc = model.evaluate(valid_lst, valid_label)\n",
    "\n",
    "        tl_ta_vl_va_lst[model_num][0].append(train_cost)\n",
    "        tl_ta_vl_va_lst[model_num][1].append(train_acc)\n",
    "        tl_ta_vl_va_lst[model_num][2].append(valid_cost)\n",
    "        tl_ta_vl_va_lst[model_num][3].append(valid_acc)\n",
    "\n",
    "        print(\"-- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(train_cost, train_acc*100, valid_cost, valid_acc*100))\n",
    "    \n",
    "    for model in model_lst :\n",
    "        print('Accuracy:', model.evaluate(valid_lst, valid_label)[1])\n",
    "    print(\" \")\n",
    "\n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <br></br><br></br><br></br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst)) :\n",
    "    plt.plot(tl_ta_vl_va_lst[idx][0], label='training'+str(idx))\n",
    "    plt.plot(tl_ta_vl_va_lst[idx][2], label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst)) :\n",
    "    plt.plot(tl_ta_vl_va_lst[idx][1], label='training'+str(idx))\n",
    "    plt.plot(tl_ta_vl_va_lst[idx][3], label='valid'+str(idx))\n",
    "    plt.title(\"model\"+str(idx))\n",
    "    plt.grid(\"on\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst)) :\n",
    "    plt.plot(tl_ta_vl_va_lst[idx][0], label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst)) :\n",
    "    plt.plot(tl_ta_vl_va_lst[idx][2], label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst)) :\n",
    "    plt.plot(tl_ta_vl_va_lst[idx][1], label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(model_lst)) :\n",
    "    plt.plot(tl_ta_vl_va_lst[idx][3], label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <br></br><br></br><br></br>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./advanced_RNN/original_user_vector/original'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "for idx, model in enumerate(model_lst) :\n",
    "    saver.save(model.sess, './model/MLP_default_model_{}'.format(idx))\n",
    "\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def making_data(csv) :\n",
    "    activity = pd.read_csv(csv).drop(\"Unnamed: 0\", axis=1)\n",
    "    \n",
    "    activity = activity[activity[\"label\"] == \"empty\"]\n",
    "    activity = activity.drop(\"label\", axis=1)\n",
    "    \n",
    "    activity = activity.sort_values([\"acc_id\",\"wk\"])[['acc_id', 'wk', 'cnt_clear_bam', 'cnt_clear_inzone_light','cnt_clear_inzone_normal', \n",
    "                                                  'cnt_clear_inzone_skilled', 'cnt_clear_inzone_solo', 'cnt_clear_raid', 'cnt_clear_raid_light',\n",
    "                                                  'cnt_dt', 'cnt_enter_bam', 'cnt_enter_inzone_light', 'cnt_enter_inzone_normal', \n",
    "                                                  'cnt_enter_inzone_skilled', 'cnt_enter_inzone_solo', 'cnt_enter_raid', 'cnt_enter_raid_light',\n",
    "                                                  'cnt_use_buffitem', 'district_chat', 'duel_cnt', 'duel_win', 'faction_chat', 'game_combat_time', \n",
    "                                                  'gathering_cnt', 'get_money','guild_chat', 'item_hongmun', 'making_cnt', 'normal_chat', \n",
    "                                                  'npc_exp', 'npc_hongmun', 'party_chat', 'partybattle_cnt', 'partybattle_win', 'play_time', \n",
    "                                                  'quest_exp', 'quest_hongmun', 'whisper_chat','first_week', 'payment_amount']]\n",
    "    \n",
    "    activity1 = activity[activity[\"wk\"]==1].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity2 = activity[activity[\"wk\"]==2].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity3 = activity[activity[\"wk\"]==3].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity4 = activity[activity[\"wk\"]==4].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity5 = activity[activity[\"wk\"]==5].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity6 = activity[activity[\"wk\"]==6].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity7 = activity[activity[\"wk\"]==7].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    activity8 = activity[activity[\"wk\"]==8].drop([\"acc_id\", \"wk\"], axis=1)\n",
    "    \n",
    "    label = activity[\"acc_id\"].values\n",
    "    activity = np.concatenate([activity1.values, activity2.values, activity3.values, activity4.values,\n",
    "                               activity5.values, activity6.values, activity7.values, activity8.values], axis=1)\n",
    "\n",
    "    total_lst = activity\n",
    "    return total_lst, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data, test_acc_id = making_data(\"OnlyExpanded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for model in model_lst :\n",
    "    result.append(np.argmax(model.predict(test_data), axis=2)) \n",
    "    \n",
    "result = list(map(lambda x : x.tolist()[0], result))\n",
    "for r_lst in result :\n",
    "    print(\"week: {}, month: {}, 2month: {}, retained: {}\".format(r_lst.count(0), r_lst.count(1), r_lst.count(2), r_lst.count(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame(sorted(list(set(list(test_acc_id))))).rename(columns = {0 : \"acc_id\"})\n",
    "result_df = pd.DataFrame(result).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df2 = pd.concat([label_df, result_df], axis=1)\n",
    "result_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
