{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>week-tree</th>\n",
       "      <th>month-tree</th>\n",
       "      <th>2month-tree</th>\n",
       "      <th>retained-tree</th>\n",
       "      <th>retained-week-tree</th>\n",
       "      <th>retained-month-tree</th>\n",
       "      <th>retained-2month-tree</th>\n",
       "      <th>retained-2month-week_month-tree</th>\n",
       "      <th>retained-week-month_2month-tree</th>\n",
       "      <th>...</th>\n",
       "      <th>week-2month-tree</th>\n",
       "      <th>week-retained-tree</th>\n",
       "      <th>week-retained-month_2month-tree</th>\n",
       "      <th>week-month-2month_retained-tree</th>\n",
       "      <th>week-2month-month_retained-tree</th>\n",
       "      <th>total_week</th>\n",
       "      <th>total_month</th>\n",
       "      <th>total_2month</th>\n",
       "      <th>total_retained</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cce8cf742d779df73ac7d13effb2fe76cf06cc8c4fb6ee...</td>\n",
       "      <td>1.509710e-02</td>\n",
       "      <td>0.889619</td>\n",
       "      <td>8.607723e-03</td>\n",
       "      <td>0.020867</td>\n",
       "      <td>0.058788</td>\n",
       "      <td>0.942421</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.930623</td>\n",
       "      <td>1.152129e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.021363</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051316</td>\n",
       "      <td>1.031506e-01</td>\n",
       "      <td>0.879038</td>\n",
       "      <td>4.910580e-03</td>\n",
       "      <td>0.012901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cce8f7a34235ec6c08b13e41afcafb667c8a0f63dc429f...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.066952e-08</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.324211e-25</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>6.628296e-17</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cce9bf6a13008fc11ecdc2c855ff844e869eceeda22ebc...</td>\n",
       "      <td>5.917798e-01</td>\n",
       "      <td>0.022067</td>\n",
       "      <td>5.577732e-02</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.683343</td>\n",
       "      <td>0.084129</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.092162</td>\n",
       "      <td>5.637858e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077653</td>\n",
       "      <td>0.075693</td>\n",
       "      <td>0.202722</td>\n",
       "      <td>0.108016</td>\n",
       "      <td>0.149553</td>\n",
       "      <td>5.826866e-01</td>\n",
       "      <td>0.232607</td>\n",
       "      <td>8.504402e-02</td>\n",
       "      <td>0.099663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ccebea3ff3a74ae9c9ce4a15e2f80f8a336ae1a0ba3e53...</td>\n",
       "      <td>1.536979e-35</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>3.578402e-01</td>\n",
       "      <td>0.883604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459865</td>\n",
       "      <td>0.579961</td>\n",
       "      <td>0.766740</td>\n",
       "      <td>0.934080</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>2.790499e-07</td>\n",
       "      <td>0.018602</td>\n",
       "      <td>3.068831e-01</td>\n",
       "      <td>0.674514</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ccec4f896d13bdcbf2279760bda2bbd7b4bdac229761f9...</td>\n",
       "      <td>5.100701e-25</td>\n",
       "      <td>0.013531</td>\n",
       "      <td>2.349116e-05</td>\n",
       "      <td>0.928284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.904302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.998422</td>\n",
       "      <td>1.475391e-11</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>8.480202e-03</td>\n",
       "      <td>0.990378</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              acc_id     week-tree  \\\n",
       "0  cce8cf742d779df73ac7d13effb2fe76cf06cc8c4fb6ee...  1.509710e-02   \n",
       "1  cce8f7a34235ec6c08b13e41afcafb667c8a0f63dc429f...  0.000000e+00   \n",
       "2  cce9bf6a13008fc11ecdc2c855ff844e869eceeda22ebc...  5.917798e-01   \n",
       "3  ccebea3ff3a74ae9c9ce4a15e2f80f8a336ae1a0ba3e53...  1.536979e-35   \n",
       "4  ccec4f896d13bdcbf2279760bda2bbd7b4bdac229761f9...  5.100701e-25   \n",
       "\n",
       "   month-tree   2month-tree  retained-tree  retained-week-tree  \\\n",
       "0    0.889619  8.607723e-03       0.020867            0.058788   \n",
       "1    0.000000  1.066952e-08       0.999995            0.000000   \n",
       "2    0.022067  5.577732e-02       0.009783            0.683343   \n",
       "3    0.000056  3.578402e-01       0.883604            0.000000   \n",
       "4    0.013531  2.349116e-05       0.928284            0.000000   \n",
       "\n",
       "   retained-month-tree  retained-2month-tree  retained-2month-week_month-tree  \\\n",
       "0             0.942421              0.000255                         0.930623   \n",
       "1             0.000000              0.000000                         0.000000   \n",
       "2             0.084129              0.008913                         0.092162   \n",
       "3             0.000000              0.000000                         0.000000   \n",
       "4             0.000000              0.000000                         0.000000   \n",
       "\n",
       "   retained-week-month_2month-tree  ...    week-2month-tree  \\\n",
       "0                     1.152129e-07  ...            0.003331   \n",
       "1                     0.000000e+00  ...            0.000000   \n",
       "2                     5.637858e-01  ...            0.077653   \n",
       "3                     0.000000e+00  ...            0.459865   \n",
       "4                     0.000000e+00  ...            0.000002   \n",
       "\n",
       "   week-retained-tree  week-retained-month_2month-tree  \\\n",
       "0            0.021363                         0.000002   \n",
       "1            1.000000                         0.000000   \n",
       "2            0.075693                         0.202722   \n",
       "3            0.579961                         0.766740   \n",
       "4            0.904302                         0.000000   \n",
       "\n",
       "   week-month-2month_retained-tree  week-2month-month_retained-tree  \\\n",
       "0                         0.000000                         0.051316   \n",
       "1                         1.000000                         1.000000   \n",
       "2                         0.108016                         0.149553   \n",
       "3                         0.934080                         0.999996   \n",
       "4                         0.999896                         0.998422   \n",
       "\n",
       "     total_week  total_month  total_2month  total_retained  label  \n",
       "0  1.031506e-01     0.879038  4.910580e-03        0.012901      1  \n",
       "1  1.324211e-25     0.000005  6.628296e-17        0.999995      3  \n",
       "2  5.826866e-01     0.232607  8.504402e-02        0.099663      0  \n",
       "3  2.790499e-07     0.018602  3.068831e-01        0.674514      2  \n",
       "4  1.475391e-11     0.001142  8.480202e-03        0.990378      3  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = pd.read_csv(\"final_result/valid_250_epoch.csv\").rename(columns = {\"Unnamed: 0\" : \"acc_id\"}).fillna(0)\n",
    "\n",
    "print(len(valid))\n",
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_id</th>\n",
       "      <th>week-tree</th>\n",
       "      <th>month-tree</th>\n",
       "      <th>2month-tree</th>\n",
       "      <th>retained-tree</th>\n",
       "      <th>retained-week-tree</th>\n",
       "      <th>retained-month-tree</th>\n",
       "      <th>retained-2month-tree</th>\n",
       "      <th>retained-2month-week_month-tree</th>\n",
       "      <th>retained-week-month_2month-tree</th>\n",
       "      <th>...</th>\n",
       "      <th>week-month-tree</th>\n",
       "      <th>week-2month-tree</th>\n",
       "      <th>week-retained-tree</th>\n",
       "      <th>week-retained-month_2month-tree</th>\n",
       "      <th>week-month-2month_retained-tree</th>\n",
       "      <th>week-2month-month_retained-tree</th>\n",
       "      <th>total_week</th>\n",
       "      <th>total_month</th>\n",
       "      <th>total_2month</th>\n",
       "      <th>total_retained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002a56a036206aea3a6c6ebc985df4a2d1987b562e7f0...</td>\n",
       "      <td>1.282105e-18</td>\n",
       "      <td>0.287728</td>\n",
       "      <td>7.576508e-01</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>8.865926e-10</td>\n",
       "      <td>0.335192</td>\n",
       "      <td>0.289518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367014</td>\n",
       "      <td>0.343396</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.778505</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.010793</td>\n",
       "      <td>2.567430e-09</td>\n",
       "      <td>0.559539</td>\n",
       "      <td>0.438544</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003bfdebe2b5d46217e8fa5ab0f33cf186fb558435f20...</td>\n",
       "      <td>1.116987e-09</td>\n",
       "      <td>0.011985</td>\n",
       "      <td>5.927302e-12</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>9.999859e-01</td>\n",
       "      <td>0.177245</td>\n",
       "      <td>0.998754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728745</td>\n",
       "      <td>0.037440</td>\n",
       "      <td>0.955744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687728</td>\n",
       "      <td>6.980182e-03</td>\n",
       "      <td>0.970919</td>\n",
       "      <td>0.011460</td>\n",
       "      <td>0.010641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008f5dce798aaac3f0b05f8a4269cf2052c9b8c5bd911...</td>\n",
       "      <td>3.464303e-08</td>\n",
       "      <td>0.219554</td>\n",
       "      <td>7.482451e-01</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>2.858964e-05</td>\n",
       "      <td>0.281202</td>\n",
       "      <td>0.780203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261161</td>\n",
       "      <td>0.708864</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.701051</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.117059e-04</td>\n",
       "      <td>0.297933</td>\n",
       "      <td>0.692900</td>\n",
       "      <td>0.009055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000cacd86bddabebef813351455304df5493cd71a3d1d2...</td>\n",
       "      <td>1.226835e-07</td>\n",
       "      <td>0.244845</td>\n",
       "      <td>7.135513e-01</td>\n",
       "      <td>0.051405</td>\n",
       "      <td>4.137673e-04</td>\n",
       "      <td>0.343690</td>\n",
       "      <td>0.738547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.734775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226864</td>\n",
       "      <td>0.735483</td>\n",
       "      <td>0.067612</td>\n",
       "      <td>0.768146</td>\n",
       "      <td>0.055259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.238303e-03</td>\n",
       "      <td>0.233987</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.048639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000ef0765596ac6a6a0a62654895e4673825b6102c7f41...</td>\n",
       "      <td>1.003806e-08</td>\n",
       "      <td>0.275327</td>\n",
       "      <td>3.624003e-01</td>\n",
       "      <td>0.614117</td>\n",
       "      <td>3.040017e-04</td>\n",
       "      <td>0.428519</td>\n",
       "      <td>0.391759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.585624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065011</td>\n",
       "      <td>0.333975</td>\n",
       "      <td>0.439294</td>\n",
       "      <td>0.506607</td>\n",
       "      <td>0.457827</td>\n",
       "      <td>0.540175</td>\n",
       "      <td>1.059176e-05</td>\n",
       "      <td>0.370309</td>\n",
       "      <td>0.351657</td>\n",
       "      <td>0.278023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              acc_id     week-tree  \\\n",
       "0  0002a56a036206aea3a6c6ebc985df4a2d1987b562e7f0...  1.282105e-18   \n",
       "1  0003bfdebe2b5d46217e8fa5ab0f33cf186fb558435f20...  1.116987e-09   \n",
       "2  0008f5dce798aaac3f0b05f8a4269cf2052c9b8c5bd911...  3.464303e-08   \n",
       "3  000cacd86bddabebef813351455304df5493cd71a3d1d2...  1.226835e-07   \n",
       "4  000ef0765596ac6a6a0a62654895e4673825b6102c7f41...  1.003806e-08   \n",
       "\n",
       "   month-tree   2month-tree  retained-tree  retained-week-tree  \\\n",
       "0    0.287728  7.576508e-01       0.000014        8.865926e-10   \n",
       "1    0.011985  5.927302e-12       0.001180        9.999859e-01   \n",
       "2    0.219554  7.482451e-01       0.007912        2.858964e-05   \n",
       "3    0.244845  7.135513e-01       0.051405        4.137673e-04   \n",
       "4    0.275327  3.624003e-01       0.614117        3.040017e-04   \n",
       "\n",
       "   retained-month-tree  retained-2month-tree  retained-2month-week_month-tree  \\\n",
       "0             0.335192              0.289518                              1.0   \n",
       "1             0.177245              0.998754                              0.0   \n",
       "2             0.281202              0.780203                              0.0   \n",
       "3             0.343690              0.738547                              0.0   \n",
       "4             0.428519              0.391759                              1.0   \n",
       "\n",
       "   retained-week-month_2month-tree       ...        week-month-tree  \\\n",
       "0                         0.714316       ...               0.367014   \n",
       "1                         0.000000       ...               0.728745   \n",
       "2                         0.730266       ...               0.261161   \n",
       "3                         0.734775       ...               0.226864   \n",
       "4                         0.585624       ...               0.065011   \n",
       "\n",
       "   week-2month-tree  week-retained-tree  week-retained-month_2month-tree  \\\n",
       "0          0.343396            0.000370                         0.778505   \n",
       "1          0.037440            0.955744                         0.000000   \n",
       "2          0.708864            0.006113                         0.701051   \n",
       "3          0.735483            0.067612                         0.768146   \n",
       "4          0.333975            0.439294                         0.506607   \n",
       "\n",
       "   week-month-2month_retained-tree  week-2month-month_retained-tree  \\\n",
       "0                         0.001731                         0.010793   \n",
       "1                         0.000000                         0.687728   \n",
       "2                         0.007394                         0.000000   \n",
       "3                         0.055259                         0.000000   \n",
       "4                         0.457827                         0.540175   \n",
       "\n",
       "     total_week  total_month  total_2month  total_retained  \n",
       "0  2.567430e-09     0.559539      0.438544        0.001917  \n",
       "1  6.980182e-03     0.970919      0.011460        0.010641  \n",
       "2  1.117059e-04     0.297933      0.692900        0.009055  \n",
       "3  1.238303e-03     0.233987      0.716136        0.048639  \n",
       "4  1.059176e-05     0.370309      0.351657        0.278023  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"final_result/test_250_epoch.csv\").rename(columns = {\"Unnamed: 0\" : \"acc_id\"}).fillna(0)\n",
    "\n",
    "print(len(test))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  ['week-tree', 'total_week', 'retained-week-tree',\n",
    "             'month-tree', \"total_month\", 'retained-month-tree', 'retained-2month-week_month-tree', 'week-month-tree',\n",
    "             '2month-tree', \"total_2month\", 'retained-2month-tree', 'retained-week-month_2month-tree', 'retained-month-week_2month-tree', 'week-2month-tree', 'week-retained-month_2month-tree', \n",
    "             'retained-tree', \"total_retained\",'week-retained-tree', 'week-month-2month_retained-tree', 'week-2month-month_retained-tree']\n",
    "\n",
    "target = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "valid F1 score : 0.835019533206\n",
    "valid F1 score : 0.511169513798\n",
    "valid F1 score : 0.624146637987\n",
    "valid F1 score : 0.759031198686\n",
    "valid F1 score : 0.857057237039\n",
    "valid F1 score : 0.559139784946\n",
    "valid F1 score : 0.721834139352\n",
    "valid F1 score : 0.882810071495\n",
    "valid F1 score : 0.74330571304\n",
    "valid F1 score : 0.930932160033\n",
    "valid F1 score : 0.604991177212\n",
    "valid F1 score : 0.628211250119\n",
    "valid F1 score : 0.776022020593\n",
    "valid F1 score : 0.747978788142\n",
    "valid F1 score : 0.829327654396\n",
    "valid F1 score : 0.873835053613\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1_score(solution, submission):\n",
    "    a=pd.DataFrame(submission,columns=['Y_hat'])\n",
    "    b=pd.DataFrame(solution.tolist(),columns=['Y'])\n",
    "    c=pd.concat([a,b],axis=1)\n",
    "    \n",
    "    tot_table=c.groupby(['Y','Y_hat']).Y_hat.count().unstack()\n",
    "    accuracy=np.sum(np.diag(np.array(tot_table)))/len(c)\n",
    "     \n",
    "    f1_score=1/(np.mean(np.concatenate([1/np.diag(tot_table/tot_table.sum(axis=0)),1/np.diag(tot_table/tot_table.sum(axis=1))])))\n",
    "    print('final accuracy:%s'%(accuracy))    \n",
    "    print('final_f1_score:%s'%(f1_score))   \n",
    "    print()\n",
    "    \n",
    "    return f1_score \n",
    "\n",
    "my_scorer = make_scorer(my_f1_score, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "final accuracy:0.243285446596\n",
      "final_f1_score:0.242071165155\n",
      "\n",
      "final accuracy:0.475464916393\n",
      "final_f1_score:0.47548182803\n",
      "\n",
      "final accuracy:0.255465334166\n",
      "final_f1_score:0.253675178585\n",
      "\n",
      "final accuracy:0.465775902485\n",
      "final_f1_score:0.465728430259\n",
      "\n",
      "final accuracy:0.254375\n",
      "final_f1_score:0.25270023719\n",
      "\n",
      "final accuracy:0.480703125\n",
      "final_f1_score:0.480143215552\n",
      "\n",
      "final accuracy:0.253595997498\n",
      "final_f1_score:0.252760703255\n",
      "\n",
      "final accuracy:0.469067333229\n",
      "final_f1_score:0.468955652912\n",
      "\n",
      "final accuracy:0.243902439024\n",
      "final_f1_score:0.24382817282\n",
      "\n",
      "final accuracy:0.482346508358\n",
      "final_f1_score:0.48231899172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   46.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=200,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(my_f1_score), verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 16000\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=200)\n",
    "xgb_grid = GridSearchCV(xgb, param_grid={}, scoring=my_scorer, cv=5, verbose=1)\n",
    "\n",
    "xgb_grid.fit(valid[:idx][features], valid[:idx][target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1_score2(solution, submission):\n",
    "    a=pd.DataFrame(submission,columns=['Y_hat'])\n",
    "    b=pd.DataFrame(solution,columns=['Y'])\n",
    "    c=pd.concat([a,b],axis=1)\n",
    "    \n",
    "    tot_table=c.groupby(['Y','Y_hat']).Y_hat.count().unstack()\n",
    "    accuracy=np.sum(np.diag(np.array(tot_table)))/len(c)\n",
    "     \n",
    "    f1_score=1/(np.mean(np.concatenate([1/np.diag(tot_table/tot_table.sum(axis=0)),1/np.diag(tot_table/tot_table.sum(axis=1))])))\n",
    "    return f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- 1 ----\n",
      "0.683098272592 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0]\n",
      "0.684418244763 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1]\n",
      "0.685108969477 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 2]\n",
      "0.6855744701 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 2]\n",
      "0.685642301194 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 2 0]\n",
      "0.685755238801 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 2 1]\n",
      "0.686620713619 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 2 0]\n",
      "0.686653783502 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 2 1 1 2 0]\n",
      "0.68667726168 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 2 2 0 2 0]\n",
      "0.686738642214 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 3 1 0 2 0]\n",
      "0.687083521777 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 1 0 2 1]\n",
      "0.687301332051 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 1 0 2 2]\n",
      "0.68750118393 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 2 0 1 1]\n",
      "0.687506581457 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 2 1 1 1]\n",
      "0.687506872481 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 3 1 0 0]\n",
      "0.687585731073 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 4 0 1 0]\n",
      "0.687691040691 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 4 0 1 1]\n",
      "0.688101900405 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 4 2 0 0]\n",
      "0.688162862113 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 2 3 2 0 0]\n",
      "0.6882740282 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 2 4 1 0 0]\n",
      "0.688289068158 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 4 3 0 0 0]\n",
      "0.688368281751 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 5 1 1 0 0]\n",
      "0.688376798841 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 5 2 0 0 0]\n",
      "0.688567089652 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 2 1 4 0 0 2]\n",
      "0.688779608391 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 2 2 3 0 0 2]\n",
      "0.688809742117 [1 1 0 1 1 0 0 0 1 1 0 0 0 0 2 4 1 0 0 2]\n",
      "0.688904030175 [1 1 0 1 1 0 0 0 1 1 0 0 0 1 2 1 2 2 0 2]\n",
      "0.689056555345 [1 1 0 1 1 0 0 0 1 1 0 0 0 1 2 1 4 0 0 2]\n",
      "0.689157806367 [1 1 0 1 1 0 0 0 1 1 0 0 0 1 2 2 3 0 0 2]\n",
      "0.689338507393 [1 1 0 1 1 0 0 0 1 1 0 0 0 1 2 4 1 0 0 2]\n",
      "0.689437932575 [1 1 0 1 1 0 0 0 1 1 0 0 0 2 2 1 1 0 1 1]\n",
      "0.690000356359 [1 1 0 1 1 0 0 0 1 1 0 0 0 2 2 1 1 0 2 1]\n",
      "0.690136443819 [1 1 0 1 1 0 0 0 1 1 0 0 1 1 2 4 1 0 0 2]\n",
      "0.690177412319 [1 1 0 1 1 0 0 0 1 1 0 0 2 2 1 4 1 1 0 1]\n",
      "0.69058581866 [1 1 0 1 1 0 0 0 1 1 0 0 2 2 2 1 4 0 0 2]\n",
      "0.690629716162 [1 1 0 1 1 0 0 0 1 1 0 0 2 2 2 3 2 0 1 1]\n",
      "0.690706870458 [1 1 0 1 1 0 0 0 1 1 0 0 2 2 2 4 1 0 0 2]\n",
      "0.690852335821 [1 1 0 1 1 0 0 0 1 1 0 0 2 2 2 4 1 1 0 1]\n",
      "0.690934574547 [1 1 0 1 1 0 0 0 1 1 0 1 0 2 2 5 1 1 0 0]\n",
      "0.691229807135 [1 1 0 1 1 0 0 0 1 1 0 1 1 2 2 1 1 2 1 2]\n",
      "0.691351292453 [1 1 0 1 1 0 0 0 1 1 0 1 1 2 2 1 2 2 2 1]\n",
      "0.69144484345 [1 1 0 1 1 0 0 0 1 1 0 1 2 2 2 3 2 1 0 1]\n",
      "0.691591034142 [1 1 0 1 1 0 0 0 1 1 0 1 2 2 2 4 1 0 1 1]\n",
      "0.691609688612 [1 1 0 1 1 0 0 0 1 1 0 2 0 2 2 1 1 2 0 1]\n",
      "0.691695828362 [1 1 0 1 1 0 0 0 1 1 0 2 0 2 2 1 1 2 1 2]\n",
      "0.691768789519 [1 1 0 1 1 0 0 0 1 1 0 2 0 2 2 1 2 1 0 1]\n",
      "0.691913257649 [1 1 0 1 1 0 0 0 1 1 0 2 0 2 2 3 1 1 0 1]\n",
      "0.692067821758 [1 1 0 1 1 0 0 0 1 1 0 2 1 2 2 1 1 1 0 2]\n",
      "0.692226922109 [1 1 0 1 1 0 0 0 1 1 0 2 1 2 2 1 2 1 0 2]\n",
      "0.692295470637 [1 1 0 1 1 0 0 0 1 1 0 2 1 2 2 1 2 2 0 1]\n",
      "0.692468757656 [1 1 0 1 1 0 0 0 1 1 0 2 1 2 2 1 3 1 0 1]\n",
      "0.692480995573 [1 1 0 1 1 0 0 0 1 1 0 2 1 2 2 2 2 1 0 1]\n",
      "0.692493805521 [1 1 0 1 1 0 0 0 1 1 0 2 1 2 2 3 1 1 0 1]\n",
      "0.692577216345 [1 1 0 1 1 0 0 0 1 1 1 1 2 2 2 2 3 0 1 1]\n",
      "0.692595104786 [1 1 0 1 1 0 0 0 1 1 1 1 2 2 2 3 1 1 1 1]\n",
      "0.69261642095 [1 1 0 1 1 0 0 0 1 1 1 1 2 2 2 3 2 0 1 1]\n",
      "0.692860598532 [1 1 0 1 1 0 0 0 1 1 1 2 1 1 2 1 2 2 0 1]\n",
      "0.692874606585 [1 1 0 1 1 0 0 0 1 1 1 2 1 1 2 2 1 2 0 1]\n",
      "0.693087247184 [1 1 0 1 1 0 0 0 1 1 1 2 2 2 2 1 3 2 0 1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e6a087c4faa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m                                                                                 \u001b[0mresult_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                                                                                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_f1_score2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                                                                                 \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_score\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f35fe77fa97f>\u001b[0m in \u001b[0;36mmy_f1_score2\u001b[0;34m(solution, submission)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mf1_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_table\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtot_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_table\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtot_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_series\u001b[0;34m(self, other, func, fill_value, axis, level)\u001b[0m\n\u001b[1;32m   3583\u001b[0m                                                    fill_value=fill_value)\n\u001b[1;32m   3584\u001b[0m         return self._combine_series_infer(other, func, level=level,\n\u001b[0;32m-> 3585\u001b[0;31m                                           fill_value=fill_value)\n\u001b[0m\u001b[1;32m   3586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_series_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_series_infer\u001b[0;34m(self, other, func, level, fill_value)\u001b[0m\n\u001b[1;32m   3595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3596\u001b[0m         return self._combine_match_columns(other, func, level=level,\n\u001b[0;32m-> 3597\u001b[0;31m                                            fill_value=fill_value)\n\u001b[0m\u001b[1;32m   3598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_match_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_match_columns\u001b[0;34m(self, other, func, level, fill_value)\u001b[0m\n\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m         new_data = left._data.eval(func=func, other=right,\n\u001b[0;32m-> 3617\u001b[0;31m                                    axes=[left.columns, self.index])\n\u001b[0m\u001b[1;32m   3618\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3056\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3057\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, func, other, raise_on_error, try_cast, mgr)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# get the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3089\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3090\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseterr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_Unspecified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3092\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseterrcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mseterr\u001b[0;34m(all, divide, over, under, invalid)\u001b[0m\n\u001b[1;32m   2782\u001b[0m     maskvalue = ((_errdict[divide] << SHIFT_DIVIDEBYZERO) +\n\u001b[1;32m   2783\u001b[0m                  \u001b[0;34m(\u001b[0m\u001b[0m_errdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mSHIFT_OVERFLOW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2784\u001b[0;31m                  \u001b[0;34m(\u001b[0m\u001b[0m_errdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mSHIFT_UNDERFLOW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2785\u001b[0m                  (_errdict[invalid] << SHIFT_INVALID))\n\u001b[1;32m   2786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "values = valid[features].values\n",
    "max_score = 0\n",
    "\n",
    "for idx0 in range(1,6) :\n",
    "    temp = 500-idx0\n",
    "    print()\n",
    "    print(\"----\",idx0,\"----\")\n",
    "    \n",
    "    for idx1 in range(1,6) :\n",
    "        temp -= idx1\n",
    "        \n",
    "        for idx2 in range(3) :\n",
    "            temp -= idx2\n",
    "            \n",
    "            for idx3 in range(1,6) :\n",
    "                temp -= idx3\n",
    "                \n",
    "                for idx4 in range(1,6) :\n",
    "                    temp -= idx4\n",
    "                    \n",
    "                    for idx5 in range(3) :\n",
    "                        temp -= idx5\n",
    "                        \n",
    "                        for idx6 in range(3) :\n",
    "                            temp -= idx6\n",
    "                            \n",
    "                            for idx7 in range(3) :\n",
    "                                temp -= idx7\n",
    "                                \n",
    "                                for idx8 in range(1,6) :\n",
    "                                    temp -= idx8\n",
    "                                    \n",
    "                                    for idx9 in range(1,6) :\n",
    "                                        temp -= idx9\n",
    "                                        \n",
    "                                        for idx10 in range(3) :\n",
    "                                            temp -= idx10\n",
    "                                            \n",
    "                                            for idx11 in range(3) :\n",
    "                                                temp -= idx11\n",
    "                                                \n",
    "                                                for idx12 in range(3) :\n",
    "                                                    temp -= idx12\n",
    "                                                    \n",
    "                                                    for idx13 in range(3) :\n",
    "                                                        temp -= idx13\n",
    "                                                        \n",
    "                                                        for idx14 in range(3) :\n",
    "                                                            temp -= idx14\n",
    "                                                            \n",
    "                                                            for idx15 in range(1,6) :\n",
    "                                                                temp -= idx15\n",
    "                                                                \n",
    "                                                                for idx16 in range(1,6) :\n",
    "                                                                    temp -= idx16\n",
    "                                                                    \n",
    "                                                                    for idx17 in range(3) :\n",
    "                                                                        temp -= idx17\n",
    "                                                                        \n",
    "                                                                        for idx18 in range(3) :\n",
    "                                                                            temp -= idx18\n",
    "                                                                            \n",
    "                                                                            for idx19 in range(3) :\n",
    "                                                                                week_1 = values[:,[0,1,2]]\n",
    "                                                                                week_2 = 1-values[:,[3,4,5,6,8,9,10,12,15,16]]\n",
    "                                                                                week_weight_1 = np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [0,1,2]])\n",
    "                                                                                week_weight_2 = np.array([6,6,3,3,6,6,3,3,6,6])-np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [3,4,5,6,8,9,10,12,15,16]])\n",
    "                                                                                \n",
    "                                                                                month_1 = values[:,[3,4,5,6,7]]\n",
    "                                                                                month_2 = 1-values[:,[0,1,2,8,9,10,11,13,14,15,16,17,19]]\n",
    "                                                                                month_weight_1 = np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [3,4,5,6,7]])\n",
    "                                                                                month_weight_2 = np.array([3,3,3,6,6,3,3,3,3,6,6,3,3])-np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [0,1,2,8,9,10,11,13,14,15,16,17,19]])\n",
    "                                                                                \n",
    "                                                                                month2_1 = values[:,[8,9,10,11,12,13,14]]\n",
    "                                                                                month2_2 = 1-values[:,[0,1,2,3,4,5,7,15,16,17,18]]\n",
    "                                                                                month2_weight_1 = np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [8,9,10,11,12,13,14]])\n",
    "                                                                                month2_weight_2 = np.array([6,6,3,6,6,3,3,6,6,3,3])-np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [0,1,2,3,4,5,7,15,16,17,18]])\n",
    "                                                                                \n",
    "                                                                                retained_1 = values[:,[15,16,17,18,19]]\n",
    "                                                                                retained_2 = 1-values[:,[0,1,3,4,7,8,9,13]]\n",
    "                                                                                retained_weight_1 = np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [15,16,17,18,19]])\n",
    "                                                                                retained_weight_2 = np.array([6,6,3,3,3,6,6,3])-np.array([eval(\"idx{}\".format(i)) for i in range(20) if i in [0,1,3,4,7,8,9,13]])\n",
    "                                                                                \n",
    "                                                                                week = (np.sum(week_1*week_weight_1, axis=1) + np.sum(week_2*week_weight_2, axis=1)) / (np.sum(week_weight_1) + np.sum(week_weight_2))\n",
    "                                                                                month = (np.sum(month_1*month_weight_1, axis=1) + np.sum(month_2*month_weight_2, axis=1)) / (np.sum(month_weight_1) + np.sum(month_weight_2))\n",
    "                                                                                month2 = (np.sum(month2_1*month2_weight_1, axis=1) + np.sum(month2_2*month2_weight_2, axis=1)) / (np.sum(month2_weight_1) + np.sum(month2_weight_2))\n",
    "                                                                                retained = (np.sum(retained_1*retained_weight_1, axis=1) + np.sum(retained_2*retained_weight_2, axis=1)) / (np.sum(retained_weight_1) + np.sum(retained_weight_2))\n",
    "                                                                                \n",
    "                                                                                result = np.concatenate([week.reshape([-1,1]), month.reshape([-1,1]), month2.reshape([-1,1]), retained.reshape([-1,1])], axis=1)\n",
    "                                                                                result_label = np.argmax(result, axis=1)\n",
    "                                                                                \n",
    "                                                                                score = my_f1_score2(result_label,valid[target].tolist())\n",
    "                                                                                \n",
    "                                                                                if score > max_score :\n",
    "                                                                                    max_score = score\n",
    "                                                                                    max_weight = np.array([eval(\"idx{}\".format(i)) for i in range(20)])\n",
    "                                                                                    print(max_score, max_weight)\n",
    "                                        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(lst, num_class=4) :\n",
    "    return np.eye(num_class)[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1_score2(solution, submission):\n",
    "    a=pd.DataFrame(submission,columns=['Y_hat'])\n",
    "    b=pd.DataFrame(solution,columns=['Y'])\n",
    "    c=pd.concat([a,b],axis=1)\n",
    "    \n",
    "    tot_table=c.groupby(['Y','Y_hat']).Y_hat.count().unstack()\n",
    "    accuracy=np.sum(np.diag(np.array(tot_table)))/len(c)\n",
    "     \n",
    "    f1_score=1/(np.mean(np.concatenate([1/np.diag(tot_table/tot_table.sum(axis=0)),1/np.diag(tot_table/tot_table.sum(axis=1))])))\n",
    "    return f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1_table(solution, submission):\n",
    "    a=pd.DataFrame(submission,columns=['Y_hat'])\n",
    "    b=pd.DataFrame(solution,columns=['Y'])\n",
    "    c=pd.concat([a,b],axis=1)\n",
    "    \n",
    "    tot_table=c.groupby(['Y','Y_hat']).Y_hat.count().unstack()\n",
    "    return tot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weight() :\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        \n",
    "    def convolution(self, input_X, kernel_size, width, num_filter, activation=True) :\n",
    "        conv = tf.layers.conv2d(input_X, filters=num_filter, kernel_size=[kernel_size, width], strides=1)\n",
    "        \n",
    "        if activation :\n",
    "            norm = tf.contrib.layers.layer_norm(conv)\n",
    "            relu = tf.nn.relu(norm)\n",
    "        \n",
    "            return relu\n",
    "        return conv\n",
    "        \n",
    "    def build(self, batch_size, input_dim, is_fc, fc_num_unit, output_dim) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            \n",
    "            ## Setting ##\n",
    "            self.batch_size = batch_size\n",
    "            self.input_dim = input_dim\n",
    "            self.output_dim = output_dim\n",
    "            self.is_fc = is_fc\n",
    "            self.fc_num_unit = fc_num_unit\n",
    "            \n",
    "            self.X = tf.placeholder(tf.float32, [None, self.input_dim])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, self.output_dim])\n",
    "            self.learning_rate =  tf.placeholder(tf.float32)\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            #############\n",
    "\n",
    "            \n",
    "            ## Weight ##\n",
    "            if self.is_fc : \n",
    "                self.fc_weight1 = tf.Variable(tf.random_normal([self.input_dim, self.fc_num_unit]))\n",
    "                self.fc_weight2 = tf.Variable(tf.random_normal([self.fc_num_unit, self.output_dim]))\n",
    "                \n",
    "                self.fc_weighted1 = tf.matmul(self.X, self.fc_weight1)\n",
    "                norm = tf.contrib.layers.layer_norm(self.fc_weighted1)\n",
    "                relu = tf.nn.relu(norm)\n",
    "                self.fc_weighted2 = tf.matmul(relu, self.fc_weight2)\n",
    "                \n",
    "                self.weighted =  self.fc_weighted2\n",
    "                \n",
    "            else :\n",
    "                self.weight = tf.Variable(tf.random_normal([self.input_dim, self.output_dim]))\n",
    "                self.weighted = tf.matmul(self.X, self.weight)\n",
    "            \n",
    "            self.logit = self.weighted\n",
    "            self.softmax = tf.nn.softmax(self.logit)\n",
    "            ################\n",
    "            \n",
    "            \n",
    "            ## Learning ##\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logit, labels=self.Y))\n",
    "\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.optimizer = tf.train.RMSPropOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "            \n",
    "            self.prediction = tf.equal(tf.argmax(self.logit, 1), tf.argmax(self.Y, 1))     \n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.prediction, tf.float32))    \n",
    "            ##############\n",
    "        \n",
    "        \n",
    "    def train(self, X_input, Y_input, learning_rate, training=True):\n",
    "        feed_dict = {self.X: X_input, self.Y: Y_input, self.learning_rate: learning_rate, self.training: training}\n",
    "        _, cost = self.sess.run([self.optimizer, self.cost], feed_dict=feed_dict)\n",
    "        \n",
    "        return _, cost\n",
    "    \n",
    "    def predict(self, X_input, training=False):\n",
    "        feed_dict = {self.X: X_input, self.training: training}\n",
    "        result = self.sess.run([self.logit], feed_dict=feed_dict)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input):\n",
    "        size = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for idx in range(0, size, self.batch_size):\n",
    "            X_batch = X_input[idx:idx + batch_size]\n",
    "            Y_batch = Y_input[idx:idx + batch_size]\n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: False}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= size\n",
    "        total_acc /= size\n",
    "            \n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate1 = 0.01\n",
    "learning_rate2 = 0.005\n",
    "learning_rate3 = 0.001\n",
    "\n",
    "total_epoch = 40\n",
    "batch_size = 500\n",
    "\n",
    "tl_ta_vl_va_lst = [[[],[],[],[],[]], [[],[],[],[],[]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "sess1 = tf.Session()\n",
    "model1 = Weight(sess1, \"model1\")\n",
    "model1.build(500, 20, True, 32, 4)\n",
    "sess1.run(tf.global_variables_initializer())\n",
    "\n",
    "sess2 = tf.Session()\n",
    "model2 = Weight(sess2, \"model2\")\n",
    "model2.build(500, 20, False, 32, 4)\n",
    "sess2.run(tf.global_variables_initializer())\n",
    "\n",
    "model_lst = [model1, model2]\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 16000\n",
    "\n",
    "training_lst = valid[:idx][features].values\n",
    "valid_lst = valid[idx:][features].values\n",
    "\n",
    "training_label = one_hot(valid[:idx][\"label\"])\n",
    "valid_label = one_hot(valid[idx:][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started!\n",
      "\n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  0\n",
      "-- train 1.11386(67.7%), valid1.09035(69.2%)\n",
      "-- train 1.94959(58.7%), valid1.99763(58.1%)\n",
      "f1 score: 0.674376464919\n",
      "f1 score: nan\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  1\n",
      "-- train 0.84879(69.5%), valid0.82987(70.4%)\n",
      "-- train 1.23798(60.0%), valid1.25950(59.3%)\n",
      "f1 score: 0.68292113369\n",
      "f1 score: 0.0931404774127\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  2\n",
      "-- train 0.75714(70.2%), valid0.73995(71.4%)\n",
      "-- train 0.84707(68.3%), valid0.84183(68.8%)\n",
      "f1 score: 0.686880967627\n",
      "f1 score: 0.667619484282\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  3\n",
      "-- train 0.71581(71.1%), valid0.70170(72.5%)\n",
      "-- train 0.77975(69.7%), valid0.76721(70.7%)\n",
      "f1 score: 0.696055258602\n",
      "f1 score: 0.688986428604\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  4\n",
      "-- train 0.69876(71.6%), valid0.68776(72.7%)\n",
      "-- train 0.74499(70.2%), valid0.73136(71.2%)\n",
      "f1 score: 0.698329362653\n",
      "f1 score: 0.693052305342\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  5\n",
      "-- train 0.68884(72.0%), valid0.67989(73.0%)\n",
      "-- train 0.72293(70.7%), valid0.70989(72.1%)\n",
      "f1 score: 0.702166108654\n",
      "f1 score: 0.701378136867\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  6\n",
      "-- train 0.68246(72.1%), valid0.67557(73.0%)\n",
      "-- train 0.70889(70.9%), valid0.69657(72.4%)\n",
      "f1 score: 0.701726231118\n",
      "f1 score: 0.703051324517\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  7\n",
      "-- train 0.67762(72.3%), valid0.67296(73.1%)\n",
      "-- train 0.70009(71.2%), valid0.68831(72.6%)\n",
      "f1 score: 0.703178906252\n",
      "f1 score: 0.705301206517\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  8\n",
      "-- train 0.67409(72.4%), valid0.67081(73.2%)\n",
      "-- train 0.69456(71.5%), valid0.68311(73.1%)\n",
      "f1 score: 0.702445925285\n",
      "f1 score: 0.709523054623\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  9\n",
      "-- train 0.67142(72.4%), valid0.66896(73.1%)\n",
      "-- train 0.69100(71.6%), valid0.67976(73.3%)\n",
      "f1 score: 0.701693297832\n",
      "f1 score: 0.712233637605\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  10\n",
      "-- train 0.67010(72.3%), valid0.66904(73.1%)\n",
      "-- train 0.68919(71.7%), valid0.67855(73.2%)\n",
      "f1 score: 0.704128873948\n",
      "f1 score: 0.712540508562\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  11\n",
      "-- train 0.66913(72.3%), valid0.66844(73.1%)\n",
      "-- train 0.68809(71.7%), valid0.67752(73.3%)\n",
      "f1 score: 0.703264832366\n",
      "f1 score: 0.713346054139\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  12\n",
      "-- train 0.66826(72.3%), valid0.66793(73.2%)\n",
      "-- train 0.68719(71.8%), valid0.67666(73.4%)\n",
      "f1 score: 0.70483793624\n",
      "f1 score: 0.713930939361\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  13\n",
      "-- train 0.66753(72.4%), valid0.66751(73.1%)\n",
      "-- train 0.68645(71.9%), valid0.67594(73.4%)\n",
      "f1 score: 0.703912942724\n",
      "f1 score: 0.713824194585\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  14\n",
      "-- train 0.66681(72.4%), valid0.66709(73.2%)\n",
      "-- train 0.68584(72.0%), valid0.67535(73.5%)\n",
      "f1 score: 0.704012097978\n",
      "f1 score: 0.714975909758\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  15\n",
      "-- train 0.66612(72.4%), valid0.66677(73.3%)\n",
      "-- train 0.68532(72.0%), valid0.67487(73.6%)\n",
      "f1 score: 0.705471993171\n",
      "f1 score: 0.716414082812\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  16\n",
      "-- train 0.66551(72.4%), valid0.66651(73.3%)\n",
      "-- train 0.68488(72.0%), valid0.67446(73.6%)\n",
      "f1 score: 0.70505880196\n",
      "f1 score: 0.714646879939\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  17\n",
      "-- train 0.66488(72.5%), valid0.66613(73.3%)\n",
      "-- train 0.68451(72.0%), valid0.67413(73.6%)\n",
      "f1 score: 0.705535121209\n",
      "f1 score: 0.713883320817\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  18\n",
      "-- train 0.66429(72.5%), valid0.66579(73.3%)\n",
      "-- train 0.68419(72.0%), valid0.67384(73.5%)\n",
      "f1 score: 0.705715581721\n",
      "f1 score: 0.713436970927\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  19\n",
      "-- train 0.66377(72.5%), valid0.66551(73.4%)\n",
      "-- train 0.68392(72.1%), valid0.67361(73.5%)\n",
      "f1 score: 0.706611002473\n",
      "f1 score: 0.713754062274\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  20\n",
      "-- train 0.66330(72.5%), valid0.66532(73.6%)\n",
      "-- train 0.68368(72.1%), valid0.67341(73.5%)\n",
      "f1 score: 0.708580666399\n",
      "f1 score: 0.713978893701\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  21\n",
      "-- train 0.66282(72.6%), valid0.66499(73.5%)\n",
      "-- train 0.68347(72.1%), valid0.67325(73.5%)\n",
      "f1 score: 0.708524039313\n",
      "f1 score: 0.713373691245\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  22\n",
      "-- train 0.66228(72.6%), valid0.66464(73.4%)\n",
      "-- train 0.68329(72.1%), valid0.67311(73.4%)\n",
      "f1 score: 0.706955125836\n",
      "f1 score: 0.713121594202\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  23\n",
      "-- train 0.66178(72.6%), valid0.66441(73.4%)\n",
      "-- train 0.68313(72.1%), valid0.67299(73.5%)\n",
      "f1 score: 0.707104580637\n",
      "f1 score: 0.713608912458\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  24\n",
      "-- train 0.66139(72.7%), valid0.66431(73.5%)\n",
      "-- train 0.68298(72.1%), valid0.67289(73.5%)\n",
      "f1 score: 0.708197220989\n",
      "f1 score: 0.714038570474\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  25\n",
      "-- train 0.65848(72.4%), valid0.66215(73.0%)\n",
      "-- train 0.68279(72.1%), valid0.67279(73.5%)\n",
      "f1 score: 0.705000570979\n",
      "f1 score: 0.713752596129\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  26\n",
      "-- train 0.65829(72.5%), valid0.66204(73.0%)\n",
      "-- train 0.68272(72.1%), valid0.67280(73.4%)\n",
      "f1 score: 0.705598796226\n",
      "f1 score: 0.713469874292\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  27\n",
      "-- train 0.65816(72.5%), valid0.66197(73.0%)\n",
      "-- train 0.68268(72.1%), valid0.67281(73.4%)\n",
      "f1 score: 0.70559520173\n",
      "f1 score: 0.71326494977\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  28\n",
      "-- train 0.65806(72.5%), valid0.66192(73.0%)\n",
      "-- train 0.68265(72.1%), valid0.67281(73.4%)\n",
      "f1 score: 0.705778266476\n",
      "f1 score: 0.713059839252\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  29\n",
      "-- train 0.65796(72.5%), valid0.66188(73.0%)\n",
      "-- train 0.68262(72.1%), valid0.67281(73.4%)\n",
      "f1 score: 0.705584217194\n",
      "f1 score: 0.713059839252\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  30\n",
      "-- train 0.65786(72.5%), valid0.66183(73.0%)\n",
      "-- train 0.68259(72.1%), valid0.67280(73.4%)\n",
      "f1 score: 0.705584217194\n",
      "f1 score: 0.712662588479\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  31\n",
      "-- train 0.65777(72.5%), valid0.66178(73.0%)\n",
      "-- train 0.68257(72.1%), valid0.67279(73.4%)\n",
      "f1 score: 0.706052991375\n",
      "f1 score: 0.712662588479\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  32\n",
      "-- train 0.65768(72.5%), valid0.66174(73.1%)\n",
      "-- train 0.68254(72.1%), valid0.67278(73.4%)\n",
      "f1 score: 0.706488239792\n",
      "f1 score: 0.712886863875\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  33\n",
      "-- train 0.65759(72.5%), valid0.66172(73.1%)\n",
      "-- train 0.68252(72.1%), valid0.67276(73.4%)\n",
      "f1 score: 0.707172464263\n",
      "f1 score: 0.712886863875\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  34\n",
      "-- train 0.65750(72.5%), valid0.66167(73.1%)\n",
      "-- train 0.68249(72.1%), valid0.67275(73.4%)\n",
      "f1 score: 0.707172464263\n",
      "f1 score: 0.712886863875\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  35\n",
      "-- train 0.65741(72.5%), valid0.66164(73.1%)\n",
      "-- train 0.68247(72.1%), valid0.67274(73.4%)\n",
      "f1 score: 0.707172464263\n",
      "f1 score: 0.712886863875\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  36\n",
      "-- train 0.65733(72.5%), valid0.66161(73.1%)\n",
      "-- train 0.68245(72.1%), valid0.67272(73.4%)\n",
      "f1 score: 0.707172464263\n",
      "f1 score: 0.712886863875\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  37\n",
      "-- train 0.65724(72.5%), valid0.66158(73.1%)\n",
      "-- train 0.68243(72.1%), valid0.67271(73.4%)\n",
      "f1 score: 0.707133200878\n",
      "f1 score: 0.712886863875\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  38\n",
      "-- train 0.65715(72.5%), valid0.66155(73.1%)\n",
      "-- train 0.68241(72.1%), valid0.67270(73.4%)\n",
      "f1 score: 0.707133200878\n",
      "f1 score: 0.712883141258\n",
      " \n",
      "log : 0\n",
      "log : 10\n",
      "log : 20\n",
      "log : 30\n",
      "***epoch*** :  39\n",
      "-- train 0.65706(72.5%), valid0.66150(73.1%)\n",
      "-- train 0.68239(72.1%), valid0.67268(73.4%)\n",
      "f1 score: 0.707133200878\n",
      "f1 score: 0.713125375181\n",
      " \n",
      "\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "print('Learning Started!')\n",
    "print(\"\")\n",
    "\n",
    "# train my model\n",
    "for epoch in range(total_epoch):\n",
    "    avg_cost = [0]*len(model_lst)\n",
    "    total_batch = int(len(training_lst) / batch_size)\n",
    "    idx = 0\n",
    "    \n",
    "    if epoch == 0 :\n",
    "        learning_rate = learning_rate1\n",
    "    elif epoch == 10 :\n",
    "        learning_rate = learning_rate2\n",
    "    elif epoch == 25 :\n",
    "        learning_rate = learning_rate3\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = training_lst[idx:idx+batch_size],training_label[idx:idx+batch_size]\n",
    "        \n",
    "        for model_num, model in enumerate(model_lst) :\n",
    "            _, c = model.train(batch_xs, batch_ys, learning_rate)\n",
    "            avg_cost[model_num] += c / total_batch\n",
    "        \n",
    "        idx += batch_size\n",
    "        if i%10 == 0 :\n",
    "            print(\"log :\", i)\n",
    "            \n",
    "    #train/valid cost & acc\n",
    "    print(\"***epoch*** : \", epoch)\n",
    "    for model_num, model in enumerate(model_lst) :\n",
    "        train_cost, train_acc = model.evaluate(training_lst, training_label)\n",
    "        valid_cost, valid_acc = model.evaluate(valid_lst, valid_label)\n",
    "\n",
    "        tl_ta_vl_va_lst[model_num][0].append(train_cost)\n",
    "        tl_ta_vl_va_lst[model_num][1].append(train_acc)\n",
    "        tl_ta_vl_va_lst[model_num][2].append(valid_cost)\n",
    "        tl_ta_vl_va_lst[model_num][3].append(valid_acc)\n",
    "\n",
    "        print(\"-- train {:.5f}({:.1f}%), valid{:.5f}({:.1f}%)\".format(train_cost, train_acc*100, valid_cost, valid_acc*100))\n",
    "    \n",
    "    for model_num, model in enumerate(model_lst) :\n",
    "        f1_score = my_f1_score2(np.argmax(model.predict(valid_lst)[0], axis=1), np.argmax(valid_label, axis=1))\n",
    "        tl_ta_vl_va_lst[model_num][4].append(f1_score)\n",
    "        print('f1 score:', f1_score)\n",
    "    print(\" \")\n",
    "\n",
    "print(\"\")\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a040eb8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in range(len(model_lst)) :\n",
    "    plt.plot(tl_ta_vl_va_lst[idx][4], label='training'+str(idx))\n",
    "    \n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68066734716\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y_hat</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>870</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>449</td>\n",
       "      <td>101</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>338</td>\n",
       "      <td>738</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>124</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y_hat    0    1    2    3\n",
       "Y                        \n",
       "0      870  103   64   55\n",
       "1       71  449  101   56\n",
       "2       21  338  738  160\n",
       "3       33   58  124  759"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(my_f1_score2(np.argmax(valid[16000:][[\"total_week\", \"total_month\", \"total_2month\", \"total_retained\"]].values, axis=1), np.argmax(valid_label, axis=1)))\n",
    "my_f1_table(np.argmax(valid[16000:][[\"total_week\", \"total_month\", \"total_2month\", \"total_retained\"]].values, axis=1), np.argmax(valid_label, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707133200878\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y_hat</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>873</td>\n",
       "      <td>97</td>\n",
       "      <td>57</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>452</td>\n",
       "      <td>77</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>327</td>\n",
       "      <td>766</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>72</td>\n",
       "      <td>127</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y_hat    0    1    2    3\n",
       "Y                        \n",
       "0      873   97   57   43\n",
       "1       57  452   77   37\n",
       "2       15  327  766  116\n",
       "3       50   72  127  834"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(my_f1_score2(np.argmax(model_lst[0].predict(valid_lst)[0], axis=1), np.argmax(valid_label, axis=1)))\n",
    "my_f1_table(np.argmax(model_lst[0].predict(valid_lst)[0], axis=1), np.argmax(valid_label, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.713125375181\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y_hat</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>881</td>\n",
       "      <td>78</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>487</td>\n",
       "      <td>115</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>324</td>\n",
       "      <td>767</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>59</td>\n",
       "      <td>110</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y_hat    0    1    2    3\n",
       "Y                        \n",
       "0      881   78   35   38\n",
       "1       62  487  115   50\n",
       "2       16  324  767  140\n",
       "3       36   59  110  802"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(my_f1_score2(np.argmax(model_lst[1].predict(valid_lst)[0], axis=1), np.argmax(valid_label, axis=1)))\n",
    "my_f1_table(np.argmax(model_lst[1].predict(valid_lst)[0], axis=1), np.argmax(valid_label, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model0_week</th>\n",
       "      <th>model0_month</th>\n",
       "      <th>model0_2month</th>\n",
       "      <th>model0_retained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958011</td>\n",
       "      <td>0.031204</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.004573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.094016</td>\n",
       "      <td>0.058178</td>\n",
       "      <td>0.843386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.360226</td>\n",
       "      <td>0.497244</td>\n",
       "      <td>0.135444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.561752</td>\n",
       "      <td>0.388947</td>\n",
       "      <td>0.031038</td>\n",
       "      <td>0.018263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104241</td>\n",
       "      <td>0.142380</td>\n",
       "      <td>0.121338</td>\n",
       "      <td>0.632041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model0_week  model0_month  model0_2month  model0_retained\n",
       "0     0.958011      0.031204       0.006212         0.004573\n",
       "1     0.004420      0.094016       0.058178         0.843386\n",
       "2     0.007087      0.360226       0.497244         0.135444\n",
       "3     0.561752      0.388947       0.031038         0.018263\n",
       "4     0.104241      0.142380       0.121338         0.632041"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_lst[0]\n",
    "pred1 = model.sess.run(model.softmax, feed_dict = {model.X : valid_lst, model.training:False})\n",
    "pred1_df = pd.DataFrame(pred1, columns = [\"model0_week\", \"model0_month\", \"model0_2month\", \"model0_retained\"])\n",
    "\n",
    "pred1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1_week</th>\n",
       "      <th>model1_month</th>\n",
       "      <th>model1_2month</th>\n",
       "      <th>model1_retained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.930415</td>\n",
       "      <td>0.041871</td>\n",
       "      <td>0.014128</td>\n",
       "      <td>0.013586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029266</td>\n",
       "      <td>0.272544</td>\n",
       "      <td>0.187970</td>\n",
       "      <td>0.510219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009392</td>\n",
       "      <td>0.361102</td>\n",
       "      <td>0.527034</td>\n",
       "      <td>0.102472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.590559</td>\n",
       "      <td>0.357585</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>0.021030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065255</td>\n",
       "      <td>0.102617</td>\n",
       "      <td>0.083664</td>\n",
       "      <td>0.748463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model1_week  model1_month  model1_2month  model1_retained\n",
       "0     0.930415      0.041871       0.014128         0.013586\n",
       "1     0.029266      0.272544       0.187970         0.510219\n",
       "2     0.009392      0.361102       0.527034         0.102472\n",
       "3     0.590559      0.357585       0.030826         0.021030\n",
       "4     0.065255      0.102617       0.083664         0.748463"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_lst[1]\n",
    "pred2 = model.sess.run(model.softmax, feed_dict = {model.X : valid_lst, model.training:False})\n",
    "pred2_df = pd.DataFrame(pred2, columns = [\"model1_week\", \"model1_month\", \"model1_2month\", \"model1_retained\"])\n",
    "\n",
    "pred2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model0_week</th>\n",
       "      <th>model0_month</th>\n",
       "      <th>model0_2month</th>\n",
       "      <th>model0_retained</th>\n",
       "      <th>model1_week</th>\n",
       "      <th>model1_month</th>\n",
       "      <th>model1_2month</th>\n",
       "      <th>model1_retained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958011</td>\n",
       "      <td>0.031204</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.930415</td>\n",
       "      <td>0.041871</td>\n",
       "      <td>0.014128</td>\n",
       "      <td>0.013586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.094016</td>\n",
       "      <td>0.058178</td>\n",
       "      <td>0.843386</td>\n",
       "      <td>0.029266</td>\n",
       "      <td>0.272544</td>\n",
       "      <td>0.187970</td>\n",
       "      <td>0.510219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.360226</td>\n",
       "      <td>0.497244</td>\n",
       "      <td>0.135444</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>0.361102</td>\n",
       "      <td>0.527034</td>\n",
       "      <td>0.102472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.561752</td>\n",
       "      <td>0.388947</td>\n",
       "      <td>0.031038</td>\n",
       "      <td>0.018263</td>\n",
       "      <td>0.590559</td>\n",
       "      <td>0.357585</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>0.021030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104241</td>\n",
       "      <td>0.142380</td>\n",
       "      <td>0.121338</td>\n",
       "      <td>0.632041</td>\n",
       "      <td>0.065255</td>\n",
       "      <td>0.102617</td>\n",
       "      <td>0.083664</td>\n",
       "      <td>0.748463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model0_week  model0_month  model0_2month  model0_retained  model1_week  \\\n",
       "0     0.958011      0.031204       0.006212         0.004573     0.930415   \n",
       "1     0.004420      0.094016       0.058178         0.843386     0.029266   \n",
       "2     0.007087      0.360226       0.497244         0.135444     0.009392   \n",
       "3     0.561752      0.388947       0.031038         0.018263     0.590559   \n",
       "4     0.104241      0.142380       0.121338         0.632041     0.065255   \n",
       "\n",
       "   model1_month  model1_2month  model1_retained  \n",
       "0      0.041871       0.014128         0.013586  \n",
       "1      0.272544       0.187970         0.510219  \n",
       "2      0.361102       0.527034         0.102472  \n",
       "3      0.357585       0.030826         0.021030  \n",
       "4      0.102617       0.083664         0.748463  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.concat([pred1_df, pred2_df], axis=1)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- 0 -------\n",
      "0.713125375181 [0, 0, 0, 0]\n",
      "0.713490495877 [0, 0, 0, 1]\n",
      "0.713691494437 [0, 0, 0, 8]\n",
      "0.713948125635 [0, 0, 0, 9]\n",
      "0.713962462697 [0, 0, 0, 11]\n",
      "0.714014542681 [0, 0, 0, 12]\n",
      "0.714118530099 [0, 0, 0, 17]\n",
      "0.714454444137 [0, 0, 0, 22]\n",
      "0.714459634557 [0, 0, 0, 27]\n",
      "0.714706197933 [0, 0, 0, 28]\n",
      "0.714910726613 [0, 0, 0, 29]\n",
      "0.715061937212 [0, 0, 1, 27]\n",
      "0.715308445855 [0, 0, 1, 28]\n",
      "0.715340054113 [0, 0, 3, 28]\n",
      "0.715538605493 [0, 0, 3, 30]\n",
      "0.715591881751 [0, 0, 4, 28]\n",
      "0.715796128484 [0, 0, 4, 29]\n",
      "0.715945494247 [0, 0, 6, 30]\n",
      "0.716042855151 [0, 0, 7, 28]\n",
      "0.716241113731 [0, 0, 7, 30]\n",
      "0.716289331373 [0, 0, 8, 23]\n",
      "0.716488579974 [0, 0, 8, 27]\n",
      "0.716735749154 [0, 0, 8, 28]\n",
      "0.716934391671 [0, 0, 8, 30]\n",
      "0.717025258856 [0, 0, 11, 28]\n",
      "0.717229589981 [0, 0, 11, 30]\n",
      "0.717421757338 [0, 0, 12, 29]\n",
      "0.717506293204 [0, 1, 11, 30]\n",
      "0.717515094559 [0, 1, 15, 30]\n",
      "0.717563991892 [0, 2, 14, 30]\n",
      "0.717578041323 [0, 3, 19, 30]\n",
      "0.717644319224 [0, 5, 12, 29]\n",
      "0.717678120994 [0, 8, 16, 9]\n",
      "0.717881722998 [0, 8, 16, 12]\n",
      "0.717972249681 [0, 8, 17, 9]\n",
      "0.71817591003 [0, 8, 17, 10]\n",
      "0.718224678167 [0, 8, 19, 11]\n",
      "0.718311996513 [0, 17, 12, 18]\n",
      "0.718312251885 [0, 18, 12, 17]\n",
      "\n",
      "------- 1 -------\n",
      "0.718404020599 [1, 8, 17, 10]\n",
      "0.718452819723 [1, 8, 19, 11]\n",
      "\n",
      "------- 2 -------\n",
      "\n",
      "------- 3 -------\n",
      "0.718632058455 [3, 8, 17, 10]\n",
      "0.718680888565 [3, 8, 19, 11]\n",
      "\n",
      "------- 4 -------\n",
      "0.71876783725 [4, 3, 12, 29]\n",
      "0.718807922953 [4, 3, 19, 30]\n",
      "0.718815215209 [4, 8, 17, 9]\n",
      "0.719019354138 [4, 8, 17, 10]\n",
      "\n",
      "------- 5 -------\n",
      "\n",
      "------- 6 -------\n",
      "\n",
      "------- 7 -------\n",
      "\n",
      "------- 8 -------\n",
      "\n",
      "------- 9 -------\n",
      "\n",
      "------- 10 -------\n",
      "\n",
      "------- 11 -------\n",
      "\n",
      "------- 12 -------\n",
      "0.719238635644 [12, 6, 12, 29]\n",
      "\n",
      "------- 13 -------\n",
      "0.719261669236 [13, 7, 13, 30]\n",
      "\n",
      "------- 14 -------\n",
      "0.719292943486 [14, 6, 12, 29]\n",
      "0.71944031017 [14, 6, 21, 10]\n",
      "\n",
      "------- 15 -------\n",
      "\n",
      "------- 16 -------\n",
      "\n",
      "------- 17 -------\n",
      "\n",
      "------- 18 -------\n",
      "0.719542094559 [18, 3, 19, 13]\n",
      "0.719577998204 [18, 3, 19, 30]\n",
      "0.719720727899 [18, 3, 20, 13]\n",
      "\n",
      "------- 19 -------\n",
      "\n",
      "------- 20 -------\n",
      "\n",
      "------- 21 -------\n",
      "\n",
      "------- 22 -------\n",
      "\n",
      "------- 23 -------\n",
      "\n",
      "------- 24 -------\n",
      "\n",
      "------- 25 -------\n",
      "\n",
      "------- 26 -------\n",
      "\n",
      "------- 27 -------\n",
      "\n",
      "------- 28 -------\n",
      "\n",
      "------- 29 -------\n",
      "\n",
      "------- 30 -------\n"
     ]
    }
   ],
   "source": [
    "best_weight = []\n",
    "best_f1 = 0\n",
    "\n",
    "for idx0 in range(0, 31)  :\n",
    "    print()\n",
    "    print(\"-------\",idx0,\"-------\")\n",
    "    \n",
    "    for idx1 in range(0, 31)  :\n",
    "        for idx2 in range(0, 31)  :\n",
    "            for idx3 in range(0, 31)  :\n",
    "                pred_df[\"week\"] = (idx0*pred_df[\"model0_week\"] + (30-idx0)*pred_df[\"model1_week\"]) / 30\n",
    "                pred_df[\"month\"] = (idx1*pred_df[\"model0_month\"] + (30-idx1)*pred_df[\"model1_month\"]) / 30\n",
    "                pred_df[\"2month\"] = (idx2*pred_df[\"model0_2month\"] + (30-idx2)*pred_df[\"model1_2month\"]) / 30\n",
    "                pred_df[\"retained\"] = (idx3*pred_df[\"model0_retained\"] + (30-idx3)*pred_df[\"model1_retained\"]) / 30\n",
    "                \n",
    "                f1 = my_f1_score2(np.argmax(pred_df[[\"week\", \"month\", \"2month\", \"retained\"]].values, axis=1), np.argmax(valid_label, axis=1))\n",
    "                if f1 > best_f1 :\n",
    "                    best_f1 = f1\n",
    "                    best_weight = [idx0, idx1, idx2, idx3]\n",
    "                    print(best_f1, best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
